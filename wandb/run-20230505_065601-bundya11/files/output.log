  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:11.826782 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:12.359485 - iteration 0
0:00:14.099422 - vxvyvz tensor([[-0.0153,  0.0539,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:14.100542 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.101519 - dR tensor([[[ 0.1293,  0.5242, -0.8417],
         [ 0.8338,  0.4019,  0.3784],
         [ 0.5366, -0.7508, -0.3851]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:14.102326 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:14.105990 - k: tensor([[[ 0.1293,  0.5242, -0.8417, -0.0100],
         [ 0.8338,  0.4019,  0.3784,  0.0062],
         [ 0.5366, -0.7508, -0.3851,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.106889 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.107886 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.108504 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.109108 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.109695 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:03<00:00,  3.58s/it, loss=0.0474]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.374354 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.907842 - iteration 0
0:00:15.219069 - vxvyvz tensor([[-0.0006,  0.0219,  0.0139]], device='cuda:0')
0:00:15.220163 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.221139 - dR tensor([[[ 0.2961,  0.7212, -0.6262],
         [ 0.6728,  0.3079,  0.6728],
         [ 0.6780, -0.6205, -0.3941]]], device='cuda:0')
0:00:15.221977 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.225190 - k: tensor([[[ 0.2961,  0.7212, -0.6262, -0.0100],
         [ 0.6728,  0.3079,  0.6728,  0.0062],
         [ 0.6780, -0.6205, -0.3941,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.226156 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.227085 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0042],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.227722 - k: tensor([0.0027], device='cuda:0')
0:00:15.228334 - k: tensor([0.0003], device='cuda:0')
0:00:15.228921 - k: tensor([0.0626], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.03it/s]
0:00:14.627028 - bracket_assembly_nut_noaug_coarse--479260
0:00:14.627225 - {'grad_norm': 0.9915765523910522, 'grad_norm_std': inf, 'learning_rate': 4.166666666666667e-11, 'time_forward': 2.310967445373535, 'time_backward': 0.6213464736938477, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269771.877496, 'n_iterations': 1, 'n_datas': 8, 'train_loss_TCO-iter=1': 0.04742132127285004, 'train_loss_TCO': 0.04742132127285004, 'train_loss_total': 0.04742132127285004, 'train_grad_norm': 0.9915765523910522, 'val_loss_TCO-iter=1': 0.06560629606246948, 'val_loss_TCO': 0.06560629606246948, 'val_loss_total': 0.06560629606246948, 'epoch': 0}
0:00:14.627345 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.635263 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.164481 - iteration 0
0:00:15.470657 - vxvyvz tensor([[-0.0158,  0.0528,  0.1929]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.471805 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.472780 - dR tensor([[[ 0.1065,  0.5328, -0.8395],
         [ 0.8238,  0.4256,  0.3746],
         [ 0.5569, -0.7314, -0.3936]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.473609 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.476682 - k: tensor([[[ 0.1065,  0.5328, -0.8395, -0.0100],
         [ 0.8238,  0.4256,  0.3746,  0.0062],
         [ 0.5569, -0.7314, -0.3936,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.477564 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.478462 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.479107 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.479738 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.480350 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, loss=0.0477]
0:00:15.035707 - bracket_assembly_nut_noaug_coarse--479260
0:00:15.035954 - {'grad_norm': 1.0177627801895142, 'grad_norm_std': inf, 'learning_rate': 6.25e-11, 'time_forward': 0.14029908180236816, 'time_backward': 0.07913374900817871, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269772.206888, 'n_iterations': 2, 'n_datas': 16, 'train_loss_TCO-iter=1': 0.04766087979078293, 'train_loss_TCO': 0.04766087979078293, 'train_loss_total': 0.04766087979078293, 'train_grad_norm': 1.0177627801895142, 'epoch': 1}
0:00:15.036099 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.119390 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.650702 - iteration 0
0:00:15.977902 - vxvyvz tensor([[-0.0171,  0.0475,  0.1920]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.978992 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.979991 - dR tensor([[[ 0.0886,  0.5487, -0.8313],
         [ 0.8382,  0.4097,  0.3598],
         [ 0.5381, -0.7287, -0.4236]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.980837 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.983868 - k: tensor([[[ 0.0886,  0.5487, -0.8313, -0.0100],
         [ 0.8382,  0.4097,  0.3598,  0.0062],
         [ 0.5381, -0.7287, -0.4236,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.984785 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.985710 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.986328 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.986972 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.987585 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.12it/s, loss=0.0477]
0:00:15.541600 - bracket_assembly_nut_noaug_coarse--479260
0:00:15.541839 - {'grad_norm': 1.0232936143875122, 'grad_norm_std': inf, 'learning_rate': 8.333333333333334e-11, 'time_forward': 0.16355133056640625, 'time_backward': 0.07769489288330078, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269772.7125976, 'n_iterations': 3, 'n_datas': 24, 'train_loss_TCO-iter=1': 0.04766948148608208, 'train_loss_TCO': 0.04766948148608208, 'train_loss_total': 0.04766948148608208, 'train_grad_norm': 1.0232936143875122, 'epoch': 2}
0:00:15.541976 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.643035 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.174321 - iteration 0
0:00:16.471210 - vxvyvz tensor([[-0.0219,  0.0409,  0.1960]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.472316 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.473279 - dR tensor([[[ 0.0932,  0.4964, -0.8631],
         [ 0.8383,  0.4285,  0.3370],
         [ 0.5371, -0.7550, -0.3762]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.474105 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.477161 - k: tensor([[[ 0.0932,  0.4964, -0.8631, -0.0100],
         [ 0.8383,  0.4285,  0.3370,  0.0062],
         [ 0.5371, -0.7550, -0.3762,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.478039 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.478949 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0588],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.479569 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.480206 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.480803 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.24it/s, loss=0.0474]
0:00:16.044294 - bracket_assembly_nut_noaug_coarse--479260
0:00:16.044544 - {'grad_norm': 1.1826648712158203, 'grad_norm_std': inf, 'learning_rate': 1.0416666666666667e-10, 'time_forward': 0.13298535346984863, 'time_backward': 0.07877850532531738, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269773.2069452, 'n_iterations': 4, 'n_datas': 32, 'train_loss_TCO-iter=1': 0.047433726489543915, 'train_loss_TCO': 0.047433726489543915, 'train_loss_total': 0.047433726489543915, 'train_grad_norm': 1.1826648712158203, 'epoch': 3}
0:00:16.044669 - None
0:00:17.940528 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],<?, ?it/s]0:00:16.147225 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.678511 - iteration 0
0:00:16.974976 - vxvyvz tensor([[-0.0185,  0.0513,  0.1981]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.976093 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.977057 - dR tensor([[[ 0.1005,  0.5129, -0.8526],
         [ 0.8413,  0.4137,  0.3480],
         [ 0.5312, -0.7522, -0.3899]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.977896 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.981045 - k: tensor([[[ 0.1005,  0.5129, -0.8526, -0.0100],
         [ 0.8413,  0.4137,  0.3480,  0.0062],
         [ 0.5312, -0.7522, -0.3899,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.982033 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.982958 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0594],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.983582 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.984297 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.984960 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.22it/s, loss=0.0471]
0:00:16.537781 - bracket_assembly_nut_noaug_coarse--479260
0:00:16.538004 - {'grad_norm': 1.0485366582870483, 'grad_norm_std': inf, 'learning_rate': 1.25e-10, 'time_forward': 0.1330583095550537, 'time_backward': 0.07857537269592285, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269773.7108948, 'n_iterations': 5, 'n_datas': 40, 'train_loss_TCO-iter=1': 0.04714112728834152, 'train_loss_TCO': 0.04714112728834152, 'train_loss_total': 0.04714112728834152, 'train_grad_norm': 1.0485366582870483, 'epoch': 4}
0:00:16.538116 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:16.628956 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.160264 - iteration 0
0:00:17.458198 - vxvyvz tensor([[-0.0131,  0.0505,  0.1910]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:17.459322 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.460357 - dR tensor([[[ 0.1087,  0.5135, -0.8512],
         [ 0.8691,  0.3666,  0.3322],
         [ 0.4826, -0.7758, -0.4064]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:17.461217 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:17.464439 - k: tensor([[[ 0.1087,  0.5135, -0.8512, -0.0100],
         [ 0.8691,  0.3666,  0.3322,  0.0062],
         [ 0.4826, -0.7758, -0.4064,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.465445 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.466346 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0573],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.466999 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.467622 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.468337 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.34it/s, loss=0.0478]
0:00:17.035267 - bracket_assembly_nut_noaug_coarse--479260
0:00:17.035522 - {'grad_norm': 1.078023076057434, 'grad_norm_std': inf, 'learning_rate': 1.4583333333333335e-10, 'time_forward': 0.13486886024475098, 'time_backward': 0.0775594711303711, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269774.193222, 'n_iterations': 6, 'n_datas': 48, 'train_loss_TCO-iter=1': 0.04777728021144867, 'train_loss_TCO': 0.04777728021144867, 'train_loss_total': 0.04777728021144867, 'train_grad_norm': 1.078023076057434, 'epoch': 5}
0:00:17.035649 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:17.111113 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.642355 - iteration 0
0:00:17.939420 - vxvyvz tensor([[-0.0188,  0.0548,  0.1885]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:17.940528 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],<?, ?it/s]0:00:16.147225 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.941514 - dR tensor([[[ 0.0979,  0.5663, -0.8183],
         [ 0.8172,  0.4236,  0.3909],
         [ 0.5680, -0.7070, -0.4213]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:17.942356 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:17.945650 - k: tensor([[[ 0.0979,  0.5663, -0.8183, -0.0100],
         [ 0.8172,  0.4236,  0.3909,  0.0062],
         [ 0.5680, -0.7070, -0.4213,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.946649 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.947648 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0566],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.948311 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.948919 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.949525 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.52it/s, loss=0.0481]
0:00:17.508779 - bracket_assembly_nut_noaug_coarse--479260
0:00:17.509029 - {'grad_norm': 1.0568135976791382, 'grad_norm_std': inf, 'learning_rate': 1.6666666666666669e-10, 'time_forward': 0.1337296962738037, 'time_backward': 0.07834458351135254, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269774.675223, 'n_iterations': 7, 'n_datas': 56, 'train_loss_TCO-iter=1': 0.048068467527627945, 'train_loss_TCO': 0.048068467527627945, 'train_loss_total': 0.048068467527627945, 'train_grad_norm': 1.0568135976791382, 'epoch': 6}
0:00:17.509152 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:17.586039 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.117349 - iteration 0
0:00:18.403303 - vxvyvz tensor([[-0.0158,  0.0530,  0.1916]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:18.404385 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.405381 - dR tensor([[[ 0.1139,  0.4827, -0.8683],
         [ 0.8467,  0.4100,  0.3391],
         [ 0.5197, -0.7739, -0.3620]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:18.406271 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:18.409554 - k: tensor([[[ 0.1139,  0.4827, -0.8683, -0.0100],
         [ 0.8467,  0.4100,  0.3391,  0.0062],
         [ 0.5197, -0.7739, -0.3620,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.410561 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.411513 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0575],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.412178 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.412787 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.413391 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.64it/s, loss=0.0479]
0:00:18.010282 - bracket_assembly_nut_noaug_coarse--479260
0:00:18.010543 - {'grad_norm': 1.0723159313201904, 'grad_norm_std': inf, 'learning_rate': 1.8750000000000002e-10, 'time_forward': 0.1226961612701416, 'time_backward': 0.07871389389038086, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269775.1392732, 'n_iterations': 8, 'n_datas': 64, 'train_loss_TCO-iter=1': 0.047928936779499054, 'train_loss_TCO': 0.047928936779499054, 'train_loss_total': 0.047928936779499054, 'train_grad_norm': 1.0723159313201904, 'epoch': 7}
0:00:18.010669 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:18.018387 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.549623 - iteration 0
0:00:18.836166 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:18.837227 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.838215 - dR tensor([[[ 0.1270,  0.5868, -0.7997],
         [ 0.8343,  0.3729,  0.4061],
         [ 0.5366, -0.7187, -0.4422]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:18.839097 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:18.842344 - k: tensor([[[ 0.1270,  0.5868, -0.7997, -0.0100],
         [ 0.8343,  0.3729,  0.4061,  0.0062],
         [ 0.5366, -0.7187, -0.4422,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.843377 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.844345 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.844964 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.845572 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.846185 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s, loss=0.0471]
0:00:18.411965 - bracket_assembly_nut_noaug_coarse--479260
0:00:18.412216 - {'grad_norm': 1.1492713689804077, 'grad_norm_std': inf, 'learning_rate': 2.0833333333333334e-10, 'time_forward': 0.12312054634094238, 'time_backward': 0.07939767837524414, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269775.5726902, 'n_iterations': 9, 'n_datas': 72, 'train_loss_TCO-iter=1': 0.04705701768398285, 'train_loss_TCO': 0.04705701768398285, 'train_loss_total': 0.04705701768398285, 'train_grad_norm': 1.1492713689804077, 'epoch': 8}
0:00:18.412343 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:18.420212 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.951293 - iteration 0
0:00:19.239654 - vxvyvz tensor([[-0.0160,  0.0547,  0.1946]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:19.240718 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.241695 - dR tensor([[[ 0.1236,  0.5751, -0.8087],
         [ 0.8451,  0.3661,  0.3895],
         [ 0.5201, -0.7316, -0.4408]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:19.242541 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:19.245744 - k: tensor([[[ 0.1236,  0.5751, -0.8087, -0.0100],
         [ 0.8451,  0.3661,  0.3895,  0.0062],
         [ 0.5201, -0.7316, -0.4408,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.246783 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.247725 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0584],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.248387 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.249019 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.249624 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.83it/s, loss=0.0472]
0:00:18.809653 - bracket_assembly_nut_noaug_coarse--479260
0:00:18.809888 - {'grad_norm': 1.002868890762329, 'grad_norm_std': inf, 'learning_rate': 2.2916666666666665e-10, 'time_forward': 0.12476158142089844, 'time_backward': 0.0783233642578125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269775.9750493, 'n_iterations': 10, 'n_datas': 80, 'train_loss_TCO-iter=1': 0.04724136367440224, 'train_loss_TCO': 0.04724136367440224, 'train_loss_total': 0.04724136367440224, 'train_grad_norm': 1.002868890762329, 'epoch': 9}
0:00:18.810008 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:18.817564 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.348651 - iteration 0
0:00:19.649416 - vxvyvz tensor([[-0.0130,  0.0491,  0.1916]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:19.650443 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.651472 - dR tensor([[[ 0.1018,  0.5400, -0.8355],
         [ 0.8546,  0.3824,  0.3513],
         [ 0.5092, -0.7498, -0.4225]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:19.652366 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:19.655488 - k: tensor([[[ 0.1018,  0.5400, -0.8355, -0.0100],
         [ 0.8546,  0.3824,  0.3513,  0.0062],
         [ 0.5092, -0.7498, -0.4225,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.656511 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.657406 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0575],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.658067 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.658674 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.659327 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.61it/s, loss=0.0477]
0:00:19.223296 - bracket_assembly_nut_noaug_coarse--479260
0:00:19.223530 - {'grad_norm': 1.0552409887313843, 'grad_norm_std': inf, 'learning_rate': 2.5e-10, 'time_forward': 0.13708877563476562, 'time_backward': 0.07596254348754883, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269776.3825076, 'n_iterations': 11, 'n_datas': 88, 'train_loss_TCO-iter=1': 0.047663040459156036, 'train_loss_TCO': 0.047663040459156036, 'train_loss_total': 0.047663040459156036, 'train_grad_norm': 1.0552409887313843, 'epoch': 10}
0:00:19.223656 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:19.231208 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.762263 - iteration 0
0:00:20.063318 - vxvyvz tensor([[-0.0208,  0.0529,  0.1913]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:20.064393 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.065372 - dR tensor([[[ 0.1157,  0.5181, -0.8474],
         [ 0.8556,  0.3814,  0.3501],
         [ 0.5046, -0.7655, -0.3992]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:20.066203 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:20.069420 - k: tensor([[[ 0.1157,  0.5181, -0.8474, -0.0100],
         [ 0.8556,  0.3814,  0.3501,  0.0062],
         [ 0.5046, -0.7655, -0.3992,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.070437 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.071370 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.072033 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.072658 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.073278 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.60it/s, loss=0.0478]
0:00:19.640579 - bracket_assembly_nut_noaug_coarse--479260
0:00:19.640819 - {'grad_norm': 1.0751440525054932, 'grad_norm_std': inf, 'learning_rate': 2.7083333333333333e-10, 'time_forward': 0.13734173774719238, 'time_backward': 0.0765836238861084, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269776.7969701, 'n_iterations': 12, 'n_datas': 96, 'train_loss_TCO-iter=1': 0.047766294330358505, 'train_loss_TCO': 0.047766294330358505, 'train_loss_total': 0.047766294330358505, 'train_grad_norm': 1.0751440525054932, 'epoch': 11}
0:00:19.640968 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:19.648536 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.179512 - iteration 0
0:00:20.468132 - vxvyvz tensor([[-0.0185,  0.0513,  0.1981]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:20.469216 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.470200 - dR tensor([[[ 0.1005,  0.5129, -0.8526],
         [ 0.8413,  0.4137,  0.3480],
         [ 0.5312, -0.7522, -0.3899]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:20.471066 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:20.474254 - k: tensor([[[ 0.1005,  0.5129, -0.8526, -0.0100],
         [ 0.8413,  0.4137,  0.3480,  0.0062],
         [ 0.5312, -0.7522, -0.3899,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.475244 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.476198 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0594],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.476813 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.477419 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.478032 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.86it/s, loss=0.0472]
0:00:20.040791 - bracket_assembly_nut_noaug_coarse--479260
0:00:20.041031 - {'grad_norm': 1.0497361421585083, 'grad_norm_std': inf, 'learning_rate': 2.916666666666667e-10, 'time_forward': 0.1248009204864502, 'time_backward': 0.07707571983337402, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269777.2022588, 'n_iterations': 13, 'n_datas': 104, 'train_loss_TCO-iter=1': 0.04717129468917847, 'train_loss_TCO': 0.04717129468917847, 'train_loss_total': 0.04717129468917847, 'train_grad_norm': 1.0497361421585083, 'epoch': 12}
0:00:20.041152 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.048833 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.579838 - iteration 0
0:00:20.865822 - vxvyvz tensor([[-0.0184,  0.0522,  0.1931]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:20.866905 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.867982 - dR tensor([[[ 0.1479,  0.5164, -0.8435],
         [ 0.8395,  0.3854,  0.3831],
         [ 0.5229, -0.7647, -0.3766]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:20.868840 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:20.872016 - k: tensor([[[ 0.1479,  0.5164, -0.8435, -0.0100],
         [ 0.8395,  0.3854,  0.3831,  0.0062],
         [ 0.5229, -0.7647, -0.3766,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.873032 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.873960 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.874573 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.875216 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.875862 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.94it/s, loss=0.0477]
0:00:20.437341 - bracket_assembly_nut_noaug_coarse--479260
0:00:20.437604 - {'grad_norm': 1.0366345643997192, 'grad_norm_std': inf, 'learning_rate': 3.125e-10, 'time_forward': 0.12245321273803711, 'time_backward': 0.0762627124786377, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269777.5992875, 'n_iterations': 14, 'n_datas': 112, 'train_loss_TCO-iter=1': 0.04768854007124901, 'train_loss_TCO': 0.04768854007124901, 'train_loss_total': 0.04768854007124901, 'train_grad_norm': 1.0366345643997192, 'epoch': 13}
0:00:20.437722 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.445254 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.976234 - iteration 0
0:00:21.262414 - vxvyvz tensor([[-0.0222,  0.0495,  0.2019]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.263490 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.264513 - dR tensor([[[ 0.0907,  0.5337, -0.8408],
         [ 0.8235,  0.4346,  0.3647],
         [ 0.5601, -0.7254, -0.4001]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.265363 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.268524 - k: tensor([[[ 0.0907,  0.5337, -0.8408, -0.0100],
         [ 0.8235,  0.4346,  0.3647,  0.0062],
         [ 0.5601, -0.7254, -0.4001,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.269510 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.270417 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0606],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.271071 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.271712 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.272340 - k: tensor([0.0438], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.91it/s, loss=0.0468]
0:00:20.828569 - bracket_assembly_nut_noaug_coarse--479260
0:00:20.828791 - {'grad_norm': 1.0878915786743164, 'grad_norm_std': inf, 'learning_rate': 3.3333333333333337e-10, 'time_forward': 0.12235546112060547, 'time_backward': 0.07770156860351562, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269777.9972498, 'n_iterations': 15, 'n_datas': 120, 'train_loss_TCO-iter=1': 0.046784333884716034, 'train_loss_TCO': 0.046784333884716034, 'train_loss_total': 0.046784333884716034, 'train_grad_norm': 1.0878915786743164, 'epoch': 14}
0:00:20.828906 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.836587 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.367599 - iteration 0
0:00:21.587912 - vxvyvz tensor([[-0.0136,  0.0443,  0.1952]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.588975 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.589947 - dR tensor([[[ 0.1183,  0.5824, -0.8043],
         [ 0.8325,  0.3833,  0.4000],
         [ 0.5412, -0.7169, -0.4395]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.590822 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.593991 - k: tensor([[[ 0.1183,  0.5824, -0.8043, -0.0100],
         [ 0.8325,  0.3833,  0.4000,  0.0062],
         [ 0.5412, -0.7169, -0.4395,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.595002 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.596436 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.597220 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.597829 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.598435 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0473]
0:00:21.161844 - bracket_assembly_nut_noaug_coarse--479260
0:00:21.162103 - {'grad_norm': 1.1485865116119385, 'grad_norm_std': inf, 'learning_rate': 3.541666666666667e-10, 'time_forward': 0.05723381042480469, 'time_backward': 0.07717704772949219, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269778.3228345, 'n_iterations': 16, 'n_datas': 128, 'train_loss_TCO-iter=1': 0.04726168140769005, 'train_loss_TCO': 0.04726168140769005, 'train_loss_total': 0.04726168140769005, 'train_grad_norm': 1.1485865116119385, 'epoch': 15}
0:00:21.162224 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.169698 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.700677 - iteration 0
0:00:21.919944 - vxvyvz tensor([[-0.0077,  0.0509,  0.1913]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.920976 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.921934 - dR tensor([[[ 0.1557,  0.5514, -0.8196],
         [ 0.8104,  0.4031,  0.4251],
         [ 0.5648, -0.7304, -0.3841]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.922801 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.925955 - k: tensor([[[ 0.1557,  0.5514, -0.8196, -0.0100],
         [ 0.8104,  0.4031,  0.4251,  0.0062],
         [ 0.5648, -0.7304, -0.3841,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.927463 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.928477 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.929189 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.929814 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.930446 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0479]
0:00:21.493859 - bracket_assembly_nut_noaug_coarse--479260
0:00:21.494111 - {'grad_norm': 1.0059840679168701, 'grad_norm_std': inf, 'learning_rate': 3.7500000000000005e-10, 'time_forward': 0.056070804595947266, 'time_backward': 0.07738709449768066, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269778.6550841, 'n_iterations': 17, 'n_datas': 136, 'train_loss_TCO-iter=1': 0.04785638302564621, 'train_loss_TCO': 0.04785638302564621, 'train_loss_total': 0.04785638302564621, 'train_grad_norm': 1.0059840679168701, 'epoch': 16}
0:00:21.494233 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.501859 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.032839 - iteration 0
0:00:22.252292 - vxvyvz tensor([[-0.0219,  0.0525,  0.1895]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.253288 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.254240 - dR tensor([[[ 0.0940,  0.5833, -0.8068],
         [ 0.8468,  0.3793,  0.3729],
         [ 0.5235, -0.7183, -0.4583]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.255106 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.258334 - k: tensor([[[ 0.0940,  0.5833, -0.8068, -0.0100],
         [ 0.8468,  0.3793,  0.3729,  0.0062],
         [ 0.5235, -0.7183, -0.4583,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.259380 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.260340 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0569],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.260996 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.261607 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.262213 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0477]
0:00:21.833605 - bracket_assembly_nut_noaug_coarse--479260
0:00:21.833874 - {'grad_norm': 1.0627896785736084, 'grad_norm_std': inf, 'learning_rate': 3.9583333333333336e-10, 'time_forward': 0.05621814727783203, 'time_backward': 0.07859396934509277, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269778.988652, 'n_iterations': 18, 'n_datas': 144, 'train_loss_TCO-iter=1': 0.04772522300481796, 'train_loss_TCO': 0.04772522300481796, 'train_loss_total': 0.04772522300481796, 'train_grad_norm': 1.0627896785736084, 'epoch': 17}
0:00:21.834072 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.841894 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.372957 - iteration 0
0:00:22.595450 - vxvyvz tensor([[-0.0132,  0.0469,  0.2026]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.596545 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.597533 - dR tensor([[[ 0.1140,  0.5169, -0.8484],
         [ 0.8244,  0.4274,  0.3711],
         [ 0.5545, -0.7417, -0.3774]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.598371 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.601643 - k: tensor([[[ 0.1140,  0.5169, -0.8484, -0.0100],
         [ 0.8244,  0.4274,  0.3711,  0.0062],
         [ 0.5545, -0.7417, -0.3774,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.602671 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.603613 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0608],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.604267 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.605336 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.606031 - k: tensor([0.0437], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, loss=0.0468]
0:00:22.175633 - bracket_assembly_nut_noaug_coarse--479260
0:00:22.175916 - {'grad_norm': 1.0755258798599243, 'grad_norm_std': inf, 'learning_rate': 4.166666666666667e-10, 'time_forward': 0.0594935417175293, 'time_backward': 0.0782315731048584, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269779.3314495, 'n_iterations': 19, 'n_datas': 152, 'train_loss_TCO-iter=1': 0.04681265354156494, 'train_loss_TCO': 0.04681265354156494, 'train_loss_total': 0.04681265354156494, 'train_grad_norm': 1.0755258798599243, 'epoch': 18}
0:00:22.176093 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:22.183753 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.714860 - iteration 0
0:00:22.934369 - vxvyvz tensor([[-0.0156,  0.0498,  0.1963]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.935434 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.936454 - dR tensor([[[ 0.1176,  0.5219, -0.8449],
         [ 0.8394,  0.4024,  0.3654],
         [ 0.5307, -0.7521, -0.3908]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.937272 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.940464 - k: tensor([[[ 0.1176,  0.5219, -0.8449, -0.0100],
         [ 0.8394,  0.4024,  0.3654,  0.0062],
         [ 0.5307, -0.7521, -0.3908,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.941358 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.942774 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.943551 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.944185 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.944791 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0474]
0:00:22.513779 - bracket_assembly_nut_noaug_coarse--479260
0:00:22.514034 - {'grad_norm': 1.0452911853790283, 'grad_norm_std': inf, 'learning_rate': 4.375e-10, 'time_forward': 0.05629920959472656, 'time_backward': 0.07854795455932617, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269779.670589, 'n_iterations': 20, 'n_datas': 160, 'train_loss_TCO-iter=1': 0.047362636774778366, 'train_loss_TCO': 0.047362636774778366, 'train_loss_total': 0.047362636774778366, 'train_grad_norm': 1.0452911853790283, 'epoch': 19}
0:00:22.514153 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:22.521883 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.052873 - iteration 0
0:00:23.272377 - vxvyvz tensor([[-0.0198,  0.0469,  0.1924]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:23.273431 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.274420 - dR tensor([[[ 0.1081,  0.5325, -0.8395],
         [ 0.8219,  0.4272,  0.3768],
         [ 0.5593, -0.7307, -0.3915]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:23.275305 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:23.278474 - k: tensor([[[ 0.1081,  0.5325, -0.8395, -0.0100],
         [ 0.8219,  0.4272,  0.3768,  0.0062],
         [ 0.5593, -0.7307, -0.3915,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.279486 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.280444 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.281131 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.281741 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.282581 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0477]
0:00:22.841901 - bracket_assembly_nut_noaug_coarse--479260
0:00:22.842120 - {'grad_norm': 1.092923641204834, 'grad_norm_std': inf, 'learning_rate': 4.583333333333333e-10, 'time_forward': 0.05646681785583496, 'time_backward': 0.08054089546203613, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269780.0107527, 'n_iterations': 21, 'n_datas': 168, 'train_loss_TCO-iter=1': 0.04771869629621506, 'train_loss_TCO': 0.04771869629621506, 'train_loss_total': 0.04771869629621506, 'train_grad_norm': 1.092923641204834, 'epoch': 20}
0:00:22.842238 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:22.849933 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.380948 - iteration 0
0:00:23.600517 - vxvyvz tensor([[-0.0165,  0.0511,  0.1996]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:23.601504 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.602459 - dR tensor([[[ 0.0740,  0.5261, -0.8472],
         [ 0.8480,  0.4138,  0.3311],
         [ 0.5248, -0.7430, -0.4155]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:23.603331 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:23.606507 - k: tensor([[[ 0.0740,  0.5261, -0.8472, -0.0100],
         [ 0.8480,  0.4138,  0.3311,  0.0062],
         [ 0.5248, -0.7430, -0.4155,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.607471 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.608413 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.609055 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.610129 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.610871 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.047]
0:00:23.303866 - bracket_assembly_nut_noaug_coarse--479260
0:00:23.304121 - {'grad_norm': 1.0833239555358887, 'grad_norm_std': inf, 'learning_rate': 4.791666666666667e-10, 'time_forward': 0.05622434616088867, 'time_backward': 0.0784909725189209, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269780.3365135, 'n_iterations': 22, 'n_datas': 176, 'train_loss_TCO-iter=1': 0.04696185514330864, 'train_loss_TCO': 0.04696185514330864, 'train_loss_total': 0.04696185514330864, 'train_grad_norm': 1.0833239555358887, 'epoch': 21}
0:00:23.304253 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.311954 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.842974 - iteration 0
0:00:24.063063 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.064112 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.065067 - dR tensor([[[ 0.1270,  0.5868, -0.7997],
         [ 0.8343,  0.3729,  0.4061],
         [ 0.5366, -0.7187, -0.4422]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.065904 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.069139 - k: tensor([[[ 0.1270,  0.5868, -0.7997, -0.0100],
         [ 0.8343,  0.3729,  0.4061,  0.0062],
         [ 0.5366, -0.7187, -0.4422,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.070093 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.071039 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.071679 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.073076 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.073774 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.047]
0:00:23.632648 - bracket_assembly_nut_noaug_coarse--479260
0:00:23.632867 - {'grad_norm': 1.1476246118545532, 'grad_norm_std': inf, 'learning_rate': 5e-10, 'time_forward': 0.05714297294616699, 'time_backward': 0.07854986190795898, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269780.7996056, 'n_iterations': 23, 'n_datas': 184, 'train_loss_TCO-iter=1': 0.04701962321996689, 'train_loss_TCO': 0.04701962321996689, 'train_loss_total': 0.04701962321996689, 'train_grad_norm': 1.1476246118545532, 'epoch': 22}
0:00:23.632991 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.640578 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.171544 - iteration 0
0:00:24.391157 - vxvyvz tensor([[-0.0170,  0.0483,  0.1946]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.392210 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.393174 - dR tensor([[[ 0.0907,  0.5232, -0.8474],
         [ 0.8163,  0.4484,  0.3642],
         [ 0.5705, -0.7247, -0.3864]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.394009 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.397226 - k: tensor([[[ 0.0907,  0.5232, -0.8474, -0.0100],
         [ 0.8163,  0.4484,  0.3642,  0.0062],
         [ 0.5705, -0.7247, -0.3864,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.398429 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.399744 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0584],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.400383 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.401005 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.401614 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0476]
0:00:23.970411 - bracket_assembly_nut_noaug_coarse--479260
0:00:23.970633 - {'grad_norm': 1.0522533655166626, 'grad_norm_std': inf, 'learning_rate': 5.208333333333333e-10, 'time_forward': 0.056348323822021484, 'time_backward': 0.07867693901062012, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269781.1275244, 'n_iterations': 24, 'n_datas': 192, 'train_loss_TCO-iter=1': 0.04758862033486366, 'train_loss_TCO': 0.04758862033486366, 'train_loss_total': 0.04758862033486366, 'train_grad_norm': 1.0522533655166626, 'epoch': 23}
0:00:23.970811 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.978406 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.509361 - iteration 0
0:00:24.728822 - vxvyvz tensor([[-0.0115,  0.0515,  0.1964]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.729911 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.730917 - dR tensor([[[ 0.1156,  0.5163, -0.8485],
         [ 0.8309,  0.4178,  0.3675],
         [ 0.5443, -0.7475, -0.3807]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.731794 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.734997 - k: tensor([[[ 0.1156,  0.5163, -0.8485, -0.0100],
         [ 0.8309,  0.4178,  0.3675,  0.0062],
         [ 0.5443, -0.7475, -0.3807,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.735963 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.737469 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.738179 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.738824 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.739447 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0474]
0:00:24.293440 - bracket_assembly_nut_noaug_coarse--479260
0:00:24.293658 - {'grad_norm': 1.1355924606323242, 'grad_norm_std': inf, 'learning_rate': 5.416666666666667e-10, 'time_forward': 0.05632185935974121, 'time_backward': 0.07787871360778809, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269781.4644885, 'n_iterations': 25, 'n_datas': 200, 'train_loss_TCO-iter=1': 0.04735906049609184, 'train_loss_TCO': 0.04735906049609184, 'train_loss_total': 0.04735906049609184, 'train_grad_norm': 1.1355924606323242, 'epoch': 24}
0:00:24.293770 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.301358 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.832400 - iteration 0
0:00:25.052019 - vxvyvz tensor([[-0.0152,  0.0482,  0.1920]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.053072 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.054028 - dR tensor([[[ 0.0959,  0.5863, -0.8044],
         [ 0.8196,  0.4121,  0.3980],
         [ 0.5648, -0.6974, -0.4411]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.054892 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.058108 - k: tensor([[[ 0.0959,  0.5863, -0.8044, -0.0100],
         [ 0.8196,  0.4121,  0.3980,  0.0062],
         [ 0.5648, -0.6974, -0.4411,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.059648 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.060694 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.061349 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.061992 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.062616 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0476]
0:00:24.616673 - bracket_assembly_nut_noaug_coarse--479260
0:00:24.616891 - {'grad_norm': 1.1565786600112915, 'grad_norm_std': inf, 'learning_rate': 5.625e-10, 'time_forward': 0.056604623794555664, 'time_backward': 0.0782170295715332, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269781.7880363, 'n_iterations': 26, 'n_datas': 208, 'train_loss_TCO-iter=1': 0.04759988933801651, 'train_loss_TCO': 0.04759988933801651, 'train_loss_total': 0.04759988933801651, 'train_grad_norm': 1.1565786600112915, 'epoch': 25}
0:00:24.616999 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.624617 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.156176 - iteration 0
0:00:25.386955 - vxvyvz tensor([[-0.0136,  0.0443,  0.1952]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.388526 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.389565 - dR tensor([[[ 0.1183,  0.5824, -0.8042],
         [ 0.8325,  0.3833,  0.4000],
         [ 0.5412, -0.7169, -0.4395]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.390414 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.393648 - k: tensor([[[ 0.1183,  0.5824, -0.8042, -0.0100],
         [ 0.8325,  0.3833,  0.4000,  0.0062],
         [ 0.5412, -0.7169, -0.4395,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.394586 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.395518 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.396179 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.396790 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.397397 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.69it/s, loss=0.0472]
0:00:24.960889 - bracket_assembly_nut_noaug_coarse--479260
0:00:24.961127 - {'grad_norm': 1.1474039554595947, 'grad_norm_std': inf, 'learning_rate': 5.833333333333334e-10, 'time_forward': 0.06808757781982422, 'time_backward': 0.07768559455871582, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269782.122196, 'n_iterations': 27, 'n_datas': 216, 'train_loss_TCO-iter=1': 0.04723692685365677, 'train_loss_TCO': 0.04723692685365677, 'train_loss_total': 0.04723692685365677, 'train_grad_norm': 1.1474039554595947, 'epoch': 26}
0:00:24.961247 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.968783 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.499803 - iteration 0
0:00:25.719133 - vxvyvz tensor([[-0.0153,  0.0529,  0.1913]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.720170 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.721126 - dR tensor([[[ 0.0898,  0.5346, -0.8403],
         [ 0.8336,  0.4214,  0.3571],
         [ 0.5450, -0.7326, -0.4078]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.721957 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.725194 - k: tensor([[[ 0.0898,  0.5346, -0.8403, -0.0100],
         [ 0.8336,  0.4214,  0.3571,  0.0062],
         [ 0.5450, -0.7326, -0.4078,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.726676 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.727740 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.728374 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.728997 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.729620 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0478]
0:00:25.281837 - bracket_assembly_nut_noaug_coarse--479260
0:00:25.282064 - {'grad_norm': 1.0209158658981323, 'grad_norm_std': inf, 'learning_rate': 6.041666666666667e-10, 'time_forward': 0.056182146072387695, 'time_backward': 0.07804369926452637, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269782.454785, 'n_iterations': 28, 'n_datas': 224, 'train_loss_TCO-iter=1': 0.04778449609875679, 'train_loss_TCO': 0.04778449609875679, 'train_loss_total': 0.04778449609875679, 'train_grad_norm': 1.0209158658981323, 'epoch': 27}
0:00:25.282179 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.289777 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.820750 - iteration 0
0:00:26.040208 - vxvyvz tensor([[-0.0156,  0.0515,  0.1949]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.041224 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.042204 - dR tensor([[[ 0.0839,  0.5289, -0.8445],
         [ 0.8422,  0.4154,  0.3437],
         [ 0.5326, -0.7401, -0.4106]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.043075 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.046323 - k: tensor([[[ 0.0839,  0.5289, -0.8445, -0.0100],
         [ 0.8422,  0.4154,  0.3437,  0.0062],
         [ 0.5326, -0.7401, -0.4106,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.047781 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.048896 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0585],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.049519 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.050128 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.050743 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0474]
0:00:25.611111 - bracket_assembly_nut_noaug_coarse--479260
0:00:25.611295 - {'grad_norm': 1.1218459606170654, 'grad_norm_std': inf, 'learning_rate': 6.25e-10, 'time_forward': 0.05631208419799805, 'time_backward': 0.07940387725830078, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269782.7772713, 'n_iterations': 29, 'n_datas': 232, 'train_loss_TCO-iter=1': 0.04741179943084717, 'train_loss_TCO': 0.04741179943084717, 'train_loss_total': 0.04741179943084717, 'train_grad_norm': 1.1218459606170654, 'epoch': 28}
0:00:25.611409 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.619123 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.150077 - iteration 0
0:00:26.369386 - vxvyvz tensor([[-0.0136,  0.0443,  0.1952]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.370405 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.371423 - dR tensor([[[ 0.1183,  0.5824, -0.8042],
         [ 0.8325,  0.3833,  0.4000],
         [ 0.5412, -0.7169, -0.4395]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.372304 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.375751 - k: tensor([[[ 0.1183,  0.5824, -0.8042, -0.0100],
         [ 0.8325,  0.3833,  0.4000,  0.0062],
         [ 0.5412, -0.7169, -0.4395,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.376675 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.377560 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.378681 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.379422 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.380065 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0473]
0:00:25.935938 - bracket_assembly_nut_noaug_coarse--479260
0:00:25.936173 - {'grad_norm': 1.1481130123138428, 'grad_norm_std': inf, 'learning_rate': 6.458333333333333e-10, 'time_forward': 0.056261539459228516, 'time_backward': 0.07908439636230469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269783.1061993, 'n_iterations': 30, 'n_datas': 240, 'train_loss_TCO-iter=1': 0.04725192114710808, 'train_loss_TCO': 0.04725192114710808, 'train_loss_total': 0.04725192114710808, 'train_grad_norm': 1.1481130123138428, 'epoch': 29}
0:00:25.936295 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.943998 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.475004 - iteration 0
0:00:26.694222 - vxvyvz tensor([[-0.0144,  0.0505,  0.1934]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.695292 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.696306 - dR tensor([[[ 0.1033,  0.5382, -0.8365],
         [ 0.8153,  0.4359,  0.3812],
         [ 0.5698, -0.7213, -0.3937]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.697137 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.700368 - k: tensor([[[ 0.1033,  0.5382, -0.8365, -0.0100],
         [ 0.8153,  0.4359,  0.3812,  0.0062],
         [ 0.5698, -0.7213, -0.3937,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.701816 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.702830 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.703468 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.704139 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.704751 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0477]
0:00:26.262672 - bracket_assembly_nut_noaug_coarse--479260
0:00:26.262898 - {'grad_norm': 1.0985040664672852, 'grad_norm_std': inf, 'learning_rate': 6.666666666666667e-10, 'time_forward': 0.0560908317565918, 'time_backward': 0.07905459403991699, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269783.4324481, 'n_iterations': 31, 'n_datas': 248, 'train_loss_TCO-iter=1': 0.04766831919550896, 'train_loss_TCO': 0.04766831919550896, 'train_loss_total': 0.04766831919550896, 'train_grad_norm': 1.0985040664672852, 'epoch': 30}
0:00:26.263042 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.270613 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.801556 - iteration 0
0:00:27.020874 - vxvyvz tensor([[-0.0176,  0.0465,  0.1898]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.021872 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.022867 - dR tensor([[[ 0.0991,  0.4871, -0.8677],
         [ 0.8286,  0.4425,  0.3430],
         [ 0.5510, -0.7530, -0.3597]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.023733 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.026959 - k: tensor([[[ 0.0991,  0.4871, -0.8677, -0.0100],
         [ 0.8286,  0.4425,  0.3430,  0.0062],
         [ 0.5510, -0.7530, -0.3597,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.027920 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.029430 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0569],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.030048 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.030661 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.031310 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0481]
0:00:26.584081 - bracket_assembly_nut_noaug_coarse--479260
0:00:26.584278 - {'grad_norm': 1.031589388847351, 'grad_norm_std': inf, 'learning_rate': 6.875000000000001e-10, 'time_forward': 0.056069374084472656, 'time_backward': 0.07874298095703125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269783.7572014, 'n_iterations': 32, 'n_datas': 256, 'train_loss_TCO-iter=1': 0.048132456839084625, 'train_loss_TCO': 0.048132456839084625, 'train_loss_total': 0.048132456839084625, 'train_grad_norm': 1.031589388847351, 'epoch': 31}
0:00:26.584391 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.591911 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.122873 - iteration 0
0:00:27.342208 - vxvyvz tensor([[-0.0097,  0.0450,  0.1934]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.343250 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.344256 - dR tensor([[[ 0.1333,  0.5430, -0.8291],
         [ 0.8306,  0.3951,  0.3924],
         [ 0.5406, -0.7410, -0.3984]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.345097 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.348326 - k: tensor([[[ 0.1333,  0.5430, -0.8291, -0.0100],
         [ 0.8306,  0.3951,  0.3924,  0.0062],
         [ 0.5406, -0.7410, -0.3984,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.349846 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.350863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.351493 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.352149 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.352796 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.80it/s, loss=0.0476]
0:00:26.920967 - bracket_assembly_nut_noaug_coarse--479260
0:00:26.921181 - {'grad_norm': 1.1432499885559082, 'grad_norm_std': inf, 'learning_rate': 7.083333333333334e-10, 'time_forward': 0.05617356300354004, 'time_backward': 0.0871114730834961, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269784.087157, 'n_iterations': 33, 'n_datas': 264, 'train_loss_TCO-iter=1': 0.04758121445775032, 'train_loss_TCO': 0.04758121445775032, 'train_loss_total': 0.04758121445775032, 'train_grad_norm': 1.1432499885559082, 'epoch': 32}
0:00:26.921365 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.928923 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.459887 - iteration 0
0:00:27.679288 - vxvyvz tensor([[-0.0074,  0.0495,  0.1944]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.680330 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.681286 - dR tensor([[[ 0.1269,  0.5612, -0.8179],
         [ 0.8254,  0.3976,  0.4008],
         [ 0.5501, -0.7259, -0.4128]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.682109 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.685340 - k: tensor([[[ 0.1269,  0.5612, -0.8179, -0.0100],
         [ 0.8254,  0.3976,  0.4008,  0.0062],
         [ 0.5501, -0.7259, -0.4128,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.686619 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.687891 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.688527 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.689131 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.689742 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0474]
0:00:27.248612 - bracket_assembly_nut_noaug_coarse--479260
0:00:27.248837 - {'grad_norm': 1.1570886373519897, 'grad_norm_std': inf, 'learning_rate': 7.291666666666667e-10, 'time_forward': 0.05614757537841797, 'time_backward': 0.07883381843566895, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269784.4157383, 'n_iterations': 34, 'n_datas': 272, 'train_loss_TCO-iter=1': 0.04742467775940895, 'train_loss_TCO': 0.04742467775940895, 'train_loss_total': 0.04742467775940895, 'train_grad_norm': 1.1570886373519897, 'epoch': 33}
0:00:27.248953 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.256545 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.787514 - iteration 0
0:00:28.009793 - vxvyvz tensor([[-0.0144,  0.0466,  0.1922]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.010851 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.011873 - dR tensor([[[ 0.0925,  0.5057, -0.8578],
         [ 0.8313,  0.4349,  0.3460],
         [ 0.5480, -0.7451, -0.3801]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.012747 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.015969 - k: tensor([[[ 0.0925,  0.5057, -0.8578, -0.0100],
         [ 0.8313,  0.4349,  0.3460,  0.0062],
         [ 0.5480, -0.7451, -0.3801,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.016965 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.018129 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.019097 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.019804 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.020424 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, loss=0.0478]
0:00:27.570817 - bracket_assembly_nut_noaug_coarse--479260
0:00:27.571072 - {'grad_norm': 1.118054986000061, 'grad_norm_std': inf, 'learning_rate': 7.500000000000001e-10, 'time_forward': 0.05918383598327637, 'time_backward': 0.07816791534423828, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269784.7457576, 'n_iterations': 35, 'n_datas': 280, 'train_loss_TCO-iter=1': 0.047844529151916504, 'train_loss_TCO': 0.047844529151916504, 'train_loss_total': 0.047844529151916504, 'train_grad_norm': 1.118054986000061, 'epoch': 34}
0:00:27.571200 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.578742 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.109725 - iteration 0
0:00:28.328830 - vxvyvz tensor([[-0.0138,  0.0412,  0.1890]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.329890 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.330874 - dR tensor([[[ 0.1215,  0.5603, -0.8193],
         [ 0.8270,  0.3993,  0.3957],
         [ 0.5489, -0.7257, -0.4148]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.331736 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.334939 - k: tensor([[[ 0.1215,  0.5603, -0.8193, -0.0100],
         [ 0.8270,  0.3993,  0.3957,  0.0062],
         [ 0.5489, -0.7257, -0.4148,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.336311 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.337515 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0567],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.338131 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.338748 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.339380 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.048]
0:00:27.889574 - bracket_assembly_nut_noaug_coarse--479260
0:00:27.889811 - {'grad_norm': 1.0696417093276978, 'grad_norm_std': inf, 'learning_rate': 7.708333333333334e-10, 'time_forward': 0.05589413642883301, 'time_backward': 0.0782320499420166, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269785.0646884, 'n_iterations': 36, 'n_datas': 288, 'train_loss_TCO-iter=1': 0.047954268753528595, 'train_loss_TCO': 0.047954268753528595, 'train_loss_total': 0.047954268753528595, 'train_grad_norm': 1.0696417093276978, 'epoch': 35}
0:00:27.889938 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.897580 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.428621 - iteration 0
0:00:28.647901 - vxvyvz tensor([[-0.0214,  0.0474,  0.1979]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.648970 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.649964 - dR tensor([[[ 0.0977,  0.5395, -0.8363],
         [ 0.8323,  0.4163,  0.3659],
         [ 0.5456, -0.7318, -0.4084]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.650820 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.654027 - k: tensor([[[ 0.0977,  0.5395, -0.8363, -0.0100],
         [ 0.8323,  0.4163,  0.3659,  0.0062],
         [ 0.5456, -0.7318, -0.4084,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.655633 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.656667 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0594],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.657299 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.657901 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.658503 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0471]
0:00:28.206902 - bracket_assembly_nut_noaug_coarse--479260
0:00:28.207118 - {'grad_norm': 1.1110432147979736, 'grad_norm_std': inf, 'learning_rate': 7.916666666666667e-10, 'time_forward': 0.05624556541442871, 'time_backward': 0.07841944694519043, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269785.384081, 'n_iterations': 37, 'n_datas': 296, 'train_loss_TCO-iter=1': 0.04710868000984192, 'train_loss_TCO': 0.04710868000984192, 'train_loss_total': 0.04710868000984192, 'train_grad_norm': 1.1110432147979736, 'epoch': 36}
0:00:28.207251 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:28.214811 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.745807 - iteration 0
0:00:28.965011 - vxvyvz tensor([[-0.0143,  0.0479,  0.1977]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.966075 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.967090 - dR tensor([[[ 0.0824,  0.5454, -0.8341],
         [ 0.8272,  0.4294,  0.3626],
         [ 0.5559, -0.7198, -0.4158]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.967966 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.971186 - k: tensor([[[ 0.0824,  0.5454, -0.8341, -0.0100],
         [ 0.8272,  0.4294,  0.3626,  0.0062],
         [ 0.5559, -0.7198, -0.4158,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.972193 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.973687 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0593],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.974325 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.974971 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.975586 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0472]
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0475]
0:00:28.854113 - bracket_assembly_nut_noaug_coarse--479260
0:00:28.854331 - {'grad_norm': 1.0423825979232788, 'grad_norm_std': inf, 'learning_rate': 8.333333333333334e-10, 'time_forward': 0.05633854866027832, 'time_backward': 0.07786154747009277, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269786.0305893, 'n_iterations': 39, 'n_datas': 312, 'train_loss_TCO-iter=1': 0.04749030992388725, 'train_loss_TCO': 0.04749030992388725, 'train_loss_total': 0.04749030992388725, 'train_grad_norm': 1.0423825979232788, 'epoch': 38}
0:00:28.854450 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:28.862010 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.392974 - iteration 0
0:00:29.612112 - vxvyvz tensor([[-0.0186,  0.0479,  0.1950]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:29.613109 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.614087 - dR tensor([[[ 0.0605,  0.5430, -0.8375],
         [ 0.8519,  0.4092,  0.3269],
         [ 0.5203, -0.7333, -0.4378]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:29.614951 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:29.618255 - k: tensor([[[ 0.0605,  0.5430, -0.8375, -0.0100],
         [ 0.8519,  0.4092,  0.3269,  0.0062],
         [ 0.5203, -0.7333, -0.4378,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.619273 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.620682 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0585],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.621378 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.622034 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.622642 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0473]
0:00:29.169736 - bracket_assembly_nut_noaug_coarse--479260
0:00:29.169950 - {'grad_norm': 1.0969820022583008, 'grad_norm_std': inf, 'learning_rate': 8.541666666666667e-10, 'time_forward': 0.05594134330749512, 'time_backward': 0.07840871810913086, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269786.3483963, 'n_iterations': 40, 'n_datas': 320, 'train_loss_TCO-iter=1': 0.0473332405090332, 'train_loss_TCO': 0.0473332405090332, 'train_loss_total': 0.0473332405090332, 'train_grad_norm': 1.0969820022583008, 'epoch': 39}
0:00:29.170141 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.177853 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.708896 - iteration 0
0:00:29.928206 - vxvyvz tensor([[-0.0205,  0.0443,  0.1943]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:29.929221 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.930251 - dR tensor([[[ 0.1008,  0.5674, -0.8173],
         [ 0.8243,  0.4124,  0.3879],
         [ 0.5572, -0.7127, -0.4261]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:29.931130 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:29.934410 - k: tensor([[[ 0.1008,  0.5674, -0.8173, -0.0100],
         [ 0.8243,  0.4124,  0.3879,  0.0062],
         [ 0.5572, -0.7127, -0.4261,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.935942 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.936989 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.937637 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.938243 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.938914 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0475]
0:00:29.497475 - bracket_assembly_nut_noaug_coarse--479260
0:00:29.497696 - {'grad_norm': 1.0413110256195068, 'grad_norm_std': inf, 'learning_rate': 8.75e-10, 'time_forward': 0.05634140968322754, 'time_backward': 0.07876062393188477, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269786.6649234, 'n_iterations': 41, 'n_datas': 328, 'train_loss_TCO-iter=1': 0.047457680106163025, 'train_loss_TCO': 0.047457680106163025, 'train_loss_total': 0.047457680106163025, 'train_grad_norm': 1.0413110256195068, 'epoch': 40}
0:00:29.497810 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.505332 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.036302 - iteration 0
0:00:30.255344 - vxvyvz tensor([[-0.0135,  0.0424,  0.1924]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.256386 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.257335 - dR tensor([[[ 0.0561,  0.5797, -0.8129],
         [ 0.8114,  0.4480,  0.3754],
         [ 0.5818, -0.6806, -0.4452]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.258159 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.261397 - k: tensor([[[ 0.0561,  0.5797, -0.8129, -0.0100],
         [ 0.8114,  0.4480,  0.3754,  0.0062],
         [ 0.5818, -0.6806, -0.4452,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.262987 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.264045 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.264658 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.265262 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.265866 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0476]
0:00:29.826629 - bracket_assembly_nut_noaug_coarse--479260
0:00:29.826826 - {'grad_norm': 1.0627394914627075, 'grad_norm_std': inf, 'learning_rate': 8.958333333333333e-10, 'time_forward': 0.05580854415893555, 'time_backward': 0.07822680473327637, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269786.9912589, 'n_iterations': 42, 'n_datas': 336, 'train_loss_TCO-iter=1': 0.047594714909791946, 'train_loss_TCO': 0.047594714909791946, 'train_loss_total': 0.047594714909791946, 'train_grad_norm': 1.0627394914627075, 'epoch': 41}
0:00:29.826959 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.834624 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.365740 - iteration 0
0:00:30.589119 - vxvyvz tensor([[-0.0142,  0.0476,  0.1920]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.590179 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.591240 - dR tensor([[[ 0.0977,  0.5521, -0.8280],
         [ 0.8506,  0.3855,  0.3574],
         [ 0.5166, -0.7393, -0.4320]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.592137 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.595410 - k: tensor([[[ 0.0977,  0.5521, -0.8280, -0.0100],
         [ 0.8506,  0.3855,  0.3574,  0.0062],
         [ 0.5166, -0.7393, -0.4320,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.597083 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.598026 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.598729 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.599362 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.600032 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.99it/s, loss=0.0476]
0:00:30.155813 - bracket_assembly_nut_noaug_coarse--479260
0:00:30.156082 - {'grad_norm': 1.135722041130066, 'grad_norm_std': inf, 'learning_rate': 9.166666666666666e-10, 'time_forward': 0.06070852279663086, 'time_backward': 0.07849001884460449, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269787.325744, 'n_iterations': 43, 'n_datas': 344, 'train_loss_TCO-iter=1': 0.04757673665881157, 'train_loss_TCO': 0.04757673665881157, 'train_loss_total': 0.04757673665881157, 'train_grad_norm': 1.135722041130066, 'epoch': 42}
0:00:30.156204 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:30.163923 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.694941 - iteration 0
0:00:30.914208 - vxvyvz tensor([[-0.0074,  0.0495,  0.1944]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.915239 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.916274 - dR tensor([[[ 0.1269,  0.5612, -0.8179],
         [ 0.8254,  0.3975,  0.4008],
         [ 0.5501, -0.7259, -0.4128]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.917097 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.920362 - k: tensor([[[ 0.1269,  0.5612, -0.8179, -0.0100],
         [ 0.8254,  0.3975,  0.4008,  0.0062],
         [ 0.5501, -0.7259, -0.4128,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.921964 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.923006 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.923672 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.924330 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.925018 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0474]
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0478]
0:00:31.121568 - bracket_assembly_nut_noaug_coarse--479260
0:00:31.121797 - {'grad_norm': 1.077850580215454, 'grad_norm_std': inf, 'learning_rate': 9.791666666666667e-10, 'time_forward': 0.05597949028015137, 'time_backward': 0.07857728004455566, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269788.2956245, 'n_iterations': 46, 'n_datas': 368, 'train_loss_TCO-iter=1': 0.047789882868528366, 'train_loss_TCO': 0.047789882868528366, 'train_loss_total': 0.047789882868528366, 'train_grad_norm': 1.077850580215454, 'epoch': 45}
0:00:31.121979 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.129558 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.660545 - iteration 0
0:00:31.879933 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:31.880936 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.881887 - dR tensor([[[ 0.1270,  0.5868, -0.7997],
         [ 0.8343,  0.3729,  0.4061],
         [ 0.5365, -0.7187, -0.4422]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:31.882732 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:31.885952 - k: tensor([[[ 0.1270,  0.5868, -0.7997, -0.0100],
         [ 0.8343,  0.3729,  0.4061,  0.0062],
         [ 0.5365, -0.7187, -0.4422,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.887537 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.888495 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.889113 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.889718 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.890319 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.047]
0:00:31.442141 - bracket_assembly_nut_noaug_coarse--479260
0:00:31.442362 - {'grad_norm': 1.1479883193969727, 'grad_norm_std': inf, 'learning_rate': 1e-09, 'time_forward': 0.05607104301452637, 'time_backward': 0.07809829711914062, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269788.6156206, 'n_iterations': 47, 'n_datas': 376, 'train_loss_TCO-iter=1': 0.0470079742372036, 'train_loss_TCO': 0.0470079742372036, 'train_loss_total': 0.0470079742372036, 'train_grad_norm': 1.1479883193969727, 'epoch': 46}
0:00:31.442482 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.450092 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.981005 - iteration 0
0:00:32.200355 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.201360 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.202352 - dR tensor([[[ 0.1270,  0.5869, -0.7997],
         [ 0.8343,  0.3729,  0.4061],
         [ 0.5365, -0.7187, -0.4423]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.203224 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.206476 - k: tensor([[[ 0.1270,  0.5869, -0.7997, -0.0100],
         [ 0.8343,  0.3729,  0.4061,  0.0062],
         [ 0.5365, -0.7187, -0.4423,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.207504 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.208493 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.209137 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.209800 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.210406 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.047]
0:00:31.760700 - bracket_assembly_nut_noaug_coarse--479260
0:00:31.760914 - {'grad_norm': 1.1469224691390991, 'grad_norm_std': inf, 'learning_rate': 1.0208333333333334e-09, 'time_forward': 0.05565452575683594, 'time_backward': 0.07921075820922852, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269788.936821, 'n_iterations': 48, 'n_datas': 384, 'train_loss_TCO-iter=1': 0.04698777198791504, 'train_loss_TCO': 0.04698777198791504, 'train_loss_total': 0.04698777198791504, 'train_grad_norm': 1.1469224691390991, 'epoch': 47}
0:00:31.761043 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.768610 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.299611 - iteration 0
0:00:32.518701 - vxvyvz tensor([[-0.0154,  0.0512,  0.1942]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.519755 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.520722 - dR tensor([[[ 0.1039,  0.5347, -0.8386],
         [ 0.8322,  0.4150,  0.3677],
         [ 0.5447, -0.7361, -0.4019]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.521643 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.524883 - k: tensor([[[ 0.1039,  0.5347, -0.8386, -0.0100],
         [ 0.8322,  0.4150,  0.3677,  0.0062],
         [ 0.5447, -0.7361, -0.4019,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.525884 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.526858 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.528022 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.528746 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.529365 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0475]
0:00:32.076794 - bracket_assembly_nut_noaug_coarse--479260
0:00:32.077001 - {'grad_norm': 1.1547274589538574, 'grad_norm_std': inf, 'learning_rate': 1.0416666666666667e-09, 'time_forward': 0.05608630180358887, 'time_backward': 0.07828402519226074, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269789.2548738, 'n_iterations': 49, 'n_datas': 392, 'train_loss_TCO-iter=1': 0.04751379042863846, 'train_loss_TCO': 0.04751379042863846, 'train_loss_total': 0.04751379042863846, 'train_grad_norm': 1.1547274589538574, 'epoch': 48}
0:00:32.077182 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.084806 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.615810 - iteration 0
0:00:32.835155 - vxvyvz tensor([[-0.0094,  0.0434,  0.1893]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.836220 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.837218 - dR tensor([[[ 0.1093,  0.5521, -0.8266],
         [ 0.8086,  0.4342,  0.3969],
         [ 0.5781, -0.7118, -0.3990]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.838050 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.841297 - k: tensor([[[ 0.1093,  0.5521, -0.8266, -0.0100],
         [ 0.8086,  0.4342,  0.3969,  0.0062],
         [ 0.5781, -0.7118, -0.3990,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.842863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.843946 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.844614 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.845222 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.845860 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0481]
0:00:32.398679 - bracket_assembly_nut_noaug_coarse--479260
0:00:32.398911 - {'grad_norm': 1.1021885871887207, 'grad_norm_std': inf, 'learning_rate': 1.0625e-09, 'time_forward': 0.056365251541137695, 'time_backward': 0.07924461364746094, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269789.5723398, 'n_iterations': 50, 'n_datas': 400, 'train_loss_TCO-iter=1': 0.04807358607649803, 'train_loss_TCO': 0.04807358607649803, 'train_loss_total': 0.04807358607649803, 'train_grad_norm': 1.1021885871887207, 'epoch': 49}
0:00:32.399052 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.406541 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.937535 - iteration 0
0:00:33.159846 - vxvyvz tensor([[-0.0159,  0.0458,  0.1994]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:33.160879 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.161864 - dR tensor([[[ 0.1318,  0.5450, -0.8280],
         [ 0.8337,  0.3910,  0.3901],
         [ 0.5363, -0.7417, -0.4028]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:33.162695 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:33.165944 - k: tensor([[[ 0.1318,  0.5450, -0.8280, -0.0100],
         [ 0.8337,  0.3910,  0.3901,  0.0062],
         [ 0.5363, -0.7417, -0.4028,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.166880 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.168351 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0598],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.169051 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.169658 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.170262 - k: tensor([0.0441], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                         | 0/1 [00:00<?, ?it/s, loss=0.047]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')s, loss=0.0478]
0:00:33.638111 - iteration 0
0:00:33.857397 - vxvyvz tensor([[-0.0116,  0.0521,  0.1918]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:33.858421 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.859413 - dR tensor([[[ 0.1053,  0.5849, -0.8042],
         [ 0.8499,  0.3670,  0.3782],
         [ 0.5164, -0.7233, -0.4584]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:33.860307 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:33.863541 - k: tensor([[[ 0.1053,  0.5849, -0.8042, -0.0100],
         [ 0.8499,  0.3670,  0.3782,  0.0062],
         [ 0.5164, -0.7233, -0.4584,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.865149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.866173 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.866812 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.867431 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.868096 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0475]
0:00:33.420725 - bracket_assembly_nut_noaug_coarse--479260
0:00:33.420964 - {'grad_norm': 1.1092348098754883, 'grad_norm_std': inf, 'learning_rate': 1.125e-09, 'time_forward': 0.05640053749084473, 'time_backward': 0.07884478569030762, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269790.5941062, 'n_iterations': 53, 'n_datas': 424, 'train_loss_TCO-iter=1': 0.0475090928375721, 'train_loss_TCO': 0.0475090928375721, 'train_loss_total': 0.0475090928375721, 'train_grad_norm': 1.1092348098754883, 'epoch': 52}
0:00:33.421077 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:33.428830 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.959883 - iteration 0
0:00:34.179071 - vxvyvz tensor([[-0.0161,  0.0509,  0.1896]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.180121 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.181092 - dR tensor([[[ 0.1004,  0.5333, -0.8400],
         [ 0.8173,  0.4373,  0.3753],
         [ 0.5674, -0.7241, -0.3920]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.181915 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.185191 - k: tensor([[[ 0.1004,  0.5333, -0.8400, -0.0100],
         [ 0.8173,  0.4373,  0.3753,  0.0062],
         [ 0.5674, -0.7241, -0.3920,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.186759 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.187764 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0569],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.188447 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.189071 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.189672 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0481]
0:00:33.740853 - bracket_assembly_nut_noaug_coarse--479260
0:00:33.741048 - {'grad_norm': 1.095866322517395, 'grad_norm_std': inf, 'learning_rate': 1.1458333333333333e-09, 'time_forward': 0.05621814727783203, 'time_backward': 0.07919025421142578, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269790.916027, 'n_iterations': 54, 'n_datas': 432, 'train_loss_TCO-iter=1': 0.0480705201625824, 'train_loss_TCO': 0.0480705201625824, 'train_loss_total': 0.0480705201625824, 'train_grad_norm': 1.095866322517395, 'epoch': 53}
0:00:33.741163 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:33.748624 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.279581 - iteration 0
0:00:34.498844 - vxvyvz tensor([[-0.0171,  0.0443,  0.1906]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.499881 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.500837 - dR tensor([[[ 0.1301,  0.5329, -0.8361],
         [ 0.8202,  0.4160,  0.3927],
         [ 0.5571, -0.7369, -0.3830]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.501677 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.504950 - k: tensor([[[ 0.1301,  0.5329, -0.8361, -0.0100],
         [ 0.8202,  0.4160,  0.3927,  0.0062],
         [ 0.5571, -0.7369, -0.3830,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.506592 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.507622 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.508306 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.508923 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.509541 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, loss=0.048]
0:00:34.065720 - bracket_assembly_nut_noaug_coarse--479260
0:00:34.065928 - {'grad_norm': 1.0622150897979736, 'grad_norm_std': inf, 'learning_rate': 1.1666666666666668e-09, 'time_forward': 0.056224822998046875, 'time_backward': 0.08130836486816406, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269791.237948, 'n_iterations': 55, 'n_datas': 440, 'train_loss_TCO-iter=1': 0.047952063381671906, 'train_loss_TCO': 0.047952063381671906, 'train_loss_total': 0.047952063381671906, 'train_grad_norm': 1.0622150897979736, 'epoch': 54}
0:00:34.066044 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:34.073515 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.604475 - iteration 0
0:00:34.823745 - vxvyvz tensor([[-0.0132,  0.0542,  0.1894]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.824781 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.825737 - dR tensor([[[ 0.1314,  0.5129, -0.8484],
         [ 0.8311,  0.4096,  0.3763],
         [ 0.5404, -0.7545, -0.3724]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.826564 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.829799 - k: tensor([[[ 0.1314,  0.5129, -0.8484, -0.0100],
         [ 0.8311,  0.4096,  0.3763,  0.0062],
         [ 0.5404, -0.7545, -0.3724,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.831337 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.832403 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.833043 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.833648 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.834252 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0481]
0:00:34.386630 - bracket_assembly_nut_noaug_coarse--479260
0:00:34.386837 - {'grad_norm': 1.027013897895813, 'grad_norm_std': inf, 'learning_rate': 1.1874999999999999e-09, 'time_forward': 0.056053876876831055, 'time_backward': 0.0788271427154541, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269791.5602627, 'n_iterations': 56, 'n_datas': 448, 'train_loss_TCO-iter=1': 0.0480940043926239, 'train_loss_TCO': 0.0480940043926239, 'train_loss_total': 0.0480940043926239, 'train_grad_norm': 1.027013897895813, 'epoch': 55}
0:00:34.387051 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:34.394615 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.925628 - iteration 0
0:00:35.144751 - vxvyvz tensor([[-0.0193,  0.0501,  0.1881]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:35.145767 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:35.146762 - dR tensor([[[ 0.0757,  0.4875, -0.8698],
         [ 0.8343,  0.4468,  0.3230],
         [ 0.5461, -0.7501, -0.3729]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:35.147610 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:35.150820 - k: tensor([[[ 0.0757,  0.4875, -0.8698, -0.0100],
         [ 0.8343,  0.4468,  0.3230,  0.0062],
         [ 0.5461, -0.7501, -0.3729,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.152335 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.153367 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0564],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.153987 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.154592 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.155230 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0483]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')s, loss=0.0478]
0:00:35.882346 - iteration 0
0:00:36.101317 - vxvyvz tensor([[-0.0094,  0.0434,  0.1893]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.102331 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.103328 - dR tensor([[[ 0.1092,  0.5522, -0.8265],
         [ 0.8086,  0.4342,  0.3969],
         [ 0.5781, -0.7118, -0.3991]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.104204 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.107418 - k: tensor([[[ 0.1092,  0.5522, -0.8265, -0.0100],
         [ 0.8086,  0.4342,  0.3969,  0.0062],
         [ 0.5781, -0.7118, -0.3991,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.108935 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.109941 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.110556 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.111199 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.111842 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.048]
0:00:35.660243 - bracket_assembly_nut_noaug_coarse--479260
0:00:35.660458 - {'grad_norm': 1.101449728012085, 'grad_norm_std': inf, 'learning_rate': 1.2708333333333333e-09, 'time_forward': 0.05573534965515137, 'time_backward': 0.07812833786010742, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269792.8370776, 'n_iterations': 60, 'n_datas': 480, 'train_loss_TCO-iter=1': 0.04804185405373573, 'train_loss_TCO': 0.04804185405373573, 'train_loss_total': 0.04804185405373573, 'train_grad_norm': 1.101449728012085, 'epoch': 59}
0:00:35.660631 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:35.668273 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.199231 - iteration 0
0:00:36.418960 - vxvyvz tensor([[-0.0163,  0.0483,  0.1962]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.420037 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.420993 - dR tensor([[[ 0.1289,  0.5640, -0.8157],
         [ 0.8190,  0.4033,  0.4082],
         [ 0.5592, -0.7206, -0.4099]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.421831 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.425058 - k: tensor([[[ 0.1289,  0.5640, -0.8157, -0.0100],
         [ 0.8190,  0.4033,  0.4082,  0.0062],
         [ 0.5592, -0.7206, -0.4099,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.426521 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.427588 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.428241 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.428861 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.429477 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.0473]
0:00:35.983782 - bracket_assembly_nut_noaug_coarse--479260
0:00:35.984021 - {'grad_norm': 1.0510424375534058, 'grad_norm_std': inf, 'learning_rate': 1.2916666666666667e-09, 'time_forward': 0.056543588638305664, 'time_backward': 0.07926106452941895, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269793.157722, 'n_iterations': 61, 'n_datas': 488, 'train_loss_TCO-iter=1': 0.04728209227323532, 'train_loss_TCO': 0.04728209227323532, 'train_loss_total': 0.04728209227323532, 'train_grad_norm': 1.0510424375534058, 'epoch': 60}
0:00:35.984156 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:35.991827 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.522792 - iteration 0
0:00:36.742005 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.743044 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.744054 - dR tensor([[[ 0.1269,  0.5869, -0.7996],
         [ 0.8343,  0.3728,  0.4061],
         [ 0.5365, -0.7187, -0.4424]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.744908 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.748164 - k: tensor([[[ 0.1269,  0.5869, -0.7996, -0.0100],
         [ 0.8343,  0.3728,  0.4061,  0.0062],
         [ 0.5365, -0.7187, -0.4424,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.749119 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.750628 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.751290 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.751937 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.752557 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.047]
0:00:36.300717 - bracket_assembly_nut_noaug_coarse--479260
0:00:36.300931 - {'grad_norm': 1.148165225982666, 'grad_norm_std': inf, 'learning_rate': 1.3125e-09, 'time_forward': 0.056067705154418945, 'time_backward': 0.07778263092041016, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269793.4776905, 'n_iterations': 62, 'n_datas': 496, 'train_loss_TCO-iter=1': 0.047008294612169266, 'train_loss_TCO': 0.047008294612169266, 'train_loss_total': 0.047008294612169266, 'train_grad_norm': 1.148165225982666, 'epoch': 61}
0:00:36.301036 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:36.308561 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.839604 - iteration 0
0:00:37.058516 - vxvyvz tensor([[-0.0153,  0.0534,  0.1874]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:37.059572 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:37.060573 - dR tensor([[[ 0.1071,  0.5332, -0.8392],
         [ 0.8286,  0.4186,  0.3717],
         [ 0.5495, -0.7351, -0.3970]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:37.061398 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:37.064633 - k: tensor([[[ 0.1071,  0.5332, -0.8392, -0.0100],
         [ 0.8286,  0.4186,  0.3717,  0.0062],
         [ 0.5495, -0.7351, -0.3970,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.065591 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.067122 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0562],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.067778 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.068416 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.069051 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0482]
0:00:36.618336 - bracket_assembly_nut_noaug_coarse--479260
0:00:36.618556 - {'grad_norm': 1.116329312324524, 'grad_norm_std': inf, 'learning_rate': 1.3333333333333335e-09, 'time_forward': 0.05583357810974121, 'time_backward': 0.07740283012390137, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269793.7935097, 'n_iterations': 63, 'n_datas': 504, 'train_loss_TCO-iter=1': 0.04821063578128815, 'train_loss_TCO': 0.04821063578128815, 'train_loss_total': 0.04821063578128815, 'train_grad_norm': 1.116329312324524, 'epoch': 62}
0:00:36.618672 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:36.626211 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:37.157215 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0584],], device='cuda:0')s, loss=0.0478]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.021265 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.021868 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.022470 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0475]
0:00:37.589568 - bracket_assembly_nut_noaug_coarse--479260
0:00:37.589787 - {'grad_norm': 1.1312949657440186, 'grad_norm_std': inf, 'learning_rate': 1.3958333333333334e-09, 'time_forward': 0.05607461929321289, 'time_backward': 0.07782220840454102, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269794.7474754, 'n_iterations': 66, 'n_datas': 528, 'train_loss_TCO-iter=1': 0.04753702133893967, 'train_loss_TCO': 0.04753702133893967, 'train_loss_total': 0.04753702133893967, 'train_grad_norm': 1.1312949657440186, 'epoch': 65}
0:00:37.589901 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:37.597570 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.128598 - iteration 0
0:00:38.347846 - vxvyvz tensor([[-0.0222,  0.0503,  0.1874]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:38.348861 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.349823 - dR tensor([[[ 0.0704,  0.5486, -0.8331],
         [ 0.8340,  0.4258,  0.3509],
         [ 0.5472, -0.7196, -0.4275]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:38.350651 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:38.353901 - k: tensor([[[ 0.0704,  0.5486, -0.8331, -0.0100],
         [ 0.8340,  0.4258,  0.3509,  0.0062],
         [ 0.5472, -0.7196, -0.4275,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.355407 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.356433 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0562],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.357070 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.357679 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.358284 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0481]
0:00:37.913861 - bracket_assembly_nut_noaug_coarse--479260
0:00:37.914075 - {'grad_norm': 1.0277386903762817, 'grad_norm_std': inf, 'learning_rate': 1.4166666666666667e-09, 'time_forward': 0.056054115295410156, 'time_backward': 0.07900047302246094, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269795.0844913, 'n_iterations': 67, 'n_datas': 536, 'train_loss_TCO-iter=1': 0.048117030411958694, 'train_loss_TCO': 0.048117030411958694, 'train_loss_total': 0.048117030411958694, 'train_grad_norm': 1.0277386903762817, 'epoch': 66}
0:00:37.914182 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:37.921792 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.452813 - iteration 0
0:00:38.672184 - vxvyvz tensor([[-0.0086,  0.0513,  0.1931]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:38.673202 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.674198 - dR tensor([[[ 0.0909,  0.5613, -0.8226],
         [ 0.8310,  0.4125,  0.3733],
         [ 0.5489, -0.7175, -0.4289]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:38.675064 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:38.678254 - k: tensor([[[ 0.0909,  0.5613, -0.8226, -0.0100],
         [ 0.8310,  0.4125,  0.3733,  0.0062],
         [ 0.5489, -0.7175, -0.4289,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.679201 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.680139 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.680768 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.681372 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.681975 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0475]
0:00:38.236610 - bracket_assembly_nut_noaug_coarse--479260
0:00:38.236828 - {'grad_norm': 1.0957642793655396, 'grad_norm_std': inf, 'learning_rate': 1.4375e-09, 'time_forward': 0.055498600006103516, 'time_backward': 0.0793149471282959, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269795.4085221, 'n_iterations': 68, 'n_datas': 544, 'train_loss_TCO-iter=1': 0.04751913994550705, 'train_loss_TCO': 0.04751913994550705, 'train_loss_total': 0.04751913994550705, 'train_grad_norm': 1.0957642793655396, 'epoch': 67}
0:00:38.236939 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:38.244609 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.775723 - iteration 0
0:00:38.995945 - vxvyvz tensor([[-0.0174,  0.0457,  0.1915]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:38.996995 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.997957 - dR tensor([[[ 0.1034,  0.5466, -0.8310],
         [ 0.8309,  0.4118,  0.3743],
         [ 0.5467, -0.7292, -0.4116]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:38.998820 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:39.002069 - k: tensor([[[ 0.1034,  0.5466, -0.8310, -0.0100],
         [ 0.8309,  0.4118,  0.3743,  0.0062],
         [ 0.5467, -0.7292, -0.4116,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.003558 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.004538 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0575],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.005184 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.005792 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.006404 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.0478]
0:00:38.556439 - bracket_assembly_nut_noaug_coarse--479260
0:00:38.556658 - {'grad_norm': 1.0850605964660645, 'grad_norm_std': inf, 'learning_rate': 1.4583333333333334e-09, 'time_forward': 0.05717778205871582, 'time_backward': 0.07879877090454102, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269795.732429, 'n_iterations': 69, 'n_datas': 552, 'train_loss_TCO-iter=1': 0.04777650535106659, 'train_loss_TCO': 0.04777650535106659, 'train_loss_total': 0.04777650535106659, 'train_grad_norm': 1.0850605964660645, 'epoch': 68}
0:00:38.556774 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:38.564328 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:39.095281 - iteration 0
0:00:39.314485 - vxvyvz tensor([[-0.0192,  0.0475,  0.1961]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:39.315543 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:39.316556 - dR tensor([[[ 0.1145,  0.5548, -0.8241],
         [ 0.8249,  0.4091,  0.3900],
         [ 0.5535, -0.7244, -0.4108]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:39.317376 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:39.320617 - k: tensor([[[ 0.1145,  0.5548, -0.8241, -0.0100],
         [ 0.8249,  0.4091,  0.3900,  0.0062],
         [ 0.5535, -0.7244, -0.4108,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.321530 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.323059 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0588],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.323782 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.324405 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.325037 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0473]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0478]
       grad_fn=<CopySlices>)
0:00:40.290489 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.291532 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.292188 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.292794 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.293394 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0476]
0:00:39.841307 - bracket_assembly_nut_noaug_coarse--479260
0:00:39.841522 - {'grad_norm': 1.1483312845230103, 'grad_norm_std': inf, 'learning_rate': 1.5416666666666668e-09, 'time_forward': 0.056142568588256836, 'time_backward': 0.07778716087341309, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269797.0182867, 'n_iterations': 73, 'n_datas': 584, 'train_loss_TCO-iter=1': 0.04755961894989014, 'train_loss_TCO': 0.04755961894989014, 'train_loss_total': 0.04755961894989014, 'train_grad_norm': 1.1483312845230103, 'epoch': 72}
0:00:39.841702 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:39.849385 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.380479 - iteration 0
0:00:40.599818 - vxvyvz tensor([[-0.0156,  0.0507,  0.1941]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:40.600831 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.601790 - dR tensor([[[ 0.0854,  0.5574, -0.8258],
         [ 0.8226,  0.4281,  0.3741],
         [ 0.5621, -0.7113, -0.4220]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:40.602619 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:40.605836 - k: tensor([[[ 0.0854,  0.5574, -0.8258, -0.0100],
         [ 0.8226,  0.4281,  0.3741,  0.0062],
         [ 0.5621, -0.7113, -0.4220,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.607354 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.608375 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.609013 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.609628 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.610230 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0475]
0:00:40.161434 - bracket_assembly_nut_noaug_coarse--479260
0:00:40.161654 - {'grad_norm': 1.0714788436889648, 'grad_norm_std': inf, 'learning_rate': 1.5625000000000001e-09, 'time_forward': 0.056282758712768555, 'time_backward': 0.07764339447021484, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269797.335067, 'n_iterations': 74, 'n_datas': 592, 'train_loss_TCO-iter=1': 0.04747958853840828, 'train_loss_TCO': 0.04747958853840828, 'train_loss_total': 0.04747958853840828, 'train_grad_norm': 1.0714788436889648, 'epoch': 73}
0:00:40.161761 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:40.169360 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.700338 - iteration 0
0:00:40.919531 - vxvyvz tensor([[-0.0156,  0.0507,  0.1941]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:40.920566 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.921569 - dR tensor([[[ 0.0854,  0.5574, -0.8258],
         [ 0.8226,  0.4281,  0.3741],
         [ 0.5621, -0.7113, -0.4220]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:40.922399 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:40.925625 - k: tensor([[[ 0.0854,  0.5574, -0.8258, -0.0100],
         [ 0.8226,  0.4281,  0.3741,  0.0062],
         [ 0.5621, -0.7113, -0.4220,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.926550 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.928103 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.928725 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.929330 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.929933 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0475]
0:00:40.479711 - bracket_assembly_nut_noaug_coarse--479260
0:00:40.479911 - {'grad_norm': 1.0711414813995361, 'grad_norm_std': inf, 'learning_rate': 1.5833333333333334e-09, 'time_forward': 0.05584120750427246, 'time_backward': 0.07776427268981934, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269797.654964, 'n_iterations': 75, 'n_datas': 600, 'train_loss_TCO-iter=1': 0.047470126301050186, 'train_loss_TCO': 0.047470126301050186, 'train_loss_total': 0.047470126301050186, 'train_grad_norm': 1.0711414813995361, 'epoch': 74}
0:00:40.480111 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:40.487563 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:41.018538 - iteration 0
0:00:41.237641 - vxvyvz tensor([[-0.0137,  0.0513,  0.1976]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:41.238679 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:41.239677 - dR tensor([[[ 0.0986,  0.5161, -0.8508],
         [ 0.8392,  0.4164,  0.3498],
         [ 0.5349, -0.7485, -0.3920]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:41.240544 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:41.244012 - k: tensor([[[ 0.0986,  0.5161, -0.8508, -0.0100],
         [ 0.8392,  0.4164,  0.3498,  0.0062],
         [ 0.5349, -0.7485, -0.3920,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.245476 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.246442 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0593],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.247079 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:41.247683 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:41.248307 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0478]
0:00:42.214756 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.216278 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0566],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.216898 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.217507 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.218110 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.048]
0:00:41.768597 - bracket_assembly_nut_noaug_coarse--479260
0:00:41.768813 - {'grad_norm': 1.0558276176452637, 'grad_norm_std': inf, 'learning_rate': 1.6666666666666667e-09, 'time_forward': 0.055493831634521484, 'time_backward': 0.07808232307434082, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269798.9433916, 'n_iterations': 79, 'n_datas': 632, 'train_loss_TCO-iter=1': 0.04804490879178047, 'train_loss_TCO': 0.04804490879178047, 'train_loss_total': 0.04804490879178047, 'train_grad_norm': 1.0558276176452637, 'epoch': 78}
0:00:41.768925 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:41.776420 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.307369 - iteration 0
0:00:42.526512 - vxvyvz tensor([[-0.0136,  0.0443,  0.1952]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:42.527568 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.528557 - dR tensor([[[ 0.1182,  0.5826, -0.8041],
         [ 0.8326,  0.3831,  0.3999],
         [ 0.5411, -0.7168, -0.4399]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:42.529393 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:42.532609 - k: tensor([[[ 0.1182,  0.5826, -0.8041, -0.0100],
         [ 0.8326,  0.3831,  0.3999,  0.0062],
         [ 0.5411, -0.7168, -0.4399,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.534113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.535143 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.535809 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.536426 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.537070 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0473]
0:00:42.086694 - bracket_assembly_nut_noaug_coarse--479260
0:00:42.086955 - {'grad_norm': 1.1486080884933472, 'grad_norm_std': inf, 'learning_rate': 1.6875e-09, 'time_forward': 0.05600237846374512, 'time_backward': 0.07749056816101074, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269799.2617598, 'n_iterations': 80, 'n_datas': 640, 'train_loss_TCO-iter=1': 0.04727041721343994, 'train_loss_TCO': 0.04727041721343994, 'train_loss_total': 0.04727041721343994, 'train_grad_norm': 1.1486080884933472, 'epoch': 79}
0:00:42.087078 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.094700 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.625670 - iteration 0
0:00:42.844785 - vxvyvz tensor([[-0.0124,  0.0452,  0.1973]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:42.845792 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.846755 - dR tensor([[[ 0.1269,  0.5870, -0.7996],
         [ 0.8344,  0.3727,  0.4061],
         [ 0.5364, -0.7186, -0.4425]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:42.847614 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:42.850823 - k: tensor([[[ 0.1269,  0.5870, -0.7996, -0.0100],
         [ 0.8344,  0.3727,  0.4061,  0.0062],
         [ 0.5364, -0.7186, -0.4425,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.851765 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.853256 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.853875 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.854491 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.855137 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.047]
0:00:42.404974 - bracket_assembly_nut_noaug_coarse--479260
0:00:42.405191 - {'grad_norm': 1.1479861736297607, 'grad_norm_std': inf, 'learning_rate': 1.7083333333333333e-09, 'time_forward': 0.055718183517456055, 'time_backward': 0.07790064811706543, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269799.5802243, 'n_iterations': 81, 'n_datas': 648, 'train_loss_TCO-iter=1': 0.0470193587243557, 'train_loss_TCO': 0.0470193587243557, 'train_loss_total': 0.0470193587243557, 'train_grad_norm': 1.1479861736297607, 'epoch': 80}
0:00:42.405326 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.412862 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.943862 - iteration 0
0:00:43.162936 - vxvyvz tensor([[-0.0088,  0.0508,  0.1958]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:43.163980 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.164957 - dR tensor([[[ 0.1145,  0.5156, -0.8491],
         [ 0.8285,  0.4221,  0.3680],
         [ 0.5481, -0.7457, -0.3788]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:43.165780 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:43.168984 - k: tensor([[[ 0.1145,  0.5156, -0.8491, -0.0100],
         [ 0.8285,  0.4221,  0.3680,  0.0062],
         [ 0.5481, -0.7457, -0.3788,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.170466 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.171448 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0588],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.172101 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.172721 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.173339 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0475]
0:00:42.720661 - bracket_assembly_nut_noaug_coarse--479260
0:00:42.720881 - {'grad_norm': 1.097525715827942, 'grad_norm_std': inf, 'learning_rate': 1.7291666666666666e-09, 'time_forward': 0.055832624435424805, 'time_backward': 0.07784843444824219, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269799.8983312, 'n_iterations': 82, 'n_datas': 656, 'train_loss_TCO-iter=1': 0.04746311157941818, 'train_loss_TCO': 0.04746311157941818, 'train_loss_total': 0.04746311157941818, 'train_grad_norm': 1.097525715827942, 'epoch': 81}
0:00:42.720995 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.728586 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.259623 - iteration 0
0:00:43.478683 - vxvyvz tensor([[-0.0106,  0.0514,  0.1937]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:43.479755 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.480733 - dR tensor([[[ 0.0938,  0.5330, -0.8409],
         [ 0.8168,  0.4418,  0.3711],
         [ 0.5693, -0.7216, -0.3939]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:43.481558 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:43.484771 - k: tensor([[[ 0.0938,  0.5330, -0.8409, -0.0100],
         [ 0.8168,  0.4418,  0.3711,  0.0062],
         [ 0.5693, -0.7216, -0.3939,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.486227 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.487280 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.487932 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.488552 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.489172 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0476]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0478]
       grad_fn=<CopySlices>)
0:00:44.469183 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.470748 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.471400 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.472042 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.472660 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0477]
0:00:44.026711 - bracket_assembly_nut_noaug_coarse--479260
0:00:44.026957 - {'grad_norm': 1.0871220827102661, 'grad_norm_std': inf, 'learning_rate': 1.8125e-09, 'time_forward': 0.05582833290100098, 'time_backward': 0.07780957221984863, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269801.1975563, 'n_iterations': 86, 'n_datas': 688, 'train_loss_TCO-iter=1': 0.04767158627510071, 'train_loss_TCO': 0.04767158627510071, 'train_loss_total': 0.04767158627510071, 'train_grad_norm': 1.0871220827102661, 'epoch': 85}
0:00:44.027078 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:44.034626 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.565659 - iteration 0
0:00:44.784708 - vxvyvz tensor([[-0.0221,  0.0494,  0.2019]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:44.785747 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.786750 - dR tensor([[[ 0.0905,  0.5340, -0.8406],
         [ 0.8236,  0.4344,  0.3647],
         [ 0.5599, -0.7253, -0.4005]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:44.787612 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:44.790788 - k: tensor([[[ 0.0905,  0.5340, -0.8406, -0.0100],
         [ 0.8236,  0.4344,  0.3647,  0.0062],
         [ 0.5599, -0.7253, -0.4005,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.792345 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.793356 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0606],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.793994 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.794610 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.795237 - k: tensor([0.0438], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0468]
0:00:44.351491 - bracket_assembly_nut_noaug_coarse--479260
0:00:44.351708 - {'grad_norm': 1.087934970855713, 'grad_norm_std': inf, 'learning_rate': 1.8333333333333332e-09, 'time_forward': 0.055863380432128906, 'time_backward': 0.07777261734008789, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269801.520219, 'n_iterations': 87, 'n_datas': 696, 'train_loss_TCO-iter=1': 0.04676993936300278, 'train_loss_TCO': 0.04676993936300278, 'train_loss_total': 0.04676993936300278, 'train_grad_norm': 1.087934970855713, 'epoch': 86}
0:00:44.351824 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:44.359348 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.890369 - iteration 0
0:00:45.110256 - vxvyvz tensor([[-0.0152,  0.0482,  0.1920]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:45.111331 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.112339 - dR tensor([[[ 0.0957,  0.5866, -0.8042],
         [ 0.8197,  0.4118,  0.3980],
         [ 0.5647, -0.6973, -0.4415]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:45.113169 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:45.116367 - k: tensor([[[ 0.0957,  0.5866, -0.8042, -0.0100],
         [ 0.8197,  0.4118,  0.3980,  0.0062],
         [ 0.5647, -0.6973, -0.4415,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.117311 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.118890 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.119539 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.120183 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.120786 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0476]
0:00:44.676640 - bracket_assembly_nut_noaug_coarse--479260
0:00:44.676859 - {'grad_norm': 1.159358024597168, 'grad_norm_std': inf, 'learning_rate': 1.854166666666667e-09, 'time_forward': 0.056732177734375, 'time_backward': 0.07736515998840332, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269801.8452241, 'n_iterations': 88, 'n_datas': 704, 'train_loss_TCO-iter=1': 0.04763771593570709, 'train_loss_TCO': 0.04763771593570709, 'train_loss_total': 0.04763771593570709, 'train_grad_norm': 1.159358024597168, 'epoch': 87}
0:00:44.676972 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:44.684536 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.215538 - iteration 0
0:00:45.434546 - vxvyvz tensor([[-0.0205,  0.0501,  0.1911]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:45.435600 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.436619 - dR tensor([[[ 0.1203,  0.5441, -0.8304],
         [ 0.8382,  0.3924,  0.3786],
         [ 0.5319, -0.7416, -0.4089]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:45.437441 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:45.440655 - k: tensor([[[ 0.1203,  0.5441, -0.8304, -0.0100],
         [ 0.8382,  0.3924,  0.3786,  0.0062],
         [ 0.5319, -0.7416, -0.4089,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.442112 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.443190 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0573],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.443858 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.444478 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.445079 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0478]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0478]
0:00:46.397438 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.398416 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.399070 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.399687 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.400323 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.047]
0:00:45.949962 - bracket_assembly_nut_noaug_coarse--479260
0:00:45.950185 - {'grad_norm': 1.0040665864944458, 'grad_norm_std': inf, 'learning_rate': 1.9375e-09, 'time_forward': 0.05588579177856445, 'time_backward': 0.07807540893554688, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269803.1255937, 'n_iterations': 92, 'n_datas': 736, 'train_loss_TCO-iter=1': 0.046959083527326584, 'train_loss_TCO': 0.046959083527326584, 'train_loss_total': 0.046959083527326584, 'train_grad_norm': 1.0040665864944458, 'epoch': 91}
0:00:45.950297 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:45.957914 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.488897 - iteration 0
0:00:46.707995 - vxvyvz tensor([[-0.0137,  0.0525,  0.1854]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:46.709012 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.710019 - dR tensor([[[ 0.1301,  0.5321, -0.8366],
         [ 0.8339,  0.3978,  0.3827],
         [ 0.5364, -0.7474, -0.3919]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:46.710881 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:46.714104 - k: tensor([[[ 0.1301,  0.5321, -0.8366, -0.0100],
         [ 0.8339,  0.3978,  0.3827,  0.0062],
         [ 0.5364, -0.7474, -0.3919,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.715288 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.716651 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0556],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.717271 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.717873 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.718474 - k: tensor([0.0454], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0484]
0:00:46.268772 - bracket_assembly_nut_noaug_coarse--479260
0:00:46.268989 - {'grad_norm': 1.0199775695800781, 'grad_norm_std': inf, 'learning_rate': 1.9583333333333335e-09, 'time_forward': 0.05587935447692871, 'time_backward': 0.07919883728027344, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269803.4448335, 'n_iterations': 93, 'n_datas': 744, 'train_loss_TCO-iter=1': 0.04840397089719772, 'train_loss_TCO': 0.04840397089719772, 'train_loss_total': 0.04840397089719772, 'train_grad_norm': 1.0199775695800781, 'epoch': 92}
0:00:46.269103 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:46.276597 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.807570 - iteration 0
0:00:47.026976 - vxvyvz tensor([[-0.0135,  0.0443,  0.1952]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:47.028019 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:47.028989 - dR tensor([[[ 0.1181,  0.5827, -0.8040],
         [ 0.8327,  0.3830,  0.3999],
         [ 0.5410, -0.7167, -0.4400]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:47.029840 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:47.033119 - k: tensor([[[ 0.1181,  0.5827, -0.8040, -0.0100],
         [ 0.8327,  0.3830,  0.3999,  0.0062],
         [ 0.5410, -0.7167, -0.4400,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.034048 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.035572 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.036229 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.036834 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.037433 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0472]
0:00:46.585139 - bracket_assembly_nut_noaug_coarse--479260
0:00:46.585351 - {'grad_norm': 1.147312045097351, 'grad_norm_std': inf, 'learning_rate': 1.9791666666666666e-09, 'time_forward': 0.056188106536865234, 'time_backward': 0.0789186954498291, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269803.763432, 'n_iterations': 94, 'n_datas': 752, 'train_loss_TCO-iter=1': 0.04723436012864113, 'train_loss_TCO': 0.04723436012864113, 'train_loss_total': 0.04723436012864113, 'train_grad_norm': 1.147312045097351, 'epoch': 93}
0:00:46.585471 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:46.593138 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:47.124189 - iteration 0
0:00:47.343441 - vxvyvz tensor([[-0.0074,  0.0495,  0.1944]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:47.344465 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:47.345426 - dR tensor([[[ 0.1267,  0.5616, -0.8177],
         [ 0.8255,  0.3973,  0.4008],
         [ 0.5499, -0.7258, -0.4132]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:47.346253 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:47.349543 - k: tensor([[[ 0.1267,  0.5616, -0.8177, -0.0100],
         [ 0.8255,  0.3973,  0.4008,  0.0062],
         [ 0.5499, -0.7258, -0.4132,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.350960 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.351987 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.352600 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.353203 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.353804 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, loss=0.0475]
0:00:46.906754 - bracket_assembly_nut_noaug_coarse--479260
0:00:46.906993 - {'grad_norm': 1.1594339609146118, 'grad_norm_std': inf, 'learning_rate': 2e-09, 'time_forward': 0.05606985092163086, 'time_backward': 0.08052277565002441, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269804.0813982, 'n_iterations': 95, 'n_datas': 760, 'train_loss_TCO-iter=1': 0.04745596647262573, 'train_loss_TCO': 0.04745596647262573, 'train_loss_total': 0.04745596647262573, 'train_grad_norm': 1.1594339609146118, 'epoch': 94}
0:00:46.907113 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:46.914528 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:47.445519 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0586],], device='cuda:0',s, loss=0.0478]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.316198 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.316816 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.317429 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:00:47.863890 - bracket_assembly_nut_noaug_coarse--479260
0:00:47.864112 - {'grad_norm': 1.1480712890625, 'grad_norm_std': inf, 'learning_rate': 2.0625000000000003e-09, 'time_forward': 0.05599164962768555, 'time_backward': 0.0780336856842041, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269805.0425773, 'n_iterations': 98, 'n_datas': 784, 'train_loss_TCO-iter=1': 0.04723741486668587, 'train_loss_TCO': 0.04723741486668587, 'train_loss_total': 0.04723741486668587, 'train_grad_norm': 1.1480712890625, 'epoch': 97}
0:00:47.864225 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:47.871759 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.402730 - iteration 0
0:00:48.625130 - vxvyvz tensor([[-0.0152,  0.0506,  0.2025]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:48.626205 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.627193 - dR tensor([[[ 0.1108,  0.4982, -0.8600],
         [ 0.8267,  0.4341,  0.3579],
         [ 0.5516, -0.7506, -0.3638]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:48.628071 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.631970 - k: tensor([[[ 0.1108,  0.4982, -0.8600, -0.0100],
         [ 0.8267,  0.4341,  0.3579,  0.0062],
         [ 0.5516, -0.7506, -0.3638,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.632907 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.633835 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0607],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.634447 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.635090 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.635725 - k: tensor([0.0437], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.07it/s, loss=0.0469]
0:00:48.186491 - bracket_assembly_nut_noaug_coarse--479260
0:00:48.186709 - {'grad_norm': 1.0654412508010864, 'grad_norm_std': inf, 'learning_rate': 2.0833333333333334e-09, 'time_forward': 0.059256553649902344, 'time_backward': 0.07847976684570312, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269805.3613222, 'n_iterations': 99, 'n_datas': 792, 'train_loss_TCO-iter=1': 0.046850576996803284, 'train_loss_TCO': 0.046850576996803284, 'train_loss_total': 0.046850576996803284, 'train_grad_norm': 1.0654412508010864, 'epoch': 98}
0:00:48.186826 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.194249 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.725254 - iteration 0
0:00:48.944290 - vxvyvz tensor([[-0.0159,  0.0483,  0.1936]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:48.945287 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.946286 - dR tensor([[[ 0.0826,  0.4891, -0.8683],
         [ 0.8368,  0.4392,  0.3270],
         [ 0.5413, -0.7536, -0.3730]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:48.947150 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.950321 - k: tensor([[[ 0.0826,  0.4891, -0.8683, -0.0100],
         [ 0.8368,  0.4392,  0.3270,  0.0062],
         [ 0.5413, -0.7536, -0.3730,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.951568 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.952873 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.953505 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.954113 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.954716 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0477]
0:00:48.530566 - bracket_assembly_nut_noaug_coarse--479260
0:00:48.530785 - {'grad_norm': 1.0099726915359497, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05573463439941406, 'time_backward': 0.07920598983764648, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269805.6811278, 'n_iterations': 100, 'n_datas': 800, 'train_loss_TCO-iter=1': 0.047737959772348404, 'train_loss_TCO': 0.047737959772348404, 'train_loss_total': 0.047737959772348404, 'train_grad_norm': 1.0099726915359497, 'epoch': 99}
0:00:48.530998 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.538482 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.069577 - iteration 0
0:00:49.288899 - vxvyvz tensor([[-0.0169,  0.0486,  0.1974]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:49.289943 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.290925 - dR tensor([[[ 0.1187,  0.4834, -0.8673],
         [ 0.8301,  0.4310,  0.3539],
         [ 0.5449, -0.7619, -0.3501]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:49.291795 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.295048 - k: tensor([[[ 0.1187,  0.4834, -0.8673, -0.0100],
         [ 0.8301,  0.4310,  0.3539,  0.0062],
         [ 0.5449, -0.7619, -0.3501,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.296556 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.297575 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.298188 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.298825 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.299440 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0474]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.676991 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.207842 - iteration 0
0:00:49.420698 - vxvyvz tensor([[-0.0054,  0.0133, -0.0093]], device='cuda:0')
0:00:49.421667 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.422590 - dR tensor([[[ 0.6320, -0.6577,  0.4099],
         [ 0.0027, -0.5271, -0.8498],
         [ 0.7750,  0.5382, -0.3314]]], device='cuda:0')
0:00:49.423452 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.426472 - k: tensor([[[ 0.6320, -0.6577,  0.4099, -0.0100],
         [ 0.0027, -0.5271, -0.8498,  0.0062],
         [ 0.7750,  0.5382, -0.3314,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.427418 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.428353 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0028],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.428982 - k: tensor([0.0054], device='cuda:0')
0:00:49.429586 - k: tensor([0.0003], device='cuda:0')
0:00:49.430186 - k: tensor([0.0649], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.32it/s]
0:00:48.909105 - bracket_assembly_nut_noaug_coarse--479260
0:00:48.909347 - {'grad_norm': 1.0814208984375, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05621647834777832, 'time_backward': 0.0779120922088623, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269806.0763164, 'n_iterations': 101, 'n_datas': 808, 'train_loss_TCO-iter=1': 0.04742743447422981, 'train_loss_TCO': 0.04742743447422981, 'train_loss_total': 0.04742743447422981, 'train_grad_norm': 1.0814208984375, 'val_loss_TCO-iter=1': 0.07071100920438766, 'val_loss_TCO': 0.07071100920438766, 'val_loss_total': 0.07071100920438766, 'epoch': 100}
0:00:48.909468 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.917008 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.444693 - iteration 0
0:00:49.663836 - vxvyvz tensor([[-0.0221,  0.0494,  0.2019]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:49.664839 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.665787 - dR tensor([[[ 0.0905,  0.5341, -0.8406],
         [ 0.8236,  0.4343,  0.3646],
         [ 0.5599, -0.7253, -0.4006]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:49.666611 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.669924 - k: tensor([[[ 0.0905,  0.5341, -0.8406, -0.0100],
         [ 0.8236,  0.4343,  0.3646,  0.0062],
         [ 0.5599, -0.7253, -0.4006,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.670865 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.671803 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0606],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.672435 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.673040 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.673640 - k: tensor([0.0438], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0468]
0:00:49.904200 - {'grad_norm': 1.1494611501693726, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:00:49.904315 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:49.911788 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.442761 - iteration 0
0:00:50.661733 - vxvyvz tensor([[-0.0124,  0.0452,  0.1974]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.662818 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.663820 - dR tensor([[[ 0.1268,  0.5872, -0.7994],
         [ 0.8344,  0.3726,  0.4060],
         [ 0.5363, -0.7186, -0.4428]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.664677 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.667891 - k: tensor([[[ 0.1268,  0.5872, -0.7994, -0.0100],
         [ 0.8344,  0.3726,  0.4060,  0.0062],
         [ 0.5363, -0.7186, -0.4428,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.669321 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.670418 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.671073 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.671712 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.672336 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.047]
0:00:50.232801 - bracket_assembly_nut_noaug_coarse--479260
0:00:50.233011 - {'grad_norm': 1.149132251739502, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0558316707611084, 'time_backward': 0.0778961181640625, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.3974116, 'n_iterations': 105, 'n_datas': 840, 'train_loss_TCO-iter=1': 0.04702790826559067, 'train_loss_TCO': 0.04702790826559067, 'train_loss_total': 0.04702790826559067, 'train_grad_norm': 1.149132251739502, 'epoch': 104}
0:00:50.233135 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:50.240514 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.771444 - iteration 0
0:00:50.990556 - vxvyvz tensor([[-0.0156,  0.0404,  0.1904]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.991615 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.992607 - dR tensor([[[ 0.0912,  0.5261, -0.8455],
         [ 0.8206,  0.4414,  0.3631],
         [ 0.5642, -0.7269, -0.3914]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.993436 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.996708 - k: tensor([[[ 0.0912,  0.5261, -0.8455, -0.0100],
         [ 0.8206,  0.4414,  0.3631,  0.0062],
         [ 0.5642, -0.7269, -0.3914,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.998226 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.999255 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0571],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.999915 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.000547 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.001168 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.048]
       grad_fn=<CopySlices>)': 1.1494611501693726, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:00:52.075637 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.076653 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.077289 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.077895 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.078495 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0472]
0:00:51.638712 - bracket_assembly_nut_noaug_coarse--479260
0:00:51.638941 - {'grad_norm': 1.147571086883545, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05620002746582031, 'time_backward': 0.07857728004455566, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269808.804287, 'n_iterations': 109, 'n_datas': 872, 'train_loss_TCO-iter=1': 0.047234099358320236, 'train_loss_TCO': 0.047234099358320236, 'train_loss_total': 0.047234099358320236, 'train_grad_norm': 1.147571086883545, 'epoch': 108}
0:00:51.639080 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:51.646719 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.177713 - iteration 0
0:00:52.396749 - vxvyvz tensor([[-0.0124,  0.0452,  0.1974]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.397779 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.398757 - dR tensor([[[ 0.1268,  0.5873, -0.7994],
         [ 0.8345,  0.3726,  0.4060],
         [ 0.5363, -0.7185, -0.4428]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.399621 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.402833 - k: tensor([[[ 0.1268,  0.5873, -0.7994, -0.0100],
         [ 0.8345,  0.3726,  0.4060,  0.0062],
         [ 0.5363, -0.7185, -0.4428,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.403780 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.405281 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.405903 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.406508 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.407145 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.047]
0:00:51.969696 - bracket_assembly_nut_noaug_coarse--479260
0:00:51.969908 - {'grad_norm': 1.1474790573120117, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05577278137207031, 'time_backward': 0.0785372257232666, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269809.1328118, 'n_iterations': 110, 'n_datas': 880, 'train_loss_TCO-iter=1': 0.04699621722102165, 'train_loss_TCO': 0.04699621722102165, 'train_loss_total': 0.04699621722102165, 'train_grad_norm': 1.1474790573120117, 'epoch': 109}
0:00:51.970022 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:51.977511 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.508485 - iteration 0
0:00:52.727872 - vxvyvz tensor([[-0.0135,  0.0443,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.728893 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.729875 - dR tensor([[[ 0.1180,  0.5829, -0.8039],
         [ 0.8328,  0.3829,  0.3999],
         [ 0.5409, -0.7167, -0.4402]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.730699 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.733924 - k: tensor([[[ 0.1180,  0.5829, -0.8039, -0.0100],
         [ 0.8328,  0.3829,  0.3999,  0.0062],
         [ 0.5409, -0.7167, -0.4402,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.735329 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.736349 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.736979 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.737589 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.738203 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:00:52.300619 - bracket_assembly_nut_noaug_coarse--479260
0:00:52.300843 - {'grad_norm': 1.1479716300964355, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05601787567138672, 'time_backward': 0.07813286781311035, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269809.4635081, 'n_iterations': 111, 'n_datas': 888, 'train_loss_TCO-iter=1': 0.04723957180976868, 'train_loss_TCO': 0.04723957180976868, 'train_loss_total': 0.04723957180976868, 'train_grad_norm': 1.1479716300964355, 'epoch': 110}
0:00:52.300955 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:52.308473 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.839498 - iteration 0
0:00:53.059136 - vxvyvz tensor([[-0.0135,  0.0443,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:53.060168 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:53.061146 - dR tensor([[[ 0.1180,  0.5829, -0.8039],
         [ 0.8328,  0.3829,  0.3999],
         [ 0.5409, -0.7167, -0.4402]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:53.061977 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:53.065208 - k: tensor([[[ 0.1180,  0.5829, -0.8039, -0.0100],
         [ 0.8328,  0.3829,  0.3999,  0.0062],
         [ 0.5409, -0.7167, -0.4402,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.066685 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.067718 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.068378 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:53.068997 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:53.069618 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0473]
       grad_fn=<CopySlices>)': 1.1494611501693726, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:00:54.056149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.057168 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0569],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.057785 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.058391 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.059032 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.048]
0:00:53.613975 - bracket_assembly_nut_noaug_coarse--479260
0:00:53.614196 - {'grad_norm': 1.0097830295562744, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056069374084472656, 'time_backward': 0.07792401313781738, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269810.7841218, 'n_iterations': 115, 'n_datas': 920, 'train_loss_TCO-iter=1': 0.04796861112117767, 'train_loss_TCO': 0.04796861112117767, 'train_loss_total': 0.04796861112117767, 'train_grad_norm': 1.0097830295562744, 'epoch': 114}
0:00:53.614309 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:53.622011 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.153017 - iteration 0
0:00:54.372170 - vxvyvz tensor([[-0.0135,  0.0443,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:54.373199 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.374200 - dR tensor([[[ 0.1180,  0.5829, -0.8039],
         [ 0.8328,  0.3829,  0.3999],
         [ 0.5409, -0.7167, -0.4403]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:54.375064 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:54.378260 - k: tensor([[[ 0.1180,  0.5829, -0.8039, -0.0100],
         [ 0.8328,  0.3829,  0.3999,  0.0062],
         [ 0.5409, -0.7167, -0.4403,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.379766 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.380794 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.381438 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.382043 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.382646 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:00:53.947007 - bracket_assembly_nut_noaug_coarse--479260
0:00:53.947205 - {'grad_norm': 1.147689938545227, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056023597717285156, 'time_backward': 0.07784223556518555, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269811.1077623, 'n_iterations': 116, 'n_datas': 928, 'train_loss_TCO-iter=1': 0.04723416268825531, 'train_loss_TCO': 0.04723416268825531, 'train_loss_total': 0.04723416268825531, 'train_grad_norm': 1.147689938545227, 'epoch': 115}
0:00:53.947321 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:53.954761 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.485741 - iteration 0
0:00:54.704734 - vxvyvz tensor([[-0.0085,  0.0513,  0.1931]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:54.705772 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.706731 - dR tensor([[[ 0.0907,  0.5616, -0.8224],
         [ 0.8311,  0.4123,  0.3732],
         [ 0.5486, -0.7174, -0.4293]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:54.707606 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:54.710814 - k: tensor([[[ 0.0907,  0.5616, -0.8224, -0.0100],
         [ 0.8311,  0.4123,  0.3732,  0.0062],
         [ 0.5486, -0.7174, -0.4293,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.711799 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.713251 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.713867 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.714472 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.715110 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0475]
0:00:54.271423 - bracket_assembly_nut_noaug_coarse--479260
0:00:54.271622 - {'grad_norm': 1.0966647863388062, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05559372901916504, 'time_backward': 0.07789945602416992, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269811.4402666, 'n_iterations': 117, 'n_datas': 936, 'train_loss_TCO-iter=1': 0.04753547161817551, 'train_loss_TCO': 0.04753547161817551, 'train_loss_total': 0.04753547161817551, 'train_grad_norm': 1.0966647863388062, 'epoch': 116}
0:00:54.271736 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:54.279211 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.810130 - iteration 0
0:00:55.029886 - vxvyvz tensor([[-0.0153,  0.0534,  0.1875]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:55.030948 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:55.031963 - dR tensor([[[ 0.1069,  0.5336, -0.8390],
         [ 0.8288,  0.4183,  0.3716],
         [ 0.5493, -0.7350, -0.3975]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:55.032809 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:55.036026 - k: tensor([[[ 0.1069,  0.5336, -0.8390, -0.0100],
         [ 0.8288,  0.4183,  0.3716,  0.0062],
         [ 0.5493, -0.7350, -0.3975,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.036966 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.038447 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0562],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.039196 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:55.039845 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:55.040468 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0482]
0:00:54.598058 - bracket_assembly_nut_noaug_coarse--479260
0:00:54.598274 - {'grad_norm': 1.1174439191818237, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05649924278259277, 'time_backward': 0.07804656028747559, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269811.7658277, 'n_iterations': 118, 'n_datas': 944, 'train_loss_TCO-iter=1': 0.048229485750198364, 'train_loss_TCO': 0.048229485750198364, 'train_loss_total': 0.048229485750198364, 'train_grad_norm': 1.1174439191818237, 'epoch': 117}
0:00:54.598388 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:54.606123 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:55.137115 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0572],726, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.033710 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.034315 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.034956 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.048]
0:00:55.600719 - bracket_assembly_nut_noaug_coarse--479260
0:00:55.600901 - {'grad_norm': 1.063637614250183, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056307315826416016, 'time_backward': 0.07810711860656738, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269812.761762, 'n_iterations': 121, 'n_datas': 968, 'train_loss_TCO-iter=1': 0.04796503484249115, 'train_loss_TCO': 0.04796503484249115, 'train_loss_total': 0.04796503484249115, 'train_grad_norm': 1.063637614250183, 'epoch': 120}
0:00:55.601011 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:55.608510 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.139461 - iteration 0
0:00:56.358643 - vxvyvz tensor([[-0.0185,  0.0483,  0.1985]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:56.359719 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.360684 - dR tensor([[[ 0.0818,  0.5439, -0.8352],
         [ 0.8426,  0.4098,  0.3494],
         [ 0.5323, -0.7323, -0.4248]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:56.361517 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:56.364956 - k: tensor([[[ 0.0818,  0.5439, -0.8352, -0.0100],
         [ 0.8426,  0.4098,  0.3494,  0.0062],
         [ 0.5323, -0.7323, -0.4248,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.366518 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.367519 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.368163 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.368750 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.369333 - k: tensor([0.0441], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.047]
0:00:55.929838 - bracket_assembly_nut_noaug_coarse--479260
0:00:55.930092 - {'grad_norm': 1.0735348463058472, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05611085891723633, 'time_backward': 0.07890653610229492, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269813.0953338, 'n_iterations': 122, 'n_datas': 976, 'train_loss_TCO-iter=1': 0.04701302945613861, 'train_loss_TCO': 0.04701302945613861, 'train_loss_total': 0.04701302945613861, 'train_grad_norm': 1.0735348463058472, 'epoch': 121}
0:00:55.930212 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:55.938071 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.469154 - iteration 0
0:00:56.688694 - vxvyvz tensor([[-0.0184,  0.0504,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:56.689720 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.690674 - dR tensor([[[ 0.1264,  0.5419, -0.8309],
         [ 0.8378,  0.3902,  0.3819],
         [ 0.5311, -0.7444, -0.4047]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:56.691550 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:56.694763 - k: tensor([[[ 0.1264,  0.5419, -0.8309, -0.0100],
         [ 0.8378,  0.3902,  0.3819,  0.0062],
         [ 0.5311, -0.7444, -0.4047,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.696323 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.697249 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.697864 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.698473 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.699114 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0474]
0:00:56.258193 - bracket_assembly_nut_noaug_coarse--479260
0:00:56.258429 - {'grad_norm': 1.0921210050582886, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05641293525695801, 'time_backward': 0.07891702651977539, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269813.425202, 'n_iterations': 123, 'n_datas': 984, 'train_loss_TCO-iter=1': 0.047386426478624344, 'train_loss_TCO': 0.047386426478624344, 'train_loss_total': 0.047386426478624344, 'train_grad_norm': 1.0921210050582886, 'epoch': 122}
0:00:56.258645 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:56.266515 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.797606 - iteration 0
0:00:57.017095 - vxvyvz tensor([[-0.0135,  0.0443,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:57.018078 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.019127 - dR tensor([[[ 0.1180,  0.5830, -0.8038],
         [ 0.8328,  0.3828,  0.3999],
         [ 0.5408, -0.7166, -0.4404]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:57.020014 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:57.023224 - k: tensor([[[ 0.1180,  0.5830, -0.8038, -0.0100],
         [ 0.8328,  0.3828,  0.3999,  0.0062],
         [ 0.5408, -0.7166, -0.4404,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.024197 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.025128 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.025775 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.026395 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.027036 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0472]
0:00:56.597162 - bracket_assembly_nut_noaug_coarse--479260
0:00:56.597383 - {'grad_norm': 1.1472949981689453, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05584001541137695, 'time_backward': 0.07940673828125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269813.7535815, 'n_iterations': 124, 'n_datas': 992, 'train_loss_TCO-iter=1': 0.047227390110492706, 'train_loss_TCO': 0.047227390110492706, 'train_loss_total': 0.047227390110492706, 'train_grad_norm': 1.1472949981689453, 'epoch': 123}
0:00:56.597496 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:56.605065 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.136124 - iteration 0
0:00:57.355313 - vxvyvz tensor([[-0.0202,  0.0517,  0.1885]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:57.356363 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.357320 - dR tensor([[[ 0.1200,  0.5262, -0.8418],
         [ 0.8112,  0.4368,  0.3887],
         [ 0.5723, -0.7296, -0.3745]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:57.358151 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:57.361381 - k: tensor([[[ 0.1200,  0.5262, -0.8418, -0.0100],
         [ 0.8112,  0.4368,  0.3887,  0.0062],
         [ 0.5723, -0.7296, -0.3745,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.362888 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.363896 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0566],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.364527 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.365153 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.365756 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0482]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:00:58.336069 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.337571 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.338189 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.338824 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.339446 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0476]
0:00:57.896701 - bracket_assembly_nut_noaug_coarse--479260
0:00:57.896917 - {'grad_norm': 1.1097490787506104, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055873870849609375, 'time_backward': 0.07845354080200195, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269815.0650175, 'n_iterations': 128, 'n_datas': 1024, 'train_loss_TCO-iter=1': 0.04761422052979469, 'train_loss_TCO': 0.04761422052979469, 'train_loss_total': 0.04761422052979469, 'train_grad_norm': 1.1097490787506104, 'epoch': 127}
0:00:57.897032 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:57.904709 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.435776 - iteration 0
0:00:58.655059 - vxvyvz tensor([[-0.0201,  0.0454,  0.1962]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:58.656099 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.657092 - dR tensor([[[ 0.1121,  0.5135, -0.8507],
         [ 0.8389,  0.4101,  0.3580],
         [ 0.5327, -0.7538, -0.3848]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:58.657918 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:58.661181 - k: tensor([[[ 0.1121,  0.5135, -0.8507, -0.0100],
         [ 0.8389,  0.4101,  0.3580,  0.0062],
         [ 0.5327, -0.7538, -0.3848,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.662668 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.663709 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.664370 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.664987 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.665611 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0474]
0:00:58.217996 - bracket_assembly_nut_noaug_coarse--479260
0:00:58.218216 - {'grad_norm': 1.1208335161209106, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05629563331604004, 'time_backward': 0.07829904556274414, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269815.3911285, 'n_iterations': 129, 'n_datas': 1032, 'train_loss_TCO-iter=1': 0.04737574979662895, 'train_loss_TCO': 0.04737574979662895, 'train_loss_total': 0.04737574979662895, 'train_grad_norm': 1.1208335161209106, 'epoch': 128}
0:00:58.218329 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:58.225833 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.756826 - iteration 0
0:00:58.976053 - vxvyvz tensor([[-0.0152,  0.0482,  0.1921]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:58.977094 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.978079 - dR tensor([[[ 0.0955,  0.5870, -0.8040],
         [ 0.8199,  0.4116,  0.3979],
         [ 0.5645, -0.6972, -0.4419]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:58.978920 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:58.982109 - k: tensor([[[ 0.0955,  0.5870, -0.8040, -0.0100],
         [ 0.8199,  0.4116,  0.3979,  0.0062],
         [ 0.5645, -0.6972, -0.4419,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.983566 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.984588 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.985185 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.985772 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.986357 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0476]
0:00:58.543469 - bracket_assembly_nut_noaug_coarse--479260
0:00:58.543688 - {'grad_norm': 1.157138466835022, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05580496788024902, 'time_backward': 0.0792391300201416, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269815.712685, 'n_iterations': 130, 'n_datas': 1040, 'train_loss_TCO-iter=1': 0.04757169634103775, 'train_loss_TCO': 0.04757169634103775, 'train_loss_total': 0.04757169634103775, 'train_grad_norm': 1.157138466835022, 'epoch': 129}
0:00:58.543799 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:58.551299 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:59.082241 - iteration 0
0:00:59.301601 - vxvyvz tensor([[-0.0157,  0.0517,  0.1908]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:59.302652 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:59.303645 - dR tensor([[[ 0.0837,  0.5572, -0.8262],
         [ 0.8478,  0.3958,  0.3528],
         [ 0.5236, -0.7300, -0.4393]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:59.304526 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:59.307743 - k: tensor([[[ 0.0837,  0.5572, -0.8262, -0.0100],
         [ 0.8478,  0.3958,  0.3528,  0.0062],
         [ 0.5236, -0.7300, -0.4393,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.308687 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.310164 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.310813 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.311450 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.312101 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0477]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:00.286727 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.288314 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0602],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.289114 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.289727 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.290333 - k: tensor([0.0439], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.97it/s, loss=0.0469]
0:00:59.857835 - bracket_assembly_nut_noaug_coarse--479260
0:00:59.858072 - {'grad_norm': 1.0332834720611572, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05819082260131836, 'time_backward': 0.08145928382873535, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269817.0192268, 'n_iterations': 134, 'n_datas': 1072, 'train_loss_TCO-iter=1': 0.046944208443164825, 'train_loss_TCO': 0.046944208443164825, 'train_loss_total': 0.046944208443164825, 'train_grad_norm': 1.0332834720611572, 'epoch': 133}
0:00:59.858193 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:59.865902 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.396935 - iteration 0
0:01:00.616551 - vxvyvz tensor([[-0.0133,  0.0521,  0.1927]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:00.617599 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.618546 - dR tensor([[[ 0.0983,  0.5233, -0.8464],
         [ 0.8243,  0.4337,  0.3638],
         [ 0.5575, -0.7335, -0.3888]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:00.619412 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:00.622638 - k: tensor([[[ 0.0983,  0.5233, -0.8464, -0.0100],
         [ 0.8243,  0.4337,  0.3638,  0.0062],
         [ 0.5575, -0.7335, -0.3888,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.624230 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.625159 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0578],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.625809 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.626429 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.627058 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, loss=0.0477]
0:01:00.188791 - bracket_assembly_nut_noaug_coarse--479260
0:01:00.189017 - {'grad_norm': 1.0477640628814697, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05649447441101074, 'time_backward': 0.08063411712646484, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269817.3548582, 'n_iterations': 135, 'n_datas': 1080, 'train_loss_TCO-iter=1': 0.04773024097084999, 'train_loss_TCO': 0.04773024097084999, 'train_loss_total': 0.04773024097084999, 'train_grad_norm': 1.0477640628814697, 'epoch': 134}
0:01:00.189131 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:00.196667 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.727682 - iteration 0
0:01:00.946995 - vxvyvz tensor([[-0.0168,  0.0516,  0.1951]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:00.948033 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.949002 - dR tensor([[[ 0.1353,  0.5458, -0.8269],
         [ 0.8310,  0.3920,  0.3947],
         [ 0.5396, -0.7406, -0.4005]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:00.949839 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:00.953089 - k: tensor([[[ 0.1353,  0.5458, -0.8269, -0.0100],
         [ 0.8310,  0.3920,  0.3947,  0.0062],
         [ 0.5396, -0.7406, -0.4005,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.954557 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.955593 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0585],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.956244 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.956864 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.957479 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0474]
0:01:00.519533 - bracket_assembly_nut_noaug_coarse--479260
0:01:00.519780 - {'grad_norm': 1.0576112270355225, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056142330169677734, 'time_backward': 0.07888579368591309, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269817.6834934, 'n_iterations': 136, 'n_datas': 1088, 'train_loss_TCO-iter=1': 0.04735864698886871, 'train_loss_TCO': 0.04735864698886871, 'train_loss_total': 0.04735864698886871, 'train_grad_norm': 1.0576112270355225, 'epoch': 135}
0:01:00.519924 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:00.527699 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.058691 - iteration 0
0:01:01.278207 - vxvyvz tensor([[-0.0204,  0.0501,  0.1912]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:01.279257 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.280272 - dR tensor([[[ 0.1202,  0.5445, -0.8301],
         [ 0.8384,  0.3922,  0.3786],
         [ 0.5317, -0.7415, -0.4093]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:01.281107 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:01.284345 - k: tensor([[[ 0.1202,  0.5445, -0.8301, -0.0100],
         [ 0.8384,  0.3922,  0.3786,  0.0062],
         [ 0.5317, -0.7415, -0.4093,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.285583 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.286869 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.287503 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.288153 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.288759 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0478]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:02.271991 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.273018 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0576],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.273635 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.274239 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.274877 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0475]
0:01:01.838114 - bracket_assembly_nut_noaug_coarse--479260
0:01:01.838344 - {'grad_norm': 1.1354423761367798, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05574750900268555, 'time_backward': 0.07900595664978027, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269819.0011818, 'n_iterations': 140, 'n_datas': 1120, 'train_loss_TCO-iter=1': 0.04754604771733284, 'train_loss_TCO': 0.04754604771733284, 'train_loss_total': 0.04754604771733284, 'train_grad_norm': 1.1354423761367798, 'epoch': 139}
0:01:01.838456 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:01.846087 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.377131 - iteration 0
0:01:02.596424 - vxvyvz tensor([[-0.0135,  0.0443,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:02.597459 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.598430 - dR tensor([[[ 0.1179,  0.5832, -0.8037],
         [ 0.8329,  0.3827,  0.3999],
         [ 0.5408, -0.7166, -0.4406]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:02.599298 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:02.602477 - k: tensor([[[ 0.1179,  0.5832, -0.8037, -0.0100],
         [ 0.8329,  0.3827,  0.3999,  0.0062],
         [ 0.5408, -0.7166, -0.4406,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.603423 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.604954 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.605577 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.606183 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.606795 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:01:02.165001 - bracket_assembly_nut_noaug_coarse--479260
0:01:02.165202 - {'grad_norm': 1.1477142572402954, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05603814125061035, 'time_backward': 0.0780189037322998, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269819.3320372, 'n_iterations': 141, 'n_datas': 1128, 'train_loss_TCO-iter=1': 0.04723849520087242, 'train_loss_TCO': 0.04723849520087242, 'train_loss_total': 0.04723849520087242, 'train_grad_norm': 1.1477142572402954, 'epoch': 140}
0:01:02.165312 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.172808 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.703799 - iteration 0
0:01:02.922657 - vxvyvz tensor([[-0.0121,  0.0530,  0.1934]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:02.923733 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.924710 - dR tensor([[[ 0.1077,  0.5209, -0.8468],
         [ 0.8357,  0.4139,  0.3609],
         [ 0.5385, -0.7466, -0.3907]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:02.925561 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:02.928816 - k: tensor([[[ 0.1077,  0.5209, -0.8468, -0.0100],
         [ 0.8357,  0.4139,  0.3609,  0.0062],
         [ 0.5385, -0.7466, -0.3907,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.929738 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.931188 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.931885 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.932507 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.933110 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0477]
0:01:02.500623 - bracket_assembly_nut_noaug_coarse--479260
0:01:02.500849 - {'grad_norm': 1.1080281734466553, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05564260482788086, 'time_backward': 0.0780491828918457, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269819.6582575, 'n_iterations': 142, 'n_datas': 1136, 'train_loss_TCO-iter=1': 0.04766380786895752, 'train_loss_TCO': 0.04766380786895752, 'train_loss_total': 0.04766380786895752, 'train_grad_norm': 1.1080281734466553, 'epoch': 141}
0:01:02.500987 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.508621 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.039620 - iteration 0
0:01:03.259026 - vxvyvz tensor([[-0.0233,  0.0528,  0.1939]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:03.260069 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.261019 - dR tensor([[[ 0.1020,  0.5486, -0.8298],
         [ 0.8043,  0.4455,  0.3933],
         [ 0.5854, -0.7075, -0.3958]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:03.261842 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:03.265065 - k: tensor([[[ 0.1020,  0.5486, -0.8298, -0.0100],
         [ 0.8043,  0.4455,  0.3933,  0.0062],
         [ 0.5854, -0.7075, -0.3958,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.266526 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.267474 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.268137 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.268740 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.269347 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0476]
0:01:02.827512 - bracket_assembly_nut_noaug_coarse--479260
0:01:02.827714 - {'grad_norm': 1.0422303676605225, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056050777435302734, 'time_backward': 0.07755184173583984, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269819.9940405, 'n_iterations': 143, 'n_datas': 1144, 'train_loss_TCO-iter=1': 0.047649309039115906, 'train_loss_TCO': 0.047649309039115906, 'train_loss_total': 0.047649309039115906, 'train_grad_norm': 1.0422303676605225, 'epoch': 142}
0:01:02.827830 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.835305 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.366273 - iteration 0
0:01:03.585540 - vxvyvz tensor([[-0.0152,  0.0477,  0.1907]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:03.586548 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.587562 - dR tensor([[[ 0.1118,  0.5084, -0.8538],
         [ 0.8134,  0.4468,  0.3725],
         [ 0.5709, -0.7361, -0.3636]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:03.588431 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:03.591621 - k: tensor([[[ 0.1118,  0.5084, -0.8538, -0.0100],
         [ 0.8134,  0.4468,  0.3725,  0.0062],
         [ 0.5709, -0.7361, -0.3636,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.592561 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.594030 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.594645 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.595288 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.595928 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                         | 0/1 [00:00<?, ?it/s, loss=0.048]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:01:04.591893 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.592923 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0590],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.593540 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.594148 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.594751 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0473]
0:01:04.151951 - bracket_assembly_nut_noaug_coarse--479260
0:01:04.152169 - {'grad_norm': 1.0311663150787354, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05591440200805664, 'time_backward': 0.07817554473876953, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269821.3201134, 'n_iterations': 147, 'n_datas': 1176, 'train_loss_TCO-iter=1': 0.04732527583837509, 'train_loss_TCO': 0.04732527583837509, 'train_loss_total': 0.04732527583837509, 'train_grad_norm': 1.0311663150787354, 'epoch': 146}
0:01:04.152291 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.159762 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:04.690703 - iteration 0
0:01:04.909712 - vxvyvz tensor([[-0.0141,  0.0493,  0.1974]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:04.910749 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:04.911757 - dR tensor([[[ 0.1256,  0.5119, -0.8498],
         [ 0.8265,  0.4197,  0.3750],
         [ 0.5487, -0.7495, -0.3704]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:04.912620 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:04.915823 - k: tensor([[[ 0.1256,  0.5119, -0.8498, -0.0100],
         [ 0.8265,  0.4197,  0.3750,  0.0062],
         [ 0.5487, -0.7495, -0.3704,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.916769 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.918284 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.918931 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.919550 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.920194 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0473]
0:01:04.479923 - bracket_assembly_nut_noaug_coarse--479260
0:01:04.480121 - {'grad_norm': 1.081257700920105, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05572032928466797, 'time_backward': 0.07795166969299316, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269821.6452172, 'n_iterations': 148, 'n_datas': 1184, 'train_loss_TCO-iter=1': 0.04734049737453461, 'train_loss_TCO': 0.04734049737453461, 'train_loss_total': 0.04734049737453461, 'train_grad_norm': 1.081257700920105, 'epoch': 147}
0:01:04.480277 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.487709 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.018610 - iteration 0
0:01:05.237520 - vxvyvz tensor([[-0.0156,  0.0498,  0.1963]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:05.238537 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.239541 - dR tensor([[[ 0.1172,  0.5226, -0.8445],
         [ 0.8397,  0.4019,  0.3653],
         [ 0.5303, -0.7519, -0.3917]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:05.240412 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:05.243606 - k: tensor([[[ 0.1172,  0.5226, -0.8445, -0.0100],
         [ 0.8397,  0.4019,  0.3653,  0.0062],
         [ 0.5303, -0.7519, -0.3917,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.245032 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.246073 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.246688 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.247332 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.247977 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0473]
0:01:04.809820 - bracket_assembly_nut_noaug_coarse--479260
0:01:04.810044 - {'grad_norm': 1.0437928438186646, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05547189712524414, 'time_backward': 0.07798957824707031, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269821.9730403, 'n_iterations': 149, 'n_datas': 1192, 'train_loss_TCO-iter=1': 0.04731205105781555, 'train_loss_TCO': 0.04731205105781555, 'train_loss_total': 0.04731205105781555, 'train_grad_norm': 1.0437928438186646, 'epoch': 148}
0:01:04.810160 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.817699 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.348686 - iteration 0
0:01:05.568293 - vxvyvz tensor([[-0.0175,  0.0510,  0.1997]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:05.569288 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.570245 - dR tensor([[[ 0.1435,  0.5739, -0.8062],
         [ 0.8356,  0.3662,  0.4094],
         [ 0.5303, -0.7324, -0.4270]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:05.571110 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:05.574298 - k: tensor([[[ 0.1435,  0.5739, -0.8062, -0.0100],
         [ 0.8356,  0.3662,  0.4094,  0.0062],
         [ 0.5303, -0.7324, -0.4270,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.575241 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.576765 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.577384 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.578002 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.578603 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0468]
         [-0.5688, -0.7927, -0.2192,  0.0062],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
         [ 0.2313, -0.4099,  0.8823,  0.0596],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.291684 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.292330 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.292931 - k: tensor([0.0441], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.45it/s, loss=0.0471]
0:01:05.866726 - bracket_assembly_nut_noaug_coarse--479260
0:01:05.866949 - {'grad_norm': 1.060859203338623, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05248427391052246, 'time_backward': 0.0779576301574707, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269823.0185008, 'n_iterations': 152, 'n_datas': 1216, 'train_loss_TCO-iter=1': 0.047060783952474594, 'train_loss_TCO': 0.047060783952474594, 'train_loss_total': 0.047060783952474594, 'train_grad_norm': 1.060859203338623, 'epoch': 151}
0:01:05.867090 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:05.874575 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.405525 - iteration 0
0:01:06.624469 - vxvyvz tensor([[-0.0143,  0.0466,  0.1923]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:06.625477 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.626432 - dR tensor([[[ 0.0921,  0.5064, -0.8574],
         [ 0.8317,  0.4344,  0.3459],
         [ 0.5476, -0.7449, -0.3811]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:06.627301 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:06.630485 - k: tensor([[[ 0.0921,  0.5064, -0.8574, -0.0100],
         [ 0.8317,  0.4344,  0.3459,  0.0062],
         [ 0.5476, -0.7449, -0.3811,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.631979 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.633018 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.633633 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.634241 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.634874 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0478]
0:01:06.197697 - bracket_assembly_nut_noaug_coarse--479260
0:01:06.197911 - {'grad_norm': 1.119835376739502, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05553722381591797, 'time_backward': 0.0776667594909668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269823.3598533, 'n_iterations': 153, 'n_datas': 1224, 'train_loss_TCO-iter=1': 0.04784926399588585, 'train_loss_TCO': 0.04784926399588585, 'train_loss_total': 0.04784926399588585, 'train_grad_norm': 1.119835376739502, 'epoch': 152}
0:01:06.198022 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.205389 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.736336 - iteration 0
0:01:06.955388 - vxvyvz tensor([[-0.0168,  0.0450,  0.1942]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:06.956435 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.957388 - dR tensor([[[ 0.0977,  0.5329, -0.8405],
         [ 0.8352,  0.4153,  0.3604],
         [ 0.5412, -0.7372, -0.4045]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:06.958212 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:06.961403 - k: tensor([[[ 0.0977,  0.5329, -0.8405, -0.0100],
         [ 0.8352,  0.4153,  0.3604,  0.0062],
         [ 0.5412, -0.7372, -0.4045,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.962878 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.963939 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.964595 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.965222 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.965825 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0475]
0:01:06.523629 - bracket_assembly_nut_noaug_coarse--479260
0:01:06.523850 - {'grad_norm': 1.0405992269515991, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05570173263549805, 'time_backward': 0.07747793197631836, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269823.6904936, 'n_iterations': 154, 'n_datas': 1232, 'train_loss_TCO-iter=1': 0.04754798859357834, 'train_loss_TCO': 0.04754798859357834, 'train_loss_total': 0.04754798859357834, 'train_grad_norm': 1.0405992269515991, 'epoch': 153}
0:01:06.523978 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.531420 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.062410 - iteration 0
0:01:07.282012 - vxvyvz tensor([[-0.0201,  0.0521,  0.1891]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:07.283072 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.284092 - dR tensor([[[ 0.1228,  0.5137, -0.8491],
         [ 0.8463,  0.3928,  0.3600],
         [ 0.5184, -0.7628, -0.3865]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:07.284916 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:07.288164 - k: tensor([[[ 0.1228,  0.5137, -0.8491, -0.0100],
         [ 0.8463,  0.3928,  0.3600,  0.0062],
         [ 0.5184, -0.7628, -0.3865,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.289088 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.290603 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0567],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.291261 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.291918 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.292537 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0481]
0:01:06.847775 - bracket_assembly_nut_noaug_coarse--479260
0:01:06.848002 - {'grad_norm': 1.0680663585662842, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05634951591491699, 'time_backward': 0.0778501033782959, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269824.0175982, 'n_iterations': 155, 'n_datas': 1240, 'train_loss_TCO-iter=1': 0.048079583793878555, 'train_loss_TCO': 0.048079583793878555, 'train_loss_total': 0.048079583793878555, 'train_grad_norm': 1.0680663585662842, 'epoch': 154}
0:01:06.848122 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.855684 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.386706 - iteration 0
0:01:07.605679 - vxvyvz tensor([[-0.0132,  0.0468,  0.2027]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:07.606727 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.607722 - dR tensor([[[ 0.1136,  0.5176, -0.8480],
         [ 0.8247,  0.4269,  0.3710],
         [ 0.5541, -0.7415, -0.3784]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:07.608566 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:07.611800 - k: tensor([[[ 0.1136,  0.5176, -0.8480, -0.0100],
         [ 0.8247,  0.4269,  0.3710,  0.0062],
         [ 0.5541, -0.7415, -0.3784,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.613286 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.614337 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0608],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.614986 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.615606 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.616247 - k: tensor([0.0437], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0468]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:08.607229 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.608179 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.608815 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.609431 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.610035 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0471]
0:01:08.204148 - bracket_assembly_nut_noaug_coarse--479260
0:01:08.204346 - {'grad_norm': 1.0017331838607788, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05640816688537598, 'time_backward': 0.07806277275085449, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269825.3352606, 'n_iterations': 159, 'n_datas': 1272, 'train_loss_TCO-iter=1': 0.04710046947002411, 'train_loss_TCO': 0.04710046947002411, 'train_loss_total': 0.04710046947002411, 'train_grad_norm': 1.0017331838607788, 'epoch': 158}
0:01:08.204482 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.212074 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:08.742979 - iteration 0
0:01:08.961771 - vxvyvz tensor([[-0.0201,  0.0521,  0.1891]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:08.962824 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:08.963843 - dR tensor([[[ 0.1228,  0.5137, -0.8491],
         [ 0.8463,  0.3927,  0.3600],
         [ 0.5184, -0.7628, -0.3865]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:08.964688 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:08.967901 - k: tensor([[[ 0.1228,  0.5137, -0.8491, -0.0100],
         [ 0.8463,  0.3927,  0.3600,  0.0062],
         [ 0.5184, -0.7628, -0.3865,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.968823 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.970346 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0567],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.970998 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.971617 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.972255 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0481]
0:01:08.547782 - bracket_assembly_nut_noaug_coarse--479260
0:01:08.548023 - {'grad_norm': 1.0672603845596313, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05549502372741699, 'time_backward': 0.07913923263549805, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269825.6986766, 'n_iterations': 160, 'n_datas': 1280, 'train_loss_TCO-iter=1': 0.048066817224025726, 'train_loss_TCO': 0.048066817224025726, 'train_loss_total': 0.048066817224025726, 'train_grad_norm': 1.0672603845596313, 'epoch': 159}
0:01:08.548138 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.555892 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.086851 - iteration 0
0:01:09.306421 - vxvyvz tensor([[-0.0195,  0.0498,  0.1966]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:09.307481 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.308487 - dR tensor([[[ 0.0979,  0.5663, -0.8184],
         [ 0.8430,  0.3899,  0.3706],
         [ 0.5289, -0.7262, -0.4392]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:09.309321 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:09.312607 - k: tensor([[[ 0.0979,  0.5663, -0.8184, -0.0100],
         [ 0.8430,  0.3899,  0.3706,  0.0062],
         [ 0.5289, -0.7262, -0.4392,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.314027 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.315091 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0590],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.315737 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.316359 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.316959 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0471]
0:01:08.878285 - bracket_assembly_nut_noaug_coarse--479260
0:01:08.878512 - {'grad_norm': 1.0814168453216553, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05631899833679199, 'time_backward': 0.07932066917419434, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269826.0434873, 'n_iterations': 161, 'n_datas': 1288, 'train_loss_TCO-iter=1': 0.04709012433886528, 'train_loss_TCO': 0.04709012433886528, 'train_loss_total': 0.04709012433886528, 'train_grad_norm': 1.0814168453216553, 'epoch': 160}
0:01:08.878624 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.885986 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.416958 - iteration 0
0:01:09.636206 - vxvyvz tensor([[-0.0240,  0.0497,  0.1892]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:09.637212 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.638165 - dR tensor([[[ 0.1325,  0.5424, -0.8296],
         [ 0.8245,  0.4042,  0.3960],
         [ 0.5501, -0.7365, -0.3937]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:09.639025 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:09.642248 - k: tensor([[[ 0.1325,  0.5424, -0.8296, -0.0100],
         [ 0.8245,  0.4042,  0.3960,  0.0062],
         [ 0.5501, -0.7365, -0.3937,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.643193 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.644144 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.645221 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.645880 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.646488 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0481]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:10.621743 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.623024 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.623664 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.624315 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.624920 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0476]
0:01:10.180719 - bracket_assembly_nut_noaug_coarse--479260
0:01:10.180919 - {'grad_norm': 1.0586059093475342, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05565237998962402, 'time_backward': 0.07806873321533203, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269827.3502212, 'n_iterations': 165, 'n_datas': 1320, 'train_loss_TCO-iter=1': 0.04759572818875313, 'train_loss_TCO': 0.04759572818875313, 'train_loss_total': 0.04759572818875313, 'train_grad_norm': 1.0586059093475342, 'epoch': 164}
0:01:10.181052 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:10.188545 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:10.719504 - iteration 0
0:01:10.938490 - vxvyvz tensor([[-0.0219,  0.0451,  0.1918]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:10.939559 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:10.940550 - dR tensor([[[ 0.1104,  0.5652, -0.8175],
         [ 0.8413,  0.3848,  0.3796],
         [ 0.5292, -0.7297, -0.4330]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:10.941418 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:10.944657 - k: tensor([[[ 0.1104,  0.5652, -0.8175, -0.0100],
         [ 0.8413,  0.3848,  0.3796,  0.0062],
         [ 0.5292, -0.7297, -0.4330,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.946095 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.947148 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0575],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.947807 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.948428 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.949030 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0476]
0:01:10.503140 - bracket_assembly_nut_noaug_coarse--479260
0:01:10.503318 - {'grad_norm': 1.0375157594680786, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055764198303222656, 'time_backward': 0.07811808586120605, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269827.6743448, 'n_iterations': 166, 'n_datas': 1328, 'train_loss_TCO-iter=1': 0.04762478172779083, 'train_loss_TCO': 0.04762478172779083, 'train_loss_total': 0.04762478172779083, 'train_grad_norm': 1.0375157594680786, 'epoch': 165}
0:01:10.503434 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:10.510845 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.041785 - iteration 0
0:01:11.260832 - vxvyvz tensor([[-0.0135,  0.0443,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:11.261873 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.262862 - dR tensor([[[ 0.1178,  0.5834, -0.8036],
         [ 0.8330,  0.3825,  0.3998],
         [ 0.5406, -0.7165, -0.4409]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:11.263730 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:11.267179 - k: tensor([[[ 0.1178,  0.5834, -0.8036, -0.0100],
         [ 0.8330,  0.3825,  0.3998,  0.0062],
         [ 0.5406, -0.7165, -0.4409,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.268656 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.269641 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.270239 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.270856 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.271456 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0472]
0:01:10.826747 - bracket_assembly_nut_noaug_coarse--479260
0:01:10.827005 - {'grad_norm': 1.148145079612732, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05584383010864258, 'time_backward': 0.07744622230529785, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269827.9961271, 'n_iterations': 167, 'n_datas': 1336, 'train_loss_TCO-iter=1': 0.047234468162059784, 'train_loss_TCO': 0.047234468162059784, 'train_loss_total': 0.047234468162059784, 'train_grad_norm': 1.148145079612732, 'epoch': 166}
0:01:10.827133 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:10.834623 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.365608 - iteration 0
0:01:11.584539 - vxvyvz tensor([[-0.0153,  0.0511,  0.1943]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:11.585539 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.586531 - dR tensor([[[ 0.1035,  0.5356, -0.8381],
         [ 0.8325,  0.4144,  0.3676],
         [ 0.5442, -0.7358, -0.4030]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:11.587393 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:11.590602 - k: tensor([[[ 0.1035,  0.5356, -0.8381, -0.0100],
         [ 0.8325,  0.4144,  0.3676,  0.0062],
         [ 0.5442, -0.7358, -0.4030,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.591551 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.593035 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.593659 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.594267 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.594896 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0475]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:12.573059 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.574116 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.574733 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.575382 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.576036 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0472]
0:01:12.139856 - bracket_assembly_nut_noaug_coarse--479260
0:01:12.140077 - {'grad_norm': 1.0728005170822144, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05565929412841797, 'time_backward': 0.07729339599609375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269829.3005853, 'n_iterations': 171, 'n_datas': 1368, 'train_loss_TCO-iter=1': 0.04716796055436134, 'train_loss_TCO': 0.04716796055436134, 'train_loss_total': 0.04716796055436134, 'train_grad_norm': 1.0728005170822144, 'epoch': 170}
0:01:12.140189 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.147647 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:12.678691 - iteration 0
0:01:12.897913 - vxvyvz tensor([[-0.0158,  0.0490,  0.1906]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:12.898971 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:12.899966 - dR tensor([[[ 0.0891,  0.5422, -0.8355],
         [ 0.8289,  0.4247,  0.3640],
         [ 0.5522, -0.7250, -0.4116]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:12.900810 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:12.903986 - k: tensor([[[ 0.0891,  0.5422, -0.8355, -0.0100],
         [ 0.8289,  0.4247,  0.3640,  0.0062],
         [ 0.5522, -0.7250, -0.4116,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.905462 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.906510 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.907162 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.907804 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.908425 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0479]
0:01:12.463633 - bracket_assembly_nut_noaug_coarse--479260
0:01:12.463875 - {'grad_norm': 1.0317966938018799, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0560307502746582, 'time_backward': 0.07648038864135742, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269829.632148, 'n_iterations': 172, 'n_datas': 1376, 'train_loss_TCO-iter=1': 0.04785723239183426, 'train_loss_TCO': 0.04785723239183426, 'train_loss_total': 0.04785723239183426, 'train_grad_norm': 1.0317966938018799, 'epoch': 171}
0:01:12.464012 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.471545 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.002433 - iteration 0
0:01:13.221226 - vxvyvz tensor([[-0.0085,  0.0513,  0.1932]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.222248 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.223267 - dR tensor([[[ 0.0905,  0.5620, -0.8222],
         [ 0.8313,  0.4120,  0.3731],
         [ 0.5484, -0.7173, -0.4299]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.224157 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.227340 - k: tensor([[[ 0.0905,  0.5620, -0.8222, -0.0100],
         [ 0.8313,  0.4120,  0.3731,  0.0062],
         [ 0.5484, -0.7173, -0.4299,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.228298 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.229728 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.230413 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.231055 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.231674 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0475]
0:01:12.791021 - bracket_assembly_nut_noaug_coarse--479260
0:01:12.791228 - {'grad_norm': 1.0969651937484741, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05544233322143555, 'time_backward': 0.07726383209228516, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269829.9562266, 'n_iterations': 173, 'n_datas': 1384, 'train_loss_TCO-iter=1': 0.04753246158361435, 'train_loss_TCO': 0.04753246158361435, 'train_loss_total': 0.04753246158361435, 'train_grad_norm': 1.0969651937484741, 'epoch': 172}
0:01:12.791346 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.798874 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.329865 - iteration 0
0:01:13.548815 - vxvyvz tensor([[-0.0159,  0.0552,  0.1889]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.549844 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.550847 - dR tensor([[[ 0.1197,  0.5050, -0.8548],
         [ 0.8297,  0.4220,  0.3655],
         [ 0.5453, -0.7529, -0.3685]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.551729 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.554912 - k: tensor([[[ 0.1197,  0.5050, -0.8548, -0.0100],
         [ 0.8297,  0.4220,  0.3655,  0.0062],
         [ 0.5453, -0.7529, -0.3685,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.556086 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.557422 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0567],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.558058 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.558675 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.559305 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0482]
0:01:13.119064 - bracket_assembly_nut_noaug_coarse--479260
0:01:13.119262 - {'grad_norm': 1.0749881267547607, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055715322494506836, 'time_backward': 0.07729315757751465, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269830.2838805, 'n_iterations': 174, 'n_datas': 1392, 'train_loss_TCO-iter=1': 0.04816438630223274, 'train_loss_TCO': 0.04816438630223274, 'train_loss_total': 0.04816438630223274, 'train_grad_norm': 1.0749881267547607, 'epoch': 173}
0:01:13.119382 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:13.126830 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.657819 - iteration 0
0:01:13.876851 - vxvyvz tensor([[-0.0085,  0.0513,  0.1932]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.877887 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.878873 - dR tensor([[[ 0.0905,  0.5620, -0.8222],
         [ 0.8313,  0.4120,  0.3731],
         [ 0.5484, -0.7173, -0.4299]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.879737 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.882929 - k: tensor([[[ 0.0905,  0.5620, -0.8222, -0.0100],
         [ 0.8313,  0.4120,  0.3731,  0.0062],
         [ 0.5484, -0.7173, -0.4299,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.884399 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.885437 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.886052 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.886652 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.887298 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0475]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:01:14.888915 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:14.890379 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:14.891035 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:14.891654 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:14.892298 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0477]
0:01:14.445594 - bracket_assembly_nut_noaug_coarse--479260
0:01:14.445814 - {'grad_norm': 1.0995056629180908, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05596137046813965, 'time_backward': 0.07824039459228516, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269831.6176145, 'n_iterations': 178, 'n_datas': 1424, 'train_loss_TCO-iter=1': 0.04765055328607559, 'train_loss_TCO': 0.04765055328607559, 'train_loss_total': 0.04765055328607559, 'train_grad_norm': 1.0995056629180908, 'epoch': 177}
0:01:14.445932 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:14.453394 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:14.984372 - iteration 0
0:01:15.203540 - vxvyvz tensor([[-0.0135,  0.0443,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.204618 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.205607 - dR tensor([[[ 0.1178,  0.5835, -0.8036],
         [ 0.8330,  0.3824,  0.3998],
         [ 0.5406, -0.7165, -0.4410]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.206445 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.209728 - k: tensor([[[ 0.1178,  0.5835, -0.8036, -0.0100],
         [ 0.8330,  0.3824,  0.3998,  0.0062],
         [ 0.5406, -0.7165, -0.4410,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.211223 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.212269 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.212889 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.213497 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.214100 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:01:14.768795 - bracket_assembly_nut_noaug_coarse--479260
0:01:14.769009 - {'grad_norm': 1.1485459804534912, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05600619316101074, 'time_backward': 0.0782012939453125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269831.9394515, 'n_iterations': 179, 'n_datas': 1432, 'train_loss_TCO-iter=1': 0.04723261669278145, 'train_loss_TCO': 0.04723261669278145, 'train_loss_total': 0.04723261669278145, 'train_grad_norm': 1.1485459804534912, 'epoch': 178}
0:01:14.769120 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:14.776829 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.307798 - iteration 0
0:01:15.526777 - vxvyvz tensor([[-0.0135,  0.0443,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.527826 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.528791 - dR tensor([[[ 0.1178,  0.5835, -0.8035],
         [ 0.8330,  0.3824,  0.3998],
         [ 0.5406, -0.7164, -0.4410]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.529616 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.532829 - k: tensor([[[ 0.1178,  0.5835, -0.8035, -0.0100],
         [ 0.8330,  0.3824,  0.3998,  0.0062],
         [ 0.5406, -0.7164, -0.4410,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.534423 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.535472 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.536126 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.536751 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.537366 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0472]
0:01:15.093731 - bracket_assembly_nut_noaug_coarse--479260
0:01:15.093934 - {'grad_norm': 1.1487241983413696, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055832862854003906, 'time_backward': 0.07809567451477051, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269832.2625906, 'n_iterations': 180, 'n_datas': 1440, 'train_loss_TCO-iter=1': 0.04724855720996857, 'train_loss_TCO': 0.04724855720996857, 'train_loss_total': 0.04724855720996857, 'train_grad_norm': 1.1487241983413696, 'epoch': 179}
0:01:15.094051 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:15.101678 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.632671 - iteration 0
0:01:15.851798 - vxvyvz tensor([[-0.0103,  0.0466,  0.1934]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.852817 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.853765 - dR tensor([[[ 0.1668,  0.5355, -0.8279],
         [ 0.8331,  0.3726,  0.4088],
         [ 0.5274, -0.7579, -0.3840]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.854594 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.857821 - k: tensor([[[ 0.1668,  0.5355, -0.8279, -0.0100],
         [ 0.8331,  0.3726,  0.4088,  0.0062],
         [ 0.5274, -0.7579, -0.3840,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.859307 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.860324 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.860973 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.861579 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.862180 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0476]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:16.834699 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:16.836200 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0578],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:16.836818 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:16.837420 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:16.838021 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0476]
0:01:16.406032 - bracket_assembly_nut_noaug_coarse--479260
0:01:16.406243 - {'grad_norm': 1.063064455986023, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05579519271850586, 'time_backward': 0.07762718200683594, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269833.5628061, 'n_iterations': 184, 'n_datas': 1472, 'train_loss_TCO-iter=1': 0.0475911982357502, 'train_loss_TCO': 0.0475911982357502, 'train_loss_total': 0.0475911982357502, 'train_grad_norm': 1.063064455986023, 'epoch': 183}
0:01:16.406356 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:16.413826 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:16.944825 - iteration 0
0:01:17.163982 - vxvyvz tensor([[-0.0195,  0.0515,  0.1974]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.164995 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.165945 - dR tensor([[[ 0.1142,  0.5692, -0.8142],
         [ 0.8362,  0.3875,  0.3882],
         [ 0.5364, -0.7251, -0.4317]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.166780 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.169995 - k: tensor([[[ 0.1142,  0.5692, -0.8142, -0.0100],
         [ 0.8362,  0.3875,  0.3882,  0.0062],
         [ 0.5364, -0.7251, -0.4317,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.171460 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.172438 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.173087 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.173692 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.174294 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0471]
0:01:16.732025 - bracket_assembly_nut_noaug_coarse--479260
0:01:16.732235 - {'grad_norm': 1.1087833642959595, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05576968193054199, 'time_backward': 0.07761883735656738, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269833.899094, 'n_iterations': 185, 'n_datas': 1480, 'train_loss_TCO-iter=1': 0.047065988183021545, 'train_loss_TCO': 0.047065988183021545, 'train_loss_total': 0.047065988183021545, 'train_grad_norm': 1.1087833642959595, 'epoch': 184}
0:01:16.732349 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:16.739723 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.270659 - iteration 0
0:01:17.489554 - vxvyvz tensor([[-0.0216,  0.0539,  0.1995]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.490566 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.491563 - dR tensor([[[ 0.0999,  0.5594, -0.8228],
         [ 0.8239,  0.4172,  0.3837],
         [ 0.5579, -0.7162, -0.4192]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.492430 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.495609 - k: tensor([[[ 0.0999,  0.5594, -0.8228, -0.0100],
         [ 0.8239,  0.4172,  0.3837,  0.0062],
         [ 0.5579, -0.7162, -0.4192,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.497020 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.498067 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.498670 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.499298 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.499922 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.047]
0:01:17.058672 - bracket_assembly_nut_noaug_coarse--479260
0:01:17.058899 - {'grad_norm': 1.0132859945297241, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055407047271728516, 'time_backward': 0.0774235725402832, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269834.2244039, 'n_iterations': 186, 'n_datas': 1488, 'train_loss_TCO-iter=1': 0.04695750027894974, 'train_loss_TCO': 0.04695750027894974, 'train_loss_total': 0.04695750027894974, 'train_grad_norm': 1.0132859945297241, 'epoch': 185}
0:01:17.059058 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:17.066446 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.597452 - iteration 0
0:01:17.816474 - vxvyvz tensor([[-0.0087,  0.0508,  0.1959]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.817487 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.818485 - dR tensor([[[ 0.1141,  0.5163, -0.8488],
         [ 0.8288,  0.4215,  0.3679],
         [ 0.5477, -0.7455, -0.3798]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.819352 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.822514 - k: tensor([[[ 0.1141,  0.5163, -0.8488, -0.0100],
         [ 0.8288,  0.4215,  0.3679,  0.0062],
         [ 0.5477, -0.7455, -0.3798,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.823991 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.825028 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0588],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.825644 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.826248 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.826880 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0474]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:18.808116 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:18.809214 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0565],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:18.809854 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:18.810471 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:18.811112 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0481]
0:01:18.365574 - bracket_assembly_nut_noaug_coarse--479260
0:01:18.365774 - {'grad_norm': 1.038244366645813, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05594992637634277, 'time_backward': 0.07822513580322266, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269835.5365417, 'n_iterations': 190, 'n_datas': 1520, 'train_loss_TCO-iter=1': 0.04806603863835335, 'train_loss_TCO': 0.04806603863835335, 'train_loss_total': 0.04806603863835335, 'train_grad_norm': 1.038244366645813, 'epoch': 189}
0:01:18.365890 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:18.373362 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:18.904352 - iteration 0
0:01:19.123504 - vxvyvz tensor([[-0.0123,  0.0451,  0.1975]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:19.124559 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.125536 - dR tensor([[[ 0.1264,  0.5879, -0.7990],
         [ 0.8347,  0.3721,  0.4059],
         [ 0.5359, -0.7183, -0.4437]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:19.126361 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:19.129610 - k: tensor([[[ 0.1264,  0.5879, -0.7990, -0.0100],
         [ 0.8347,  0.3721,  0.4059,  0.0062],
         [ 0.5359, -0.7183, -0.4437,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.131099 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.132124 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.132740 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.133344 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.133945 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.047]
0:01:18.690639 - bracket_assembly_nut_noaug_coarse--479260
0:01:18.690851 - {'grad_norm': 1.148104190826416, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05585193634033203, 'time_backward': 0.0783376693725586, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269835.8593698, 'n_iterations': 191, 'n_datas': 1528, 'train_loss_TCO-iter=1': 0.04700034484267235, 'train_loss_TCO': 0.04700034484267235, 'train_loss_total': 0.04700034484267235, 'train_grad_norm': 1.148104190826416, 'epoch': 190}
0:01:18.690981 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:18.698449 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.229440 - iteration 0
0:01:19.448303 - vxvyvz tensor([[-0.0152,  0.0481,  0.1922]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:19.449320 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.450313 - dR tensor([[[ 0.0953,  0.5874, -0.8036],
         [ 0.8201,  0.4113,  0.3978],
         [ 0.5642, -0.6970, -0.4426]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:19.451183 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:19.454389 - k: tensor([[[ 0.0953,  0.5874, -0.8036, -0.0100],
         [ 0.8201,  0.4113,  0.3978,  0.0062],
         [ 0.5642, -0.6970, -0.4426,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.455345 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.456888 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.457515 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.458122 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.458723 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0476]
0:01:19.016180 - bracket_assembly_nut_noaug_coarse--479260
0:01:19.016371 - {'grad_norm': 1.1567264795303345, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05549907684326172, 'time_backward': 0.07772612571716309, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269836.183611, 'n_iterations': 192, 'n_datas': 1536, 'train_loss_TCO-iter=1': 0.047564662992954254, 'train_loss_TCO': 0.047564662992954254, 'train_loss_total': 0.047564662992954254, 'train_grad_norm': 1.1567264795303345, 'epoch': 191}
0:01:19.016483 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:19.023880 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.554832 - iteration 0
0:01:19.774184 - vxvyvz tensor([[-0.0157,  0.0527,  0.1930]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:19.775247 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.776234 - dR tensor([[[ 0.1059,  0.5338, -0.8389],
         [ 0.8242,  0.4248,  0.3744],
         [ 0.5563, -0.7311, -0.3950]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:19.777055 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:19.780280 - k: tensor([[[ 0.1059,  0.5338, -0.8389, -0.0100],
         [ 0.8242,  0.4248,  0.3744,  0.0062],
         [ 0.5563, -0.7311, -0.3950,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.781204 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.782113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0579],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.782735 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.783383 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.784039 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0477]
0:01:19.343981 - bracket_assembly_nut_noaug_coarse--479260
0:01:19.344203 - {'grad_norm': 1.0195709466934204, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0553898811340332, 'time_backward': 0.07901930809020996, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269836.5102122, 'n_iterations': 193, 'n_datas': 1544, 'train_loss_TCO-iter=1': 0.0476929135620594, 'train_loss_TCO': 0.0476929135620594, 'train_loss_total': 0.0476929135620594, 'train_grad_norm': 1.0195709466934204, 'epoch': 192}
0:01:19.344316 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:19.351972 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.882979 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0578],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.769755 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.770363 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.771002 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0478]
0:01:20.327858 - bracket_assembly_nut_noaug_coarse--479260
0:01:20.328080 - {'grad_norm': 1.0957748889923096, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05571341514587402, 'time_backward': 0.07807421684265137, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269837.4963489, 'n_iterations': 196, 'n_datas': 1568, 'train_loss_TCO-iter=1': 0.04777327552437782, 'train_loss_TCO': 0.04777327552437782, 'train_loss_total': 0.04777327552437782, 'train_grad_norm': 1.0957748889923096, 'epoch': 195}
0:01:20.328214 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:20.335933 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:20.866958 - iteration 0
0:01:21.085834 - vxvyvz tensor([[-0.0135,  0.0442,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:21.086926 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.087931 - dR tensor([[[ 0.1177,  0.5836, -0.8035],
         [ 0.8331,  0.3823,  0.3998],
         [ 0.5405, -0.7164, -0.4412]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:21.088771 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:21.091953 - k: tensor([[[ 0.1177,  0.5836, -0.8035, -0.0100],
         [ 0.8331,  0.3823,  0.3998,  0.0062],
         [ 0.5405, -0.7164, -0.4412,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.092898 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.094405 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.095057 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.095677 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.096318 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
0:01:20.750644 - bracket_assembly_nut_noaug_coarse--479260
0:01:20.750875 - {'grad_norm': 1.148689866065979, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05576372146606445, 'time_backward': 0.07816195487976074, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269837.8216572, 'n_iterations': 197, 'n_datas': 1576, 'train_loss_TCO-iter=1': 0.047234538942575455, 'train_loss_TCO': 0.047234538942575455, 'train_loss_total': 0.047234538942575455, 'train_grad_norm': 1.148689866065979, 'epoch': 196}
0:01:20.751038 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:20.758505 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.289464 - iteration 0
0:01:21.508880 - vxvyvz tensor([[-0.0158,  0.0457,  0.1995]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:21.509895 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.510885 - dR tensor([[[ 0.1313,  0.5460, -0.8275],
         [ 0.8341,  0.3902,  0.3898],
         [ 0.5357, -0.7414, -0.4042]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:21.511754 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:21.514951 - k: tensor([[[ 0.1313,  0.5460, -0.8275, -0.0100],
         [ 0.8341,  0.3902,  0.3898,  0.0062],
         [ 0.5357, -0.7414, -0.4042,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.516121 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.517440 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.518057 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.518664 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.519305 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.047]
       grad_fn=<CopySlices>) 0.8823,  0.0578],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:22.522452 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.523478 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.524129 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.524748 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.525367 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0479]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:21.904457 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.435190 - iteration 0
0:01:22.648052 - vxvyvz tensor([[-0.0045,  0.0029, -0.0344]], device='cuda:0')
0:01:22.649008 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.649927 - dR tensor([[[ 0.6727, -0.7399,  0.0105],
         [-0.1428, -0.1437, -0.9793],
         [ 0.7260,  0.6572, -0.2023]]], device='cuda:0')
0:01:22.650757 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:22.653812 - k: tensor([[[ 0.6727, -0.7399,  0.0105, -0.0100],
         [-0.1428, -0.1437, -0.9793,  0.0062],
         [ 0.7260,  0.6572, -0.2023,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.654712 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.655662 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0103],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.656334 - k: tensor([0.0055], device='cuda:0')
0:01:22.656945 - k: tensor([0.0003], device='cuda:0')
0:01:22.657561 - k: tensor([0.0674], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.49it/s]
0:01:22.140553 - bracket_assembly_nut_noaug_coarse--479260
0:01:22.140788 - {'grad_norm': 1.0355151891708374, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056058406829833984, 'time_backward': 0.08017921447753906, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269839.3036933, 'n_iterations': 201, 'n_datas': 1608, 'train_loss_TCO-iter=1': 0.04791782423853874, 'train_loss_TCO': 0.04791782423853874, 'train_loss_total': 0.04791782423853874, 'train_grad_norm': 1.0355151891708374, 'val_loss_TCO-iter=1': 0.07325664907693863, 'val_loss_TCO': 0.07325664907693863, 'val_loss_total': 0.07325664907693863, 'epoch': 200}
0:01:22.140909 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.148661 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.676351 - iteration 0
0:01:22.896013 - vxvyvz tensor([[-0.0182,  0.0532,  0.1938]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:22.897008 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.897956 - dR tensor([[[ 0.1054,  0.5080, -0.8549],
         [ 0.8110,  0.4536,  0.3695],
         [ 0.5755, -0.7322, -0.3642]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:22.898795 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:22.902026 - k: tensor([[[ 0.1054,  0.5080, -0.8549, -0.0100],
         [ 0.8110,  0.4536,  0.3695,  0.0062],
         [ 0.5755, -0.7322, -0.3642,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.902958 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.903895 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.904526 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.905129 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.905730 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.46it/s, loss=0.0477]
0:01:22.466099 - bracket_assembly_nut_noaug_coarse--479260
0:01:22.466297 - {'grad_norm': 1.0626940727233887, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05291008949279785, 'time_backward': 0.07754945755004883, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269839.6309087, 'n_iterations': 202, 'n_datas': 1616, 'train_loss_TCO-iter=1': 0.047699928283691406, 'train_loss_TCO': 0.047699928283691406, 'train_loss_total': 0.047699928283691406, 'train_grad_norm': 1.0626940727233887, 'epoch': 201}
0:01:22.466412 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.473864 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.004856 - iteration 0
0:01:23.224071 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:23.225097 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.226095 - dR tensor([[[ 0.1177,  0.5837, -0.8034],
         [ 0.8331,  0.3823,  0.3997],
         [ 0.5405, -0.7164, -0.4413]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:23.226952 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:23.230155 - k: tensor([[[ 0.1177,  0.5837, -0.8034, -0.0100],
         [ 0.8331,  0.3823,  0.3997,  0.0062],
         [ 0.5405, -0.7164, -0.4413,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.231096 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.232627 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.233250 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.233855 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.234456 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0473]
0:01:22.798256 - bracket_assembly_nut_noaug_coarse--479260
0:01:22.798453 - {'grad_norm': 1.149727463722229, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055902719497680664, 'time_backward': 0.07746672630310059, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269839.9591062, 'n_iterations': 203, 'n_datas': 1624, 'train_loss_TCO-iter=1': 0.047257330268621445, 'train_loss_TCO': 0.047257330268621445, 'train_loss_total': 0.047257330268621445, 'train_grad_norm': 1.149727463722229, 'epoch': 202}
0:01:22.798567 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.806142 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.337164 - iteration 0
0:01:23.555936 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:23.556934 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.557881 - dR tensor([[[ 0.1177,  0.5837, -0.8034],
         [ 0.8331,  0.3823,  0.3997],
         [ 0.5405, -0.7164, -0.4413]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:23.558706 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:23.561928 - k: tensor([[[ 0.1177,  0.5837, -0.8034, -0.0100],
         [ 0.8331,  0.3823,  0.3997,  0.0062],
         [ 0.5405, -0.7164, -0.4413,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.562869 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.564234 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.564897 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.565506 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.566108 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.8823,  0.0578],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:24.540291 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.541334 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0588],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.541975 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.542595 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.543221 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0472]
0:01:24.096307 - bracket_assembly_nut_noaug_coarse--479260
0:01:24.096525 - {'grad_norm': 1.0282865762710571, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05593419075012207, 'time_backward': 0.07873702049255371, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269841.269062, 'n_iterations': 207, 'n_datas': 1656, 'train_loss_TCO-iter=1': 0.04721547290682793, 'train_loss_TCO': 0.04721547290682793, 'train_loss_total': 0.04721547290682793, 'train_grad_norm': 1.0282865762710571, 'epoch': 206}
0:01:24.096637 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.104294 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.635247 - iteration 0
0:01:24.854335 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:24.855407 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.856417 - dR tensor([[[ 0.1176,  0.5837, -0.8034],
         [ 0.8331,  0.3823,  0.3997],
         [ 0.5404, -0.7163, -0.4413]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:24.857243 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:24.860487 - k: tensor([[[ 0.1176,  0.5837, -0.8034, -0.0100],
         [ 0.8331,  0.3823,  0.3997,  0.0062],
         [ 0.5404, -0.7163, -0.4413,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.861439 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.862965 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.863600 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.864248 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.864850 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0472]
0:01:24.413775 - bracket_assembly_nut_noaug_coarse--479260
0:01:24.413990 - {'grad_norm': 1.1487667560577393, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055936574935913086, 'time_backward': 0.07857704162597656, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269841.5906394, 'n_iterations': 208, 'n_datas': 1664, 'train_loss_TCO-iter=1': 0.04723040759563446, 'train_loss_TCO': 0.04723040759563446, 'train_loss_total': 0.04723040759563446, 'train_grad_norm': 1.1487667560577393, 'epoch': 207}
0:01:24.414116 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.421606 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.952579 - iteration 0
0:01:25.171649 - vxvyvz tensor([[-0.0168,  0.0528,  0.1932]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:25.172703 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.173686 - dR tensor([[[ 0.0857,  0.5490, -0.8314],
         [ 0.8397,  0.4093,  0.3568],
         [ 0.5362, -0.7288, -0.4259]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:25.174515 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:25.177790 - k: tensor([[[ 0.0857,  0.5490, -0.8314, -0.0100],
         [ 0.8397,  0.4093,  0.3568,  0.0062],
         [ 0.5362, -0.7288, -0.4259,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.178709 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.180241 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.180863 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.181471 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.182071 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0475]
0:01:24.732806 - bracket_assembly_nut_noaug_coarse--479260
0:01:24.732998 - {'grad_norm': 1.14970862865448, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05571317672729492, 'time_backward': 0.07864689826965332, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269841.9078982, 'n_iterations': 209, 'n_datas': 1672, 'train_loss_TCO-iter=1': 0.04753284156322479, 'train_loss_TCO': 0.04753284156322479, 'train_loss_total': 0.04753284156322479, 'train_grad_norm': 1.14970862865448, 'epoch': 208}
0:01:24.733109 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.740512 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.271374 - iteration 0
0:01:25.490305 - vxvyvz tensor([[-0.0171,  0.0471,  0.1940]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:25.491352 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.492353 - dR tensor([[[ 0.1113,  0.5621, -0.8196],
         [ 0.8252,  0.4073,  0.3914],
         [ 0.5538, -0.7199, -0.4185]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:25.493180 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:25.496404 - k: tensor([[[ 0.1113,  0.5621, -0.8196, -0.0100],
         [ 0.8252,  0.4073,  0.3914,  0.0062],
         [ 0.5538, -0.7199, -0.4185,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.497865 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.498915 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.499546 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.500193 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.500796 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0475]
       grad_fn=<CopySlices>) 0.8823,  0.0578],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:26.472296 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.473615 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.474231 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.474864 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.475480 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0471]
0:01:26.025543 - bracket_assembly_nut_noaug_coarse--479260
0:01:26.025759 - {'grad_norm': 1.096821904182434, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05561351776123047, 'time_backward': 0.07762432098388672, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269843.2003262, 'n_iterations': 213, 'n_datas': 1704, 'train_loss_TCO-iter=1': 0.04706532135605812, 'train_loss_TCO': 0.04706532135605812, 'train_loss_total': 0.04706532135605812, 'train_grad_norm': 1.096821904182434, 'epoch': 212}
0:01:26.025891 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.033330 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.564292 - iteration 0
0:01:26.783711 - vxvyvz tensor([[-0.0131,  0.0468,  0.2027]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:26.784734 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.785687 - dR tensor([[[ 0.1134,  0.5180, -0.8478],
         [ 0.8249,  0.4266,  0.3710],
         [ 0.5538, -0.7414, -0.3789]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:26.786500 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:26.789746 - k: tensor([[[ 0.1134,  0.5180, -0.8478, -0.0100],
         [ 0.8249,  0.4266,  0.3710,  0.0062],
         [ 0.5538, -0.7414, -0.3789,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.790674 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.792179 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0608],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.792850 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.793457 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.794063 - k: tensor([0.0437], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0468]
0:01:26.359576 - bracket_assembly_nut_noaug_coarse--479260
0:01:26.359831 - {'grad_norm': 1.0743592977523804, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05600380897521973, 'time_backward': 0.07783651351928711, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269843.519166, 'n_iterations': 214, 'n_datas': 1712, 'train_loss_TCO-iter=1': 0.04675731435418129, 'train_loss_TCO': 0.04675731435418129, 'train_loss_total': 0.04675731435418129, 'train_grad_norm': 1.0743592977523804, 'epoch': 213}
0:01:26.359991 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.367469 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.898297 - iteration 0
0:01:27.117314 - vxvyvz tensor([[-0.0143,  0.0465,  0.1924]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:27.118335 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.119328 - dR tensor([[[ 0.0919,  0.5068, -0.8571],
         [ 0.8319,  0.4341,  0.3458],
         [ 0.5473, -0.7448, -0.3817]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:27.120207 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:27.123394 - k: tensor([[[ 0.0919,  0.5068, -0.8571, -0.0100],
         [ 0.8319,  0.4341,  0.3458,  0.0062],
         [ 0.5473, -0.7448, -0.3817,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.124863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.125937 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.126566 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.127206 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.127845 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0478]
0:01:26.680975 - bracket_assembly_nut_noaug_coarse--479260
0:01:26.681173 - {'grad_norm': 1.1160825490951538, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055611371994018555, 'time_backward': 0.07814192771911621, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269843.8531432, 'n_iterations': 215, 'n_datas': 1720, 'train_loss_TCO-iter=1': 0.04775817692279816, 'train_loss_TCO': 0.04775817692279816, 'train_loss_total': 0.04775817692279816, 'train_grad_norm': 1.1160825490951538, 'epoch': 214}
0:01:26.681310 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.688751 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.219718 - iteration 0
0:01:27.438651 - vxvyvz tensor([[-0.0181,  0.0527,  0.1907]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:27.439714 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.440685 - dR tensor([[[ 0.0999,  0.4892, -0.8664],
         [ 0.8299,  0.4394,  0.3438],
         [ 0.5489, -0.7534, -0.3621]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:27.441513 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:27.444740 - k: tensor([[[ 0.0999,  0.4892, -0.8664, -0.0100],
         [ 0.8299,  0.4394,  0.3438,  0.0062],
         [ 0.5489, -0.7534, -0.3621,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.445641 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.447082 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.447792 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.448414 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.449033 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0481]
0:01:26.999935 - bracket_assembly_nut_noaug_coarse--479260
0:01:27.000133 - {'grad_norm': 1.0510568618774414, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055579423904418945, 'time_backward': 0.07769942283630371, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269844.1738918, 'n_iterations': 216, 'n_datas': 1728, 'train_loss_TCO-iter=1': 0.048067592084407806, 'train_loss_TCO': 0.048067592084407806, 'train_loss_total': 0.048067592084407806, 'train_grad_norm': 1.0510568618774414, 'epoch': 215}
0:01:27.000270 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:27.007716 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.538616 - iteration 0
0:01:27.757445 - vxvyvz tensor([[-0.0173,  0.0510,  0.1901]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:27.758455 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.759448 - dR tensor([[[ 0.1215,  0.5208, -0.8450],
         [ 0.8362,  0.4049,  0.3698],
         [ 0.5348, -0.7515, -0.3863]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:27.760318 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:27.763465 - k: tensor([[[ 0.1215,  0.5208, -0.8450, -0.0100],
         [ 0.8362,  0.4049,  0.3698,  0.0062],
         [ 0.5348, -0.7515, -0.3863,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.764409 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.765870 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0570],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.766553 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.767198 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.767839 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                         | 0/1 [00:00<?, ?it/s, loss=0.048]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:01:28.730306 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.731380 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.732047 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.732651 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.733253 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0475]
0:01:28.301610 - bracket_assembly_nut_noaug_coarse--479260
0:01:28.301859 - {'grad_norm': 1.0720345973968506, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05568194389343262, 'time_backward': 0.07822155952453613, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269845.4586697, 'n_iterations': 220, 'n_datas': 1760, 'train_loss_TCO-iter=1': 0.0474814772605896, 'train_loss_TCO': 0.0474814772605896, 'train_loss_total': 0.0474814772605896, 'train_grad_norm': 1.0720345973968506, 'epoch': 219}
0:01:28.301975 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:28.309544 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:28.840619 - iteration 0
0:01:29.060472 - vxvyvz tensor([[-0.0230,  0.0479,  0.1944]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.061484 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.062438 - dR tensor([[[ 0.0940,  0.5607, -0.8227],
         [ 0.8135,  0.4331,  0.3881],
         [ 0.5739, -0.7058, -0.4154]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:29.063307 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:29.066520 - k: tensor([[[ 0.0940,  0.5607, -0.8227, -0.0100],
         [ 0.8135,  0.4331,  0.3881,  0.0062],
         [ 0.5739, -0.7058, -0.4154,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.068043 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.069040 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.069656 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.070261 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.070895 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0475]
0:01:28.663250 - bracket_assembly_nut_noaug_coarse--479260
0:01:28.663477 - {'grad_norm': 1.1136733293533325, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056700944900512695, 'time_backward': 0.07827067375183105, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269845.7965508, 'n_iterations': 221, 'n_datas': 1768, 'train_loss_TCO-iter=1': 0.047468360513448715, 'train_loss_TCO': 0.047468360513448715, 'train_loss_total': 0.047468360513448715, 'train_grad_norm': 1.1136733293533325, 'epoch': 220}
0:01:28.663603 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:28.671273 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.202325 - iteration 0
0:01:29.422082 - vxvyvz tensor([[-0.0198,  0.0585,  0.1871]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.423146 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.424151 - dR tensor([[[ 0.0957,  0.6079, -0.7882],
         [ 0.8347,  0.3824,  0.3963],
         [ 0.5424, -0.6959, -0.4708]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:29.424980 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:29.428250 - k: tensor([[[ 0.0957,  0.6079, -0.7882, -0.0100],
         [ 0.8347,  0.3824,  0.3963,  0.0062],
         [ 0.5424, -0.6959, -0.4708,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.429174 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.430669 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0561],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.431332 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.431979 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.432601 - k: tensor([0.0453], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.048]
0:01:28.998307 - bracket_assembly_nut_noaug_coarse--479260
0:01:28.998555 - {'grad_norm': 1.0338412523269653, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056673288345336914, 'time_backward': 0.08017230033874512, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269846.1601615, 'n_iterations': 222, 'n_datas': 1776, 'train_loss_TCO-iter=1': 0.04795214906334877, 'train_loss_TCO': 0.04795214906334877, 'train_loss_total': 0.04795214906334877, 'train_grad_norm': 1.0338412523269653, 'epoch': 221}
0:01:28.998672 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:29.006292 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.537359 - iteration 0
0:01:29.757556 - vxvyvz tensor([[-0.0184,  0.0512,  0.1983]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.758595 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.759618 - dR tensor([[[ 0.0998,  0.5141, -0.8519],
         [ 0.8418,  0.4128,  0.3478],
         [ 0.5305, -0.7518, -0.3916]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:29.760489 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:29.763788 - k: tensor([[[ 0.0998,  0.5141, -0.8519, -0.0100],
         [ 0.8418,  0.4128,  0.3478,  0.0062],
         [ 0.5305, -0.7518, -0.3916,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.765267 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.766323 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.766978 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.767598 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.768243 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:30.759642 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:30.760695 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:30.761314 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:30.761919 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:30.762522 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0475]
0:01:30.314876 - bracket_assembly_nut_noaug_coarse--479260
0:01:30.315107 - {'grad_norm': 1.073019027709961, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0558621883392334, 'time_backward': 0.07798528671264648, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269847.4875708, 'n_iterations': 226, 'n_datas': 1808, 'train_loss_TCO-iter=1': 0.04749864712357521, 'train_loss_TCO': 0.04749864712357521, 'train_loss_total': 0.04749864712357521, 'train_grad_norm': 1.073019027709961, 'epoch': 225}
0:01:30.315289 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.323216 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:30.854170 - iteration 0
0:01:31.073855 - vxvyvz tensor([[-0.0173,  0.0524,  0.1948]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.074899 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.075906 - dR tensor([[[ 0.1248,  0.5265, -0.8410],
         [ 0.8266,  0.4137,  0.3817],
         [ 0.5488, -0.7427, -0.3836]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.076740 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.079949 - k: tensor([[[ 0.1248,  0.5265, -0.8410, -0.0100],
         [ 0.8266,  0.4137,  0.3817,  0.0062],
         [ 0.5488, -0.7427, -0.3836,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.080920 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.082410 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0584],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.083165 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.083827 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.084441 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0475]
0:01:30.639421 - bracket_assembly_nut_noaug_coarse--479260
0:01:30.639629 - {'grad_norm': 1.1321402788162231, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056534767150878906, 'time_backward': 0.07805657386779785, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269847.8097963, 'n_iterations': 227, 'n_datas': 1816, 'train_loss_TCO-iter=1': 0.04754692316055298, 'train_loss_TCO': 0.04754692316055298, 'train_loss_total': 0.04754692316055298, 'train_grad_norm': 1.1321402788162231, 'epoch': 226}
0:01:30.639761 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.647186 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.178111 - iteration 0
0:01:31.397081 - vxvyvz tensor([[-0.0151,  0.0481,  0.1922]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.398107 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.399117 - dR tensor([[[ 0.0951,  0.5877, -0.8034],
         [ 0.8202,  0.4110,  0.3978],
         [ 0.5640, -0.6969, -0.4430]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.399982 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.403120 - k: tensor([[[ 0.0951,  0.5877, -0.8034, -0.0100],
         [ 0.8202,  0.4110,  0.3978,  0.0062],
         [ 0.5640, -0.6969, -0.4430,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.404058 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.405525 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.406127 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.406732 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.407378 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0476]
0:01:30.958575 - bracket_assembly_nut_noaug_coarse--479260
0:01:30.958788 - {'grad_norm': 1.1582791805267334, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055444955825805664, 'time_backward': 0.07785749435424805, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269848.1325288, 'n_iterations': 228, 'n_datas': 1824, 'train_loss_TCO-iter=1': 0.04760471358895302, 'train_loss_TCO': 0.04760471358895302, 'train_loss_total': 0.04760471358895302, 'train_grad_norm': 1.1582791805267334, 'epoch': 227}
0:01:30.958917 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.966357 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.497309 - iteration 0
0:01:31.716469 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.717500 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.718501 - dR tensor([[[ 0.1176,  0.5839, -0.8033],
         [ 0.8332,  0.3821,  0.3997],
         [ 0.5403, -0.7163, -0.4416]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.719370 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.722553 - k: tensor([[[ 0.1176,  0.5839, -0.8033, -0.0100],
         [ 0.8332,  0.3821,  0.3997,  0.0062],
         [ 0.5403, -0.7163, -0.4416,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.723559 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.725079 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.725702 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.726307 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.726943 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:32.680247 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:32.681729 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:32.682433 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:32.683079 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:32.683717 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0475]
0:01:32.243609 - bracket_assembly_nut_noaug_coarse--479260
0:01:32.243813 - {'grad_norm': 1.0754765272140503, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05546998977661133, 'time_backward': 0.07756638526916504, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269849.408429, 'n_iterations': 232, 'n_datas': 1856, 'train_loss_TCO-iter=1': 0.047508951276540756, 'train_loss_TCO': 0.047508951276540756, 'train_loss_total': 0.047508951276540756, 'train_grad_norm': 1.0754765272140503, 'epoch': 231}
0:01:32.243976 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:32.251359 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:32.782186 - iteration 0
0:01:33.001387 - vxvyvz tensor([[-0.0154,  0.0465,  0.1954]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.002411 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.003408 - dR tensor([[[ 0.0901,  0.5546, -0.8272],
         [ 0.8415,  0.4019,  0.3611],
         [ 0.5327, -0.7286, -0.4305]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.004281 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.007479 - k: tensor([[[ 0.0901,  0.5546, -0.8272, -0.0100],
         [ 0.8415,  0.4019,  0.3611,  0.0062],
         [ 0.5327, -0.7286, -0.4305,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.008966 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.010067 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.010684 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.011330 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.011969 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0473]
0:01:32.560821 - bracket_assembly_nut_noaug_coarse--479260
0:01:32.561033 - {'grad_norm': 1.036378026008606, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055829763412475586, 'time_backward': 0.07805371284484863, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269849.7372432, 'n_iterations': 233, 'n_datas': 1864, 'train_loss_TCO-iter=1': 0.0472835898399353, 'train_loss_TCO': 0.0472835898399353, 'train_loss_total': 0.0472835898399353, 'train_grad_norm': 1.036378026008606, 'epoch': 232}
0:01:32.561150 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:32.568620 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.099534 - iteration 0
0:01:33.318800 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.319850 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.320822 - dR tensor([[[ 0.1175,  0.5840, -0.8032],
         [ 0.8332,  0.3821,  0.3997],
         [ 0.5403, -0.7163, -0.4417]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.321651 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.324856 - k: tensor([[[ 0.1175,  0.5840, -0.8032, -0.0100],
         [ 0.8332,  0.3821,  0.3997,  0.0062],
         [ 0.5403, -0.7163, -0.4417,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.326327 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.327363 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.328032 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.328636 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.329241 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0472]
0:01:32.877160 - bracket_assembly_nut_noaug_coarse--479260
0:01:32.877375 - {'grad_norm': 1.1475932598114014, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05592632293701172, 'time_backward': 0.0774984359741211, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269850.0539823, 'n_iterations': 234, 'n_datas': 1872, 'train_loss_TCO-iter=1': 0.0471985898911953, 'train_loss_TCO': 0.0471985898911953, 'train_loss_total': 0.0471985898911953, 'train_grad_norm': 1.1475932598114014, 'epoch': 233}
0:01:32.877543 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:32.884882 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.415811 - iteration 0
0:01:33.634682 - vxvyvz tensor([[-0.0128,  0.0462,  0.1972]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.635758 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.636736 - dR tensor([[[ 0.0756,  0.5220, -0.8496],
         [ 0.8326,  0.4358,  0.3418],
         [ 0.5486, -0.7332, -0.4017]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.637577 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.640798 - k: tensor([[[ 0.0756,  0.5220, -0.8496, -0.0100],
         [ 0.8326,  0.4358,  0.3418,  0.0062],
         [ 0.5486, -0.7332, -0.4017,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.641705 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.643261 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.643920 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.644541 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.645145 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0473]
0:01:33.199773 - bracket_assembly_nut_noaug_coarse--479260
0:01:33.199995 - {'grad_norm': 1.0844014883041382, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05554676055908203, 'time_backward': 0.07790565490722656, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269850.3701818, 'n_iterations': 235, 'n_datas': 1880, 'train_loss_TCO-iter=1': 0.04725552350282669, 'train_loss_TCO': 0.04725552350282669, 'train_loss_total': 0.04725552350282669, 'train_grad_norm': 1.0844014883041382, 'epoch': 234}
0:01:33.200174 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:33.207627 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.738533 - iteration 0
0:01:33.957426 - vxvyvz tensor([[-0.0195,  0.0498,  0.1967]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.958425 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.959419 - dR tensor([[[ 0.0976,  0.5668, -0.8180],
         [ 0.8432,  0.3895,  0.3705],
         [ 0.5286, -0.7260, -0.4399]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.960303 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.963480 - k: tensor([[[ 0.0976,  0.5668, -0.8180, -0.0100],
         [ 0.8432,  0.3895,  0.3705,  0.0062],
         [ 0.5286, -0.7260, -0.4399,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.964425 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.965347 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0590],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.965974 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.966615 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.967717 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0471]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:01:34.949061 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:34.950082 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0602],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:34.950710 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:34.951356 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:34.952004 - k: tensor([0.0439], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0468]
0:01:34.534130 - bracket_assembly_nut_noaug_coarse--479260
0:01:34.534322 - {'grad_norm': 0.9966574311256409, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05569767951965332, 'time_backward': 0.07823467254638672, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269851.6774638, 'n_iterations': 239, 'n_datas': 1912, 'train_loss_TCO-iter=1': 0.04676157981157303, 'train_loss_TCO': 0.04676157981157303, 'train_loss_total': 0.04676157981157303, 'train_grad_norm': 0.9966574311256409, 'epoch': 238}
0:01:34.534436 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:34.541945 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.072931 - iteration 0
0:01:35.292114 - vxvyvz tensor([[-0.0135,  0.0442,  0.1955]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.293115 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.294077 - dR tensor([[[ 0.1175,  0.5840, -0.8032],
         [ 0.8332,  0.3820,  0.3997],
         [ 0.5403, -0.7162, -0.4417]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.294944 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.298174 - k: tensor([[[ 0.1175,  0.5840, -0.8032, -0.0100],
         [ 0.8332,  0.3820,  0.3997,  0.0062],
         [ 0.5403, -0.7162, -0.4417,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.299118 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.300558 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.301263 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.301873 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.302492 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0472]
0:01:34.872924 - bracket_assembly_nut_noaug_coarse--479260
0:01:34.873146 - {'grad_norm': 1.1462733745574951, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05584001541137695, 'time_backward': 0.07726168632507324, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269852.0270667, 'n_iterations': 240, 'n_datas': 1920, 'train_loss_TCO-iter=1': 0.04716935753822327, 'train_loss_TCO': 0.04716935753822327, 'train_loss_total': 0.04716935753822327, 'train_grad_norm': 1.1462733745574951, 'epoch': 239}
0:01:34.873262 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:34.880752 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.411777 - iteration 0
0:01:35.631607 - vxvyvz tensor([[-0.0156,  0.0472,  0.1935]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.632639 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.633591 - dR tensor([[[ 0.0870,  0.5454, -0.8337],
         [ 0.8341,  0.4178,  0.3603],
         [ 0.5448, -0.7267, -0.4185]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.634415 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.637647 - k: tensor([[[ 0.0870,  0.5454, -0.8337, -0.0100],
         [ 0.8341,  0.4178,  0.3603,  0.0062],
         [ 0.5448, -0.7267, -0.4185,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.639113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.640142 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.640778 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.641382 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.641985 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0475]
0:01:35.202890 - bracket_assembly_nut_noaug_coarse--479260
0:01:35.203131 - {'grad_norm': 1.119781255722046, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0565648078918457, 'time_backward': 0.07814455032348633, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269852.3688245, 'n_iterations': 241, 'n_datas': 1928, 'train_loss_TCO-iter=1': 0.0475257970392704, 'train_loss_TCO': 0.0475257970392704, 'train_loss_total': 0.0475257970392704, 'train_grad_norm': 1.119781255722046, 'epoch': 240}
0:01:35.203247 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:35.210901 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.741870 - iteration 0
0:01:35.960953 - vxvyvz tensor([[-0.0166,  0.0489,  0.1926]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.962026 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.963042 - dR tensor([[[ 0.0996,  0.5358, -0.8385],
         [ 0.8327,  0.4164,  0.3650],
         [ 0.5446, -0.7346, -0.4047]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.963912 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.967102 - k: tensor([[[ 0.0996,  0.5358, -0.8385, -0.0100],
         [ 0.8327,  0.4164,  0.3650,  0.0062],
         [ 0.5446, -0.7346, -0.4047,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.968060 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.969549 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0578],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.970165 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.970800 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.971422 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0477]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:01:36.964072 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:36.965074 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:36.965691 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:36.966298 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:36.966937 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.06it/s, loss=0.0477]
0:01:36.525281 - bracket_assembly_nut_noaug_coarse--479260
0:01:36.525498 - {'grad_norm': 1.0695894956588745, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0561826229095459, 'time_backward': 0.08153891563415527, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269853.69584, 'n_iterations': 245, 'n_datas': 1960, 'train_loss_TCO-iter=1': 0.04768862947821617, 'train_loss_TCO': 0.04768862947821617, 'train_loss_total': 0.04768862947821617, 'train_grad_norm': 1.0695894956588745, 'epoch': 244}
0:01:36.525606 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:36.533054 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.064011 - iteration 0
0:01:37.283242 - vxvyvz tensor([[-0.0123,  0.0451,  0.1975]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:37.284284 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.285258 - dR tensor([[[ 0.1262,  0.5883, -0.7987],
         [ 0.8349,  0.3718,  0.4058],
         [ 0.5357, -0.7181, -0.4443]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:37.286084 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:37.289341 - k: tensor([[[ 0.1262,  0.5883, -0.7987, -0.0100],
         [ 0.8349,  0.3718,  0.4058,  0.0062],
         [ 0.5357, -0.7181, -0.4443,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.290789 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.291822 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0593],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.292454 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.293077 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.293698 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.047]
0:01:36.858087 - bracket_assembly_nut_noaug_coarse--479260
0:01:36.858312 - {'grad_norm': 1.14849054813385, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05597233772277832, 'time_backward': 0.07915377616882324, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269854.020112, 'n_iterations': 246, 'n_datas': 1968, 'train_loss_TCO-iter=1': 0.046982601284980774, 'train_loss_TCO': 0.046982601284980774, 'train_loss_total': 0.046982601284980774, 'train_grad_norm': 1.14849054813385, 'epoch': 245}
0:01:36.858427 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:36.865984 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.396996 - iteration 0
0:01:37.616590 - vxvyvz tensor([[-0.0118,  0.0441,  0.1938]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:37.617653 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.618610 - dR tensor([[[ 0.1586,  0.5326, -0.8314],
         [ 0.8202,  0.3977,  0.4112],
         [ 0.5496, -0.7471, -0.3738]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:37.619480 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:37.622659 - k: tensor([[[ 0.1586,  0.5326, -0.8314, -0.0100],
         [ 0.8202,  0.3977,  0.4112,  0.0062],
         [ 0.5496, -0.7471, -0.3738,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.623976 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.625244 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.625864 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.626468 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.627109 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0476]
0:01:37.176989 - bracket_assembly_nut_noaug_coarse--479260
0:01:37.177183 - {'grad_norm': 1.0125752687454224, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05645895004272461, 'time_backward': 0.0786905288696289, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269854.3529615, 'n_iterations': 247, 'n_datas': 1976, 'train_loss_TCO-iter=1': 0.047647345811128616, 'train_loss_TCO': 0.047647345811128616, 'train_loss_total': 0.047647345811128616, 'train_grad_norm': 1.0125752687454224, 'epoch': 246}
0:01:37.177297 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:37.184757 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.715732 - iteration 0
0:01:37.934978 - vxvyvz tensor([[-0.0085,  0.0512,  0.1932]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:37.936018 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.936996 - dR tensor([[[ 0.0903,  0.5625, -0.8218],
         [ 0.8315,  0.4116,  0.3730],
         [ 0.5481, -0.7171, -0.4306]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:37.937821 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:37.941063 - k: tensor([[[ 0.0903,  0.5625, -0.8218, -0.0100],
         [ 0.8315,  0.4116,  0.3730,  0.0062],
         [ 0.5481, -0.7171, -0.4306,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.942498 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.943585 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.944242 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.944848 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.945453 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0475]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:38.928290 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:38.929808 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:38.930429 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:38.931081 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:38.931720 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0473]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:38.309330 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:38.840163 - iteration 0
0:01:39.053152 - vxvyvz tensor([[ 0.0024, -0.0049, -0.0445]], device='cuda:0')
0:01:39.054142 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.055075 - dR tensor([[[ 6.7759e-01, -7.3544e-01, -3.2168e-04],
         [-1.2893e-01, -1.1836e-01, -9.8457e-01],
         [ 7.2405e-01,  6.6717e-01, -1.7502e-01]]], device='cuda:0')
0:01:39.055946 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.058959 - k: tensor([[[ 6.7759e-01, -7.3544e-01, -3.2168e-04, -1.0004e-02],
         [-1.2893e-01, -1.1836e-01, -9.8457e-01,  6.1788e-03],
         [ 7.2405e-01,  6.6717e-01, -1.7502e-01,  1.9197e-01],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0')
0:01:39.059902 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.060839 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0133],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.061461 - k: tensor([0.0055], device='cuda:0')
0:01:39.062089 - k: tensor([0.0003], device='cuda:0')
0:01:39.062700 - k: tensor([0.0684], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.38it/s]
0:01:38.537136 - bracket_assembly_nut_noaug_coarse--479260
0:01:38.537359 - {'grad_norm': 1.0827494859695435, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056235551834106445, 'time_backward': 0.07866668701171875, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269855.7088456, 'n_iterations': 251, 'n_datas': 2008, 'train_loss_TCO-iter=1': 0.04725831374526024, 'train_loss_TCO': 0.04725831374526024, 'train_loss_total': 0.04725831374526024, 'train_grad_norm': 1.0827494859695435, 'val_loss_TCO-iter=1': 0.0742352232336998, 'val_loss_TCO': 0.0742352232336998, 'val_loss_total': 0.0742352232336998, 'epoch': 250}
0:01:38.537497 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:38.545133 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.072835 - iteration 0
0:01:39.292617 - vxvyvz tensor([[-0.0135,  0.0442,  0.1956]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:39.293631 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.294583 - dR tensor([[[ 0.1175,  0.5841, -0.8031],
         [ 0.8333,  0.3820,  0.3997],
         [ 0.5402, -0.7162, -0.4419]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:39.295460 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.298630 - k: tensor([[[ 0.1175,  0.5841, -0.8031, -0.0100],
         [ 0.8333,  0.3820,  0.3997,  0.0062],
         [ 0.5402, -0.7162, -0.4419,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.299575 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.300511 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.301155 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.301764 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.302915 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.43it/s, loss=0.0472]
0:01:38.868131 - bracket_assembly_nut_noaug_coarse--479260
0:01:38.868337 - {'grad_norm': 1.1470634937286377, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.053269386291503906, 'time_backward': 0.07752156257629395, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269856.0277038, 'n_iterations': 252, 'n_datas': 2016, 'train_loss_TCO-iter=1': 0.047171588987112045, 'train_loss_TCO': 0.047171588987112045, 'train_loss_total': 0.047171588987112045, 'train_grad_norm': 1.1470634937286377, 'epoch': 251}
0:01:38.868473 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:38.876179 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.407180 - iteration 0
0:01:39.626633 - vxvyvz tensor([[-0.0145,  0.0501,  0.1953]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:39.627687 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.628670 - dR tensor([[[ 0.1170,  0.5399, -0.8335],
         [ 0.8279,  0.4106,  0.3822],
         [ 0.5485, -0.7348, -0.3989]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:39.629520 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.632764 - k: tensor([[[ 0.1170,  0.5399, -0.8335, -0.0100],
         [ 0.8279,  0.4106,  0.3822,  0.0062],
         [ 0.5485, -0.7348, -0.3989,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.634277 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.635343 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0586],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.635996 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.636643 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.637259 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0474]
0:01:39.188663 - bracket_assembly_nut_noaug_coarse--479260
0:01:39.188881 - {'grad_norm': 0.9793853163719177, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05639481544494629, 'time_backward': 0.07746720314025879, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269856.362022, 'n_iterations': 253, 'n_datas': 2024, 'train_loss_TCO-iter=1': 0.047389138489961624, 'train_loss_TCO': 0.047389138489961624, 'train_loss_total': 0.047389138489961624, 'train_grad_norm': 0.9793853163719177, 'epoch': 252}
0:01:39.189000 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:39.196523 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.727577 - iteration 0
0:01:39.946904 - vxvyvz tensor([[-0.0135,  0.0442,  0.1956]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:39.947941 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.948905 - dR tensor([[[ 0.1175,  0.5841, -0.8031],
         [ 0.8333,  0.3819,  0.3997],
         [ 0.5402, -0.7162, -0.4419]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:39.949732 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.952924 - k: tensor([[[ 0.1175,  0.5841, -0.8031, -0.0100],
         [ 0.8333,  0.3819,  0.3997,  0.0062],
         [ 0.5402, -0.7162, -0.4419,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.954160 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.955435 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.956099 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.956732 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.957346 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:40.912892 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:40.914349 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0593],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:40.915002 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:40.915621 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:40.916262 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.047]
0:01:40.468445 - bracket_assembly_nut_noaug_coarse--479260
0:01:40.468655 - {'grad_norm': 1.1491020917892456, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05570554733276367, 'time_backward': 0.0784912109375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269857.6419382, 'n_iterations': 257, 'n_datas': 2056, 'train_loss_TCO-iter=1': 0.04699241369962692, 'train_loss_TCO': 0.04699241369962692, 'train_loss_total': 0.04699241369962692, 'train_grad_norm': 1.1491020917892456, 'epoch': 256}
0:01:40.468768 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:40.476333 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.007298 - iteration 0
0:01:41.227537 - vxvyvz tensor([[-0.0135,  0.0442,  0.1956]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:41.228572 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.229504 - dR tensor([[[ 0.1174,  0.5842, -0.8031],
         [ 0.8333,  0.3819,  0.3997],
         [ 0.5402, -0.7162, -0.4419]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:41.230310 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:41.233491 - k: tensor([[[ 0.1174,  0.5842, -0.8031, -0.0100],
         [ 0.8333,  0.3819,  0.3997,  0.0062],
         [ 0.5402, -0.7162, -0.4419,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.234972 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.235898 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.236508 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.237096 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.237680 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0472]
0:01:40.831166 - bracket_assembly_nut_noaug_coarse--479260
0:01:40.831379 - {'grad_norm': 1.1473289728164673, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05664253234863281, 'time_backward': 0.07914900779724121, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269857.9639313, 'n_iterations': 258, 'n_datas': 2064, 'train_loss_TCO-iter=1': 0.04720796272158623, 'train_loss_TCO': 0.04720796272158623, 'train_loss_total': 0.04720796272158623, 'train_grad_norm': 1.1473289728164673, 'epoch': 257}
0:01:40.831515 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:40.839165 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.370083 - iteration 0
0:01:41.589612 - vxvyvz tensor([[-0.0184,  0.0511,  0.1983]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:41.590614 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.591615 - dR tensor([[[ 0.0997,  0.5144, -0.8517],
         [ 0.8419,  0.4126,  0.3478],
         [ 0.5303, -0.7518, -0.3919]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:41.592489 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:41.595684 - k: tensor([[[ 0.0997,  0.5144, -0.8517, -0.0100],
         [ 0.8419,  0.4126,  0.3478,  0.0062],
         [ 0.5303, -0.7518, -0.3919,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.596652 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.598110 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.598762 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.599398 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.600052 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0471]
0:01:41.189817 - bracket_assembly_nut_noaug_coarse--479260
0:01:41.190042 - {'grad_norm': 1.049480676651001, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0562138557434082, 'time_backward': 0.07944917678833008, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269858.3266811, 'n_iterations': 259, 'n_datas': 2072, 'train_loss_TCO-iter=1': 0.04713890329003334, 'train_loss_TCO': 0.04713890329003334, 'train_loss_total': 0.04713890329003334, 'train_grad_norm': 1.049480676651001, 'epoch': 258}
0:01:41.190161 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:41.197749 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.728764 - iteration 0
0:01:41.947977 - vxvyvz tensor([[-0.0166,  0.0489,  0.1926]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:41.948970 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.949927 - dR tensor([[[ 0.0995,  0.5359, -0.8384],
         [ 0.8328,  0.4163,  0.3649],
         [ 0.5446, -0.7345, -0.4049]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:41.950755 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:41.954017 - k: tensor([[[ 0.0995,  0.5359, -0.8384, -0.0100],
         [ 0.8328,  0.4163,  0.3649,  0.0062],
         [ 0.5446, -0.7345, -0.4049,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.955493 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.956504 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0578],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.957123 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.957726 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.958328 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0476]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:01:42.955435 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:42.956952 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:42.957571 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:42.958178 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:42.958807 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0471]
0:01:42.514117 - bracket_assembly_nut_noaug_coarse--479260
0:01:42.514341 - {'grad_norm': 1.1404902935028076, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05530548095703125, 'time_backward': 0.07784509658813477, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269859.6839142, 'n_iterations': 263, 'n_datas': 2104, 'train_loss_TCO-iter=1': 0.047096528112888336, 'train_loss_TCO': 0.047096528112888336, 'train_loss_total': 0.047096528112888336, 'train_grad_norm': 1.1404902935028076, 'epoch': 262}
0:01:42.514476 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:42.522013 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.052996 - iteration 0
0:01:43.273209 - vxvyvz tensor([[-0.0200,  0.0501,  0.1984]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:43.274288 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.275301 - dR tensor([[[ 0.0945,  0.5233, -0.8469],
         [ 0.8516,  0.3981,  0.3410],
         [ 0.5156, -0.7534, -0.4080]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:43.276168 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:43.279343 - k: tensor([[[ 0.0945,  0.5233, -0.8469, -0.0100],
         [ 0.8516,  0.3981,  0.3410,  0.0062],
         [ 0.5156, -0.7534, -0.4080,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.280280 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.281666 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.282362 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.282985 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.283585 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.0471]
0:01:42.840168 - bracket_assembly_nut_noaug_coarse--479260
0:01:42.840377 - {'grad_norm': 1.140019178390503, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05692911148071289, 'time_backward': 0.07904863357543945, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269860.0098643, 'n_iterations': 264, 'n_datas': 2112, 'train_loss_TCO-iter=1': 0.047083597630262375, 'train_loss_TCO': 0.047083597630262375, 'train_loss_total': 0.047083597630262375, 'train_grad_norm': 1.140019178390503, 'epoch': 263}
0:01:42.840509 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:42.848082 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.379087 - iteration 0
0:01:43.598271 - vxvyvz tensor([[-0.0135,  0.0442,  0.1956]], device='cuda:0',
       grad_fn=<SliceBackward0>)
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:04:52.241691 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:52.242296 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:52.242940 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0474]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:04:53.279613 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.280985 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.281671 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.282291 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.282924 - k: tensor([0.0448], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0477]
0:04:52.838280 - bracket_assembly_nut_noaug_coarse--479260
0:04:52.838482 - {'grad_norm': 1.130066990852356, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05597329139709473, 'time_backward': 0.07886981964111328, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270050.0089295, 'n_iterations': 270, 'n_datas': 2160, 'train_loss_TCO-iter=1': 0.0477343425154686, 'train_loss_TCO': 0.0477343425154686, 'train_loss_total': 0.0477343425154686, 'train_grad_norm': 1.130066990852356, 'epoch': 269}
0:04:52.838595 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:52.846047 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:53.377021 - iteration 0
0:04:53.596350 - vxvyvz tensor([[-0.0178,  0.0508,  0.1925]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:53.597343 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:53.598326 - dR tensor([[[ 0.1438,  0.5564, -0.8183],
         [ 0.8434,  0.3638,  0.3955],
         [ 0.5178, -0.7470, -0.4170]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:53.599191 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:53.602396 - k: tensor([[[ 0.1438,  0.5564, -0.8183, -0.0100],
         [ 0.8434,  0.3638,  0.3955,  0.0062],
         [ 0.5178, -0.7470, -0.4170,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.603869 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.604922 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0577],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.605548 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.606154 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.606773 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0476]
0:04:53.164000 - bracket_assembly_nut_noaug_coarse--479260
0:04:53.164212 - {'grad_norm': 1.0251710414886475, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05602526664733887, 'time_backward': 0.07819509506225586, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270050.3339093, 'n_iterations': 271, 'n_datas': 2168, 'train_loss_TCO-iter=1': 0.04755829647183418, 'train_loss_TCO': 0.04755829647183418, 'train_loss_total': 0.04755829647183418, 'train_grad_norm': 1.0251710414886475, 'epoch': 270}
0:04:53.164325 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:53.171810 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:53.702776 - iteration 0
0:04:53.921770 - vxvyvz tensor([[-0.0140,  0.0465,  0.1934]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:53.922842 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:53.923856 - dR tensor([[[ 0.1305,  0.5550, -0.8216],
         [ 0.8347,  0.3857,  0.3932],
         [ 0.5351, -0.7370, -0.4129]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:53.924707 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:53.927915 - k: tensor([[[ 0.1305,  0.5550, -0.8216, -0.0100],
         [ 0.8347,  0.3857,  0.3932,  0.0062],
         [ 0.5351, -0.7370, -0.4129,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.928858 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.930314 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:53.931041 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.931665 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:53.932313 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0475]
0:04:53.490644 - bracket_assembly_nut_noaug_coarse--479260
0:04:53.490903 - {'grad_norm': 1.0704752206802368, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05578494071960449, 'time_backward': 0.07868599891662598, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270050.6582618, 'n_iterations': 272, 'n_datas': 2176, 'train_loss_TCO-iter=1': 0.04750962555408478, 'train_loss_TCO': 0.04750962555408478, 'train_loss_total': 0.04750962555408478, 'train_grad_norm': 1.0704752206802368, 'epoch': 271}
0:04:53.491056 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:53.498903 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:54.030052 - iteration 0
0:04:54.250868 - vxvyvz tensor([[-0.0196,  0.0499,  0.1949]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:54.251992 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:54.252961 - dR tensor([[[ 0.0960,  0.5456, -0.8325],
         [ 0.8121,  0.4407,  0.3824],
         [ 0.5755, -0.7128, -0.4008]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:54.253796 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:54.257625 - k: tensor([[[ 0.0960,  0.5456, -0.8325, -0.0100],
         [ 0.8121,  0.4407,  0.3824,  0.0062],
         [ 0.5755, -0.7128, -0.4008,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:54.258641 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:54.259575 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0585],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:54.260230 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:54.260836 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:54.261440 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0475]
0:04:53.826162 - bracket_assembly_nut_noaug_coarse--479260
0:04:53.826371 - {'grad_norm': 1.0434596538543701, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05789494514465332, 'time_backward': 0.07893180847167969, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270050.9876373, 'n_iterations': 273, 'n_datas': 2184, 'train_loss_TCO-iter=1': 0.047499723732471466, 'train_loss_TCO': 0.047499723732471466, 'train_loss_total': 0.047499723732471466, 'train_grad_norm': 1.0434596538543701, 'epoch': 272}
0:04:53.826493 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:53.834092 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:54.365159 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0580],], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.256820 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.257425 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.258026 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0475]
0:04:54.813982 - bracket_assembly_nut_noaug_coarse--479260
0:04:54.814207 - {'grad_norm': 1.1499648094177246, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05674886703491211, 'time_backward': 0.07813096046447754, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270051.983402, 'n_iterations': 276, 'n_datas': 2208, 'train_loss_TCO-iter=1': 0.04752984642982483, 'train_loss_TCO': 0.04752984642982483, 'train_loss_total': 0.04752984642982483, 'train_grad_norm': 1.1499648094177246, 'epoch': 275}
0:04:54.814391 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:54.821928 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:55.352940 - iteration 0
0:04:55.572577 - vxvyvz tensor([[-0.0134,  0.0442,  0.1957]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:55.573647 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:55.574639 - dR tensor([[[ 0.1174,  0.5844, -0.8029],
         [ 0.8334,  0.3817,  0.3996],
         [ 0.5401, -0.7161, -0.4422]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:55.575513 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:55.578706 - k: tensor([[[ 0.1174,  0.5844, -0.8029, -0.0100],
         [ 0.8334,  0.3817,  0.3996,  0.0062],
         [ 0.5401, -0.7161, -0.4422,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.579895 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.581232 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.581851 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.582456 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.583097 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0472]
0:04:55.142082 - bracket_assembly_nut_noaug_coarse--479260
0:04:55.142325 - {'grad_norm': 1.1503957509994507, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05650639533996582, 'time_backward': 0.07886934280395508, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270052.3092346, 'n_iterations': 277, 'n_datas': 2216, 'train_loss_TCO-iter=1': 0.04723949357867241, 'train_loss_TCO': 0.04723949357867241, 'train_loss_total': 0.04723949357867241, 'train_grad_norm': 1.1503957509994507, 'epoch': 276}
0:04:55.142441 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:55.150118 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:55.681246 - iteration 0
0:04:55.901255 - vxvyvz tensor([[-0.0186,  0.0454,  0.1893]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:55.902339 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:55.903367 - dR tensor([[[ 0.1411,  0.5652, -0.8128],
         [ 0.8095,  0.4068,  0.4234],
         [ 0.5699, -0.7177, -0.4001]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:55.904249 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:55.907451 - k: tensor([[[ 0.1411,  0.5652, -0.8128, -0.0100],
         [ 0.8095,  0.4068,  0.4234,  0.0062],
         [ 0.5699, -0.7177, -0.4001,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.908424 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.909817 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0568],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:55.910519 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.911171 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:55.911815 - k: tensor([0.0451], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, loss=0.048]
0:04:55.465187 - bracket_assembly_nut_noaug_coarse--479260
0:04:55.465395 - {'grad_norm': 1.0463788509368896, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.0570528507232666, 'time_backward': 0.07926774024963379, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270052.638423, 'n_iterations': 278, 'n_datas': 2224, 'train_loss_TCO-iter=1': 0.04796960949897766, 'train_loss_TCO': 0.04796960949897766, 'train_loss_total': 0.04796960949897766, 'train_grad_norm': 1.0463788509368896, 'epoch': 277}
0:04:55.465579 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:55.473102 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:56.004116 - iteration 0
0:04:56.223991 - vxvyvz tensor([[-0.0147,  0.0446,  0.1884]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:56.225008 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:56.225934 - dR tensor([[[ 0.0865,  0.5367, -0.8393],
         [ 0.8374,  0.4172,  0.3530],
         [ 0.5397, -0.7334, -0.4134]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:56.226751 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:56.230174 - k: tensor([[[ 0.0865,  0.5367, -0.8393, -0.0100],
         [ 0.8374,  0.4172,  0.3530,  0.0062],
         [ 0.5397, -0.7334, -0.4134,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.231535 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.232457 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0565],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.233051 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:56.233638 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:56.234222 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0481]
0:04:55.788227 - bracket_assembly_nut_noaug_coarse--479260
0:04:55.788429 - {'grad_norm': 1.038519263267517, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056458234786987305, 'time_backward': 0.07905125617980957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270052.9604332, 'n_iterations': 279, 'n_datas': 2232, 'train_loss_TCO-iter=1': 0.04808482527732849, 'train_loss_TCO': 0.04808482527732849, 'train_loss_total': 0.04808482527732849, 'train_grad_norm': 1.038519263267517, 'epoch': 278}
0:04:55.788559 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:55.795982 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:56.326927 - iteration 0
0:04:56.546066 - vxvyvz tensor([[-0.0138,  0.0465,  0.1947]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:56.547119 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:56.548120 - dR tensor([[[ 0.1112,  0.5564, -0.8235],
         [ 0.8337,  0.3988,  0.3820],
         [ 0.5409, -0.7290, -0.4195]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:56.548963 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:56.552230 - k: tensor([[[ 0.1112,  0.5564, -0.8235, -0.0100],
         [ 0.8337,  0.3988,  0.3820,  0.0062],
         [ 0.5409, -0.7290, -0.4195,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.553177 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.554600 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0584],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:56.555361 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:56.556007 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:56.556624 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0474]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:04:57.539945 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:57.540981 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0580],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:57.541595 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:04:57.542199 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:57.542829 - k: tensor([0.0447], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0475]
0:04:57.197772 - bracket_assembly_nut_noaug_coarse--479260
0:04:57.197996 - {'grad_norm': 1.1498017311096191, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05581378936767578, 'time_backward': 0.07905936241149902, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270054.2692184, 'n_iterations': 283, 'n_datas': 2264, 'train_loss_TCO-iter=1': 0.04753074422478676, 'train_loss_TCO': 0.04753074422478676, 'train_loss_total': 0.04753074422478676, 'train_grad_norm': 1.1498017311096191, 'epoch': 282}
0:04:57.198125 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:57.205670 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:57.736648 - iteration 0
0:04:57.955946 - vxvyvz tensor([[-0.0133,  0.0460,  0.1948]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:57.956944 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:57.957884 - dR tensor([[[ 0.1015,  0.5184, -0.8491],
         [ 0.8248,  0.4333,  0.3632],
         [ 0.5562, -0.7372, -0.3837]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:57.958708 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:57.961942 - k: tensor([[[ 0.1015,  0.5184, -0.8491, -0.0100],
         [ 0.8248,  0.4333,  0.3632,  0.0062],
         [ 0.5562, -0.7372, -0.3837,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:57.962874 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:57.963808 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0584],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:57.964431 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:04:57.965053 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:57.965652 - k: tensor([0.0445], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0475]
0:04:57.519456 - bracket_assembly_nut_noaug_coarse--479260
0:04:57.519668 - {'grad_norm': 1.031553030014038, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055283546447753906, 'time_backward': 0.07941150665283203, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270054.6923714, 'n_iterations': 284, 'n_datas': 2272, 'train_loss_TCO-iter=1': 0.04753651097416878, 'train_loss_TCO': 0.04753651097416878, 'train_loss_total': 0.04753651097416878, 'train_grad_norm': 1.031553030014038, 'epoch': 283}
0:04:57.519786 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:57.527404 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:58.058394 - iteration 0
0:04:58.277720 - vxvyvz tensor([[-0.0154,  0.0505,  0.1943]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:58.278710 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:58.279719 - dR tensor([[[ 0.0846,  0.5589, -0.8249],
         [ 0.8234,  0.4270,  0.3738],
         [ 0.5611, -0.7108, -0.4241]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:58.280560 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:58.283781 - k: tensor([[[ 0.0846,  0.5589, -0.8249, -0.0100],
         [ 0.8234,  0.4270,  0.3738,  0.0062],
         [ 0.5611, -0.7108, -0.4241,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.285236 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.286244 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.286897 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:58.287514 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:58.288153 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0475]
0:04:57.843993 - bracket_assembly_nut_noaug_coarse--479260
0:04:57.844216 - {'grad_norm': 1.0724972486495972, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056061744689941406, 'time_backward': 0.07850122451782227, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270055.0139306, 'n_iterations': 285, 'n_datas': 2280, 'train_loss_TCO-iter=1': 0.04746650159358978, 'train_loss_TCO': 0.04746650159358978, 'train_loss_total': 0.04746650159358978, 'train_grad_norm': 1.0724972486495972, 'epoch': 284}
0:04:57.844326 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:57.851941 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:58.382941 - iteration 0
0:04:58.602231 - vxvyvz tensor([[-0.0134,  0.0442,  0.1957]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:58.603270 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:58.604279 - dR tensor([[[ 0.1173,  0.5845, -0.8029],
         [ 0.8334,  0.3817,  0.3996],
         [ 0.5400, -0.7160, -0.4423]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:58.605104 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:58.608322 - k: tensor([[[ 0.1173,  0.5845, -0.8029, -0.0100],
         [ 0.8334,  0.3817,  0.3996,  0.0062],
         [ 0.5400, -0.7160, -0.4423,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.609264 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.610725 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:58.611472 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:04:58.612120 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:58.612742 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0472]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>)
0:04:59.577130 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:59.578208 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0595],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:59.578857 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:59.579478 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:59.580131 - k: tensor([0.0441], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, loss=0.0471]
0:04:59.139359 - bracket_assembly_nut_noaug_coarse--479260
0:04:59.139596 - {'grad_norm': 1.139256477355957, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05673480033874512, 'time_backward': 0.07938718795776367, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270056.306943, 'n_iterations': 289, 'n_datas': 2312, 'train_loss_TCO-iter=1': 0.047065455466508865, 'train_loss_TCO': 0.047065455466508865, 'train_loss_total': 0.047065455466508865, 'train_grad_norm': 1.139256477355957, 'epoch': 288}
0:04:59.139708 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:59.147412 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:59.678347 - iteration 0
0:04:59.897946 - vxvyvz tensor([[-0.0138,  0.0455,  0.1972]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:59.898995 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:59.900011 - dR tensor([[[ 0.0893,  0.5355, -0.8398],
         [ 0.8232,  0.4350,  0.3648],
         [ 0.5607, -0.7239, -0.4020]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:59.900840 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:59.904069 - k: tensor([[[ 0.0893,  0.5355, -0.8398, -0.0100],
         [ 0.8232,  0.4350,  0.3648,  0.0062],
         [ 0.5607, -0.7239, -0.4020,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:59.905292 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:59.906651 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0592],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:59.907314 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:04:59.907954 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:59.908570 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0473]
0:04:59.469276 - bracket_assembly_nut_noaug_coarse--479260
0:04:59.469514 - {'grad_norm': 1.0792276859283447, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05648541450500488, 'time_backward': 0.07848024368286133, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270056.634341, 'n_iterations': 290, 'n_datas': 2320, 'train_loss_TCO-iter=1': 0.04725877568125725, 'train_loss_TCO': 0.04725877568125725, 'train_loss_total': 0.04725877568125725, 'train_grad_norm': 1.0792276859283447, 'epoch': 289}
0:04:59.469647 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:59.477154 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:00.008130 - iteration 0
0:05:00.227167 - vxvyvz tensor([[-0.0164,  0.0477,  0.1898]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:00.228214 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:00.229198 - dR tensor([[[ 0.1253,  0.5379, -0.8336],
         [ 0.8200,  0.4169,  0.3923],
         [ 0.5585, -0.7327, -0.3888]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:00.230025 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:00.233232 - k: tensor([[[ 0.1253,  0.5379, -0.8336, -0.0100],
         [ 0.8200,  0.4169,  0.3923,  0.0062],
         [ 0.5585, -0.7327, -0.3888,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.234690 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.235687 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0569],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.236338 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:05:00.236930 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:00.237517 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.048]
0:04:59.788176 - bracket_assembly_nut_noaug_coarse--479260
0:04:59.788393 - {'grad_norm': 0.9842948913574219, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055670976638793945, 'time_backward': 0.07947015762329102, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270056.9640832, 'n_iterations': 291, 'n_datas': 2328, 'train_loss_TCO-iter=1': 0.04802410304546356, 'train_loss_TCO': 0.04802410304546356, 'train_loss_total': 0.04802410304546356, 'train_grad_norm': 0.9842948913574219, 'epoch': 290}
0:04:59.788525 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:59.795965 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:00.326910 - iteration 0
0:05:00.546081 - vxvyvz tensor([[-0.0154,  0.0505,  0.1943]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:00.547116 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:00.548131 - dR tensor([[[ 0.0846,  0.5590, -0.8249],
         [ 0.8234,  0.4269,  0.3738],
         [ 0.5611, -0.7108, -0.4241]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:00.548960 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:00.552222 - k: tensor([[[ 0.0846,  0.5590, -0.8249, -0.0100],
         [ 0.8234,  0.4269,  0.3738,  0.0062],
         [ 0.5611, -0.7108, -0.4241,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.553143 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.554669 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:00.555336 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:05:00.555979 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:00.556595 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0475]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:05:01.563932 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:01.564909 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:01.565524 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:05:01.566129 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:01.566736 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0479]
0:05:01.127246 - bracket_assembly_nut_noaug_coarse--479260
0:05:01.127450 - {'grad_norm': 1.0601493120193481, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05577540397644043, 'time_backward': 0.07834434509277344, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270058.2924008, 'n_iterations': 295, 'n_datas': 2360, 'train_loss_TCO-iter=1': 0.047856539487838745, 'train_loss_TCO': 0.047856539487838745, 'train_loss_total': 0.047856539487838745, 'train_grad_norm': 1.0601493120193481, 'epoch': 294}
0:05:01.127566 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:01.135078 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:01.666049 - iteration 0
0:05:01.885270 - vxvyvz tensor([[-0.0157,  0.0457,  0.1996]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:01.886308 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:01.887326 - dR tensor([[[ 0.1309,  0.5467, -0.8270],
         [ 0.8345,  0.3896,  0.3897],
         [ 0.5353, -0.7412, -0.4052]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:01.888209 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:01.891432 - k: tensor([[[ 0.1309,  0.5467, -0.8270, -0.0100],
         [ 0.8345,  0.3896,  0.3897,  0.0062],
         [ 0.5353, -0.7412, -0.4052,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:01.892384 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:01.893785 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0599],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:01.894473 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:05:01.895104 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:01.895723 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.047]
0:05:01.453044 - bracket_assembly_nut_noaug_coarse--479260
0:05:01.453266 - {'grad_norm': 1.1155269145965576, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05589604377746582, 'time_backward': 0.07864856719970703, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270058.6214948, 'n_iterations': 296, 'n_datas': 2368, 'train_loss_TCO-iter=1': 0.046952735632658005, 'train_loss_TCO': 0.046952735632658005, 'train_loss_total': 0.046952735632658005, 'train_grad_norm': 1.1155269145965576, 'epoch': 295}
0:05:01.453386 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:01.461043 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:01.992077 - iteration 0
0:05:02.211598 - vxvyvz tensor([[-0.0147,  0.0486,  0.1963]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:02.212659 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:02.213615 - dR tensor([[[ 0.0902,  0.5670, -0.8188],
         [ 0.8386,  0.4002,  0.3695],
         [ 0.5372, -0.7200, -0.4394]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:02.214446 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:02.217763 - k: tensor([[[ 0.0902,  0.5670, -0.8188, -0.0100],
         [ 0.8386,  0.4002,  0.3695,  0.0062],
         [ 0.5372, -0.7200, -0.4394,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.219267 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.220301 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0589],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.220922 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:05:02.221527 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:02.222130 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0472]
0:05:01.783880 - bracket_assembly_nut_noaug_coarse--479260
0:05:01.784106 - {'grad_norm': 1.0720840692520142, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05644941329956055, 'time_backward': 0.07828116416931152, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270058.9477491, 'n_iterations': 297, 'n_datas': 2376, 'train_loss_TCO-iter=1': 0.04715210944414139, 'train_loss_TCO': 0.04715210944414139, 'train_loss_total': 0.04715210944414139, 'train_grad_norm': 1.0720840692520142, 'epoch': 296}
0:05:01.784233 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:01.791873 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:02.322978 - iteration 0
0:05:02.543456 - vxvyvz tensor([[-0.0134,  0.0442,  0.1957]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:02.544605 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:02.545632 - dR tensor([[[ 0.1173,  0.5846, -0.8028],
         [ 0.8335,  0.3816,  0.3996],
         [ 0.5399, -0.7160, -0.4425]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:02.546470 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:02.549711 - k: tensor([[[ 0.1173,  0.5846, -0.8028, -0.0100],
         [ 0.8335,  0.3816,  0.3996,  0.0062],
         [ 0.5399, -0.7160, -0.4425,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.550620 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.552191 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:02.552829 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:05:02.553453 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:02.554056 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, loss=0.0472]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:05:03.527783 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:03.528781 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0570],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:03.529410 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:05:03.530038 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:03.530650 - k: tensor([0.0450], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.048]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:02.907877 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.438695 - iteration 0
0:05:03.651547 - vxvyvz tensor([[ 0.0140, -0.0145, -0.0501]], device='cuda:0')
0:05:03.652575 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.653496 - dR tensor([[[ 0.6638, -0.7468,  0.0412],
         [-0.0811, -0.1267, -0.9886],
         [ 0.7435,  0.6529, -0.1447]]], device='cuda:0')
0:05:03.654318 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:03.657323 - k: tensor([[[ 0.6638, -0.7468,  0.0412, -0.0100],
         [-0.0811, -0.1267, -0.9886,  0.0062],
         [ 0.7435,  0.6529, -0.1447,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.658275 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.659192 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0150],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.659834 - k: tensor([0.0054], device='cuda:0')
0:05:03.660447 - k: tensor([0.0003], device='cuda:0')
0:05:03.661062 - k: tensor([0.0690], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.50it/s]
0:05:03.152172 - bracket_assembly_nut_noaug_coarse--479260
0:05:03.152382 - {'grad_norm': 1.1100887060165405, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056441307067871094, 'time_backward': 0.07821369171142578, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270060.3086073, 'n_iterations': 301, 'n_datas': 2408, 'train_loss_TCO-iter=1': 0.04798578843474388, 'train_loss_TCO': 0.04798578843474388, 'train_loss_total': 0.04798578843474388, 'train_grad_norm': 1.1100887060165405, 'val_loss_TCO-iter=1': 0.07471717149019241, 'val_loss_TCO': 0.07471717149019241, 'val_loss_total': 0.07471717149019241, 'epoch': 300}
0:05:03.152528 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:03.159983 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.687702 - iteration 0
0:05:03.907545 - vxvyvz tensor([[-0.0176,  0.0484,  0.1937]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:03.908616 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:03.909575 - dR tensor([[[ 0.0958,  0.5406, -0.8358],
         [ 0.8397,  0.4070,  0.3595],
         [ 0.5345, -0.7363, -0.4149]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:03.910403 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:03.913617 - k: tensor([[[ 0.0958,  0.5406, -0.8358, -0.0100],
         [ 0.8397,  0.4070,  0.3595,  0.0062],
         [ 0.5345, -0.7363, -0.4149,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:03.914542 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:03.915466 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0581],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:03.916115 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:05:03.916735 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:03.917358 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, loss=0.0476]
0:05:03.502839 - bracket_assembly_nut_noaug_coarse--479260
0:05:03.503099 - {'grad_norm': 1.1507290601730347, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05267143249511719, 'time_backward': 0.078704833984375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270060.643813, 'n_iterations': 302, 'n_datas': 2416, 'train_loss_TCO-iter=1': 0.047565214335918427, 'train_loss_TCO': 0.047565214335918427, 'train_loss_total': 0.047565214335918427, 'train_grad_norm': 1.1507290601730347, 'epoch': 301}
0:05:03.503220 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:03.510918 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:04.041983 - iteration 0
0:05:04.262141 - vxvyvz tensor([[-0.0198,  0.0536,  0.1940]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:04.263242 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:04.264263 - dR tensor([[[ 0.0973,  0.5775, -0.8106],
         [ 0.8175,  0.4182,  0.3960],
         [ 0.5676, -0.7012, -0.4314]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:04.265094 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:04.268312 - k: tensor([[[ 0.0973,  0.5775, -0.8106, -0.0100],
         [ 0.8175,  0.4182,  0.3960,  0.0062],
         [ 0.5676, -0.7012, -0.4314,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:04.269814 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:04.270801 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0582],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:04.271433 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:05:04.272077 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:04.272676 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0475]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:05:05.267317 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.268845 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0564],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.269465 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.270098 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.270711 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0482]
0:05:04.845694 - bracket_assembly_nut_noaug_coarse--479260
0:05:04.845917 - {'grad_norm': 1.075089931488037, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.055649757385253906, 'time_backward': 0.07665324211120605, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270061.9946365, 'n_iterations': 306, 'n_datas': 2448, 'train_loss_TCO-iter=1': 0.048246562480926514, 'train_loss_TCO': 0.048246562480926514, 'train_loss_total': 0.048246562480926514, 'train_grad_norm': 1.075089931488037, 'epoch': 305}
0:05:04.846030 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:04.853645 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:05.384684 - iteration 0
0:05:05.604274 - vxvyvz tensor([[-0.0184,  0.0517,  0.1881]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:05.605276 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:05.606237 - dR tensor([[[ 0.1083,  0.5683, -0.8157],
         [ 0.8199,  0.4129,  0.3965],
         [ 0.5621, -0.7117, -0.4213]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:05.607101 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:05.610288 - k: tensor([[[ 0.1083,  0.5683, -0.8157, -0.0100],
         [ 0.8199,  0.4129,  0.3965,  0.0062],
         [ 0.5621, -0.7117, -0.4213,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.611247 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.612740 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0564],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.613358 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.613964 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.614565 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0481]
0:05:05.178378 - bracket_assembly_nut_noaug_coarse--479260
0:05:05.178597 - {'grad_norm': 1.0662537813186646, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056279897689819336, 'time_backward': 0.07775068283081055, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270062.3394513, 'n_iterations': 307, 'n_datas': 2456, 'train_loss_TCO-iter=1': 0.048063695430755615, 'train_loss_TCO': 0.048063695430755615, 'train_loss_total': 0.048063695430755615, 'train_grad_norm': 1.0662537813186646, 'epoch': 306}
0:05:05.178712 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:05.186135 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:05.717104 - iteration 0
0:05:05.936543 - vxvyvz tensor([[-0.0154,  0.0505,  0.1943]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:05.937539 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:05.938498 - dR tensor([[[ 0.0845,  0.5591, -0.8248],
         [ 0.8235,  0.4269,  0.3737],
         [ 0.5610, -0.7108, -0.4243]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:05.939369 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:05.942618 - k: tensor([[[ 0.0845,  0.5591, -0.8248, -0.0100],
         [ 0.8235,  0.4269,  0.3737,  0.0062],
         [ 0.5610, -0.7108, -0.4243,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.944149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.945141 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0583],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:05.945759 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.946366 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:05.947006 - k: tensor([0.0446], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0474]
0:05:05.508327 - bracket_assembly_nut_noaug_coarse--479260
0:05:05.508555 - {'grad_norm': 1.0718907117843628, 'grad_norm_std': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.05611300468444824, 'time_backward': 0.07932043075561523, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270062.673492, 'n_iterations': 308, 'n_datas': 2464, 'train_loss_TCO-iter=1': 0.047438666224479675, 'train_loss_TCO': 0.047438666224479675, 'train_loss_total': 0.047438666224479675, 'train_grad_norm': 1.0718907117843628, 'epoch': 307}
0:05:05.508674 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:05:05.516344 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:06.047279 - iteration 0
0:05:06.266932 - vxvyvz tensor([[-0.0132,  0.0523,  0.1905]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:05:06.267989 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:05:06.268969 - dR tensor([[[ 0.1389,  0.5319, -0.8354],
         [ 0.8452,  0.3759,  0.3798],
         [ 0.5160, -0.7588, -0.3973]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:05:06.269799 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:05:06.273048 - k: tensor([[[ 0.1389,  0.5319, -0.8354, -0.0100],
         [ 0.8452,  0.3759,  0.3798,  0.0062],
         [ 0.5160, -0.7588, -0.3973,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:06.274571 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:06.275597 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0572],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:06.276250 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:05:06.276867 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:06.277483 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0478]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
0:05:07.255961 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:07.257436 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0587],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:05:07.258054 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:05:07.258657 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:05:07.259305 - k: tensor([0.0444], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0472]
0:05:06.839418 - bracket_assembly_nut_noaug_coarse--479260
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',': inf, 'learning_rate': 2.1041666666666665e-09, 'time_forward': 0.056021690368652344, 'time_backward': 0.07781672477722168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269807.061483, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.04755920171737671, 'train_loss_TCO': 0.04755920171737671, 'train_loss_total': 0.04755920171737671, 'train_grad_norm': 1.1494611501693726, 'epoch': 103}