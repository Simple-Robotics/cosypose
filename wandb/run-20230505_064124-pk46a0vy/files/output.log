  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:11.802024 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:12.337707 - iteration 0
0:00:14.015759 - vxvyvz tensor([[ 0.1046,  0.0910, -0.0632]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:14.016878 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.017864 - dR tensor([[[-0.5228, -0.4331,  0.7342],
         [ 0.3446, -0.8952, -0.2827],
         [ 0.7797,  0.1052,  0.6173]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:14.018711 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:14.022387 - k: tensor([[[-0.5228, -0.4331,  0.7342, -0.0100],
         [ 0.3446, -0.8952, -0.2827,  0.0062],
         [ 0.7797,  0.1052,  0.6173,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.023361 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.024294 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0190],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.024948 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.025573 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.026190 - k: tensor([0.0703], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:03<00:00,  3.54s/it, loss=0.0721]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.302186 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.838787 - iteration 0
0:00:15.139058 - vxvyvz tensor([[-0.0078,  0.0236, -0.0142]], device='cuda:0')
0:00:15.140156 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.141134 - dR tensor([[[ 0.4857,  0.7946, -0.3642],
         [-0.3424,  0.5563,  0.7571],
         [ 0.8042, -0.2430,  0.5423]]], device='cuda:0')
0:00:15.141996 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.145356 - k: tensor([[[ 0.4857,  0.7946, -0.3642, -0.0100],
         [-0.3424,  0.5563,  0.7571,  0.0062],
         [ 0.8042, -0.2430,  0.5423,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.146265 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.147222 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0043],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.147892 - k: tensor([0.0053], device='cuda:0')
0:00:15.148532 - k: tensor([0.0003], device='cuda:0')
0:00:15.149159 - k: tensor([0.0654], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]
0:00:14.540470 - bracket_assembly_nut_noaug_coarse--917955
0:00:14.540711 - {'grad_norm': 1.0273690223693848, 'grad_norm_std': inf, 'learning_rate': 4.166666666666667e-11, 'time_forward': 2.25197172164917, 'time_backward': 0.6188929080963135, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268894.6536438, 'n_iterations': 1, 'n_datas': 8, 'train_loss_TCO-iter=1': 0.07210946083068848, 'train_loss_TCO': 0.07210946083068848, 'train_loss_total': 0.07210946083068848, 'train_grad_norm': 1.0273690223693848, 'val_loss_TCO-iter=1': 0.07103157788515091, 'val_loss_TCO': 0.07103157788515091, 'val_loss_total': 0.07103157788515091, 'epoch': 0}
0:00:14.540900 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.548954 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.081240 - iteration 0
0:00:15.392813 - vxvyvz tensor([[ 0.1046,  0.0885, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.393930 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.395035 - dR tensor([[[-0.5139, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3086],
         [ 0.7849,  0.0933,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.395959 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.399050 - k: tensor([[[-0.5139, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3086,  0.0062],
         [ 0.7849,  0.0933,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.400034 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.400929 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.401552 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.402150 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.402743 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, loss=0.073]
0:00:14.952342 - bracket_assembly_nut_noaug_coarse--917955
0:00:14.952574 - {'grad_norm': 1.146173119544983, 'grad_norm_std': inf, 'learning_rate': 6.25e-11, 'time_forward': 0.1414797306060791, 'time_backward': 0.07791829109191895, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268894.983812, 'n_iterations': 2, 'n_datas': 16, 'train_loss_TCO-iter=1': 0.07303014397621155, 'train_loss_TCO': 0.07303014397621155, 'train_loss_total': 0.07303014397621155, 'train_grad_norm': 1.146173119544983, 'epoch': 1}
0:00:14.952743 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.040891 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.575237 - iteration 0
0:00:15.875924 - vxvyvz tensor([[ 0.0999,  0.0867, -0.0670]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.876994 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.877941 - dR tensor([[[-0.5182, -0.4446,  0.7306],
         [ 0.3216, -0.8929, -0.3152],
         [ 0.7925,  0.0717,  0.6057]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.878773 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.881804 - k: tensor([[[-0.5182, -0.4446,  0.7306, -0.0100],
         [ 0.3216, -0.8929, -0.3152,  0.0062],
         [ 0.7925,  0.0717,  0.6057,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.882678 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.883598 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0201],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.884262 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.884858 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.885449 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.40it/s, loss=0.0726]
0:00:15.426156 - bracket_assembly_nut_noaug_coarse--917955
0:00:15.426383 - {'grad_norm': 1.0162214040756226, 'grad_norm_std': inf, 'learning_rate': 8.333333333333334e-11, 'time_forward': 0.1322803497314453, 'time_backward': 0.07776761054992676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268895.4661422, 'n_iterations': 3, 'n_datas': 24, 'train_loss_TCO-iter=1': 0.0725761279463768, 'train_loss_TCO': 0.0725761279463768, 'train_loss_total': 0.0725761279463768, 'train_grad_norm': 1.0162214040756226, 'epoch': 2}
0:00:15.426515 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.549229 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.083606 - iteration 0
0:00:16.384998 - vxvyvz tensor([[ 0.0999,  0.0887, -0.0686]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.386042 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.387048 - dR tensor([[[-0.5075, -0.4437,  0.7386],
         [ 0.3381, -0.8910, -0.3030],
         [ 0.7925,  0.0959,  0.6022]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.387909 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.390925 - k: tensor([[[-0.5075, -0.4437,  0.7386, -0.0100],
         [ 0.3381, -0.8910, -0.3030,  0.0062],
         [ 0.7925,  0.0959,  0.6022,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.391823 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.392727 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.393338 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.393936 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.394534 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.03it/s, loss=0.0727]
0:00:15.949652 - bracket_assembly_nut_noaug_coarse--917955
0:00:15.949875 - {'grad_norm': 1.084194302558899, 'grad_norm_std': inf, 'learning_rate': 1.0416666666666667e-10, 'time_forward': 0.1331157684326172, 'time_backward': 0.0778663158416748, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268895.9754117, 'n_iterations': 4, 'n_datas': 32, 'train_loss_TCO-iter=1': 0.07271721214056015, 'train_loss_TCO': 0.07271721214056015, 'train_loss_total': 0.07271721214056015, 'train_grad_norm': 1.084194302558899, 'epoch': 3}
0:00:15.949998 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:16.042714 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.577117 - iteration 0
0:00:16.879062 - vxvyvz tensor([[ 0.1022,  0.0914, -0.0700]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.880171 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.881139 - dR tensor([[[-0.5215, -0.4402,  0.7309],
         [ 0.3134, -0.8956, -0.3158],
         [ 0.7936,  0.0643,  0.6050]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.881987 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.885195 - k: tensor([[[-0.5215, -0.4402,  0.7309, -0.0100],
         [ 0.3134, -0.8956, -0.3158,  0.0062],
         [ 0.7936,  0.0643,  0.6050,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.886095 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.887021 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0210],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.887655 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.888300 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.888906 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.34it/s, loss=0.0729]
0:00:16.446390 - bracket_assembly_nut_noaug_coarse--917955
0:00:16.446635 - {'grad_norm': 1.0151203870773315, 'grad_norm_std': inf, 'learning_rate': 1.25e-10, 'time_forward': 0.13389992713928223, 'time_backward': 0.07678508758544922, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268896.468599, 'n_iterations': 5, 'n_datas': 40, 'train_loss_TCO-iter=1': 0.07287267595529556, 'train_loss_TCO': 0.07287267595529556, 'train_loss_total': 0.07287267595529556, 'train_grad_norm': 1.0151203870773315, 'epoch': 4}
0:00:16.446759 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:16.533648 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.068059 - iteration 0
0:00:17.369706 - vxvyvz tensor([[ 0.1042,  0.0831, -0.0667]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:17.370772 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.371792 - dR tensor([[[-0.5257, -0.4554,  0.7185],
         [ 0.3485, -0.8858, -0.3065],
         [ 0.7760,  0.0893,  0.6243]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:17.372660 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.421733 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],<?, ?it/s]0:00:16.042714 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.422704 - dR tensor([[[-0.5139, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3086],
         [ 0.7849,  0.0933,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:48.423610 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.427049 - k: tensor([[[-0.5139, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3086,  0.0062],
         [ 0.7849,  0.0933,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.427989 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.428913 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.429539 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.430166 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.430813 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  4.41it/s, loss=0.073]
0:00:48.001862 - bracket_assembly_nut_noaug_coarse--917955
0:00:48.002116 - {'grad_norm': 1.146419644355774, 'grad_norm_std': inf, 'learning_rate': 1.6666666666666669e-10, 'time_forward': 0.13457107543945312, 'time_backward': 0.08827805519104004, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268928.022044, 'n_iterations': 7, 'n_datas': 56, 'train_loss_TCO-iter=1': 0.07303643226623535, 'train_loss_TCO': 0.07303643226623535, 'train_loss_total': 0.07303643226623535, 'train_grad_norm': 1.146419644355774, 'epoch': 6}
0:00:48.002244 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]
0:00:50.111343 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],00],<?, ?it/s]0:00:16.042714 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
0:00:49.315405 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.318649 - k: tensor([[[-0.5184, -0.4561,  0.7234, -0.0100],
         [ 0.3487, -0.8851, -0.3082,  0.0062],
         [ 0.7808,  0.0924,  0.6179,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.319612 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.320546 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.321180 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.321789 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.322397 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.83it/s, loss=0.0725]
0:00:48.872623 - bracket_assembly_nut_noaug_coarse--917955
0:00:48.872859 - {'grad_norm': 1.1293493509292603, 'grad_norm_std': inf, 'learning_rate': 2.0833333333333334e-10, 'time_forward': 0.12542152404785156, 'time_backward': 0.07760024070739746, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268928.902841, 'n_iterations': 9, 'n_datas': 72, 'train_loss_TCO-iter=1': 0.07252590358257294, 'train_loss_TCO': 0.07252590358257294, 'train_loss_total': 0.07252590358257294, 'train_grad_norm': 1.1293493509292603, 'epoch': 8}
0:00:48.873037 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.880416 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.414507 - iteration 0
0:00:49.708038 - vxvyvz tensor([[ 0.0988,  0.0893, -0.0681]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:49.709090 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.710104 - dR tensor([[[-0.5146, -0.4146,  0.7505],
         [ 0.3125, -0.9058, -0.2862],
         [ 0.7984,  0.0873,  0.5957]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:49.710970 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.714219 - k: tensor([[[-0.5146, -0.4146,  0.7505, -0.0100],
         [ 0.3125, -0.9058, -0.2862,  0.0062],
         [ 0.7984,  0.0873,  0.5957,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.715284 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.716271 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0204],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.716944 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.717586 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.718244 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s, loss=0.0727]
0:00:49.268860 - bracket_assembly_nut_noaug_coarse--917955
0:00:49.269068 - {'grad_norm': 1.038745641708374, 'grad_norm_std': inf, 'learning_rate': 2.2916666666666665e-10, 'time_forward': 0.12555551528930664, 'time_backward': 0.0784311294555664, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268929.2996585, 'n_iterations': 10, 'n_datas': 80, 'train_loss_TCO-iter=1': 0.07274205982685089, 'train_loss_TCO': 0.07274205982685089, 'train_loss_total': 0.07274205982685089, 'train_grad_norm': 1.038745641708374, 'epoch': 9}
0:00:49.269188 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:49.276871 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.811113 - iteration 0
0:00:50.103918 - vxvyvz tensor([[ 0.1025,  0.0914, -0.0635]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.104995 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.106035 - dR tensor([[[-0.4966, -0.4639,  0.7336],
         [ 0.3431, -0.8813, -0.3250],
         [ 0.7973,  0.0903,  0.5969]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.106949 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.110336 - k: tensor([[[-0.4966, -0.4639,  0.7336, -0.0100],
         [ 0.3431, -0.8813, -0.3250,  0.0062],
         [ 0.7973,  0.0903,  0.5969,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.111343 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],00],<?, ?it/s]0:00:16.042714 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.112385 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0191],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.113056 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.113704 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.114343 - k: tensor([0.0703], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s, loss=0.0723]
0:00:49.678305 - bracket_assembly_nut_noaug_coarse--917955
0:00:49.678527 - {'grad_norm': 1.0320687294006348, 'grad_norm_std': inf, 'learning_rate': 2.5e-10, 'time_forward': 0.12535333633422852, 'time_backward': 0.07866024971008301, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268929.6959255, 'n_iterations': 11, 'n_datas': 88, 'train_loss_TCO-iter=1': 0.0722527727484703, 'train_loss_TCO': 0.0722527727484703, 'train_loss_total': 0.0722527727484703, 'train_grad_norm': 1.0320687294006348, 'epoch': 10}
0:00:49.678684 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:49.686381 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.220516 - iteration 0
0:00:50.511937 - vxvyvz tensor([[ 0.1024,  0.0878, -0.0697]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.513042 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.514077 - dR tensor([[[-0.5033, -0.4597,  0.7316],
         [ 0.3422, -0.8835, -0.3197],
         [ 0.7934,  0.0895,  0.6021]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.514979 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.518343 - k: tensor([[[-0.5033, -0.4597,  0.7316, -0.0100],
         [ 0.3422, -0.8835, -0.3197,  0.0062],
         [ 0.7934,  0.0895,  0.6021,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.519353 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.520390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.521064 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.521708 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.522350 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.81it/s, loss=0.0729]
0:00:50.079364 - bracket_assembly_nut_noaug_coarse--917955
0:00:50.079600 - {'grad_norm': 1.1377301216125488, 'grad_norm_std': inf, 'learning_rate': 2.7083333333333333e-10, 'time_forward': 0.12376642227172852, 'time_backward': 0.08031105995178223, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268930.1055427, 'n_iterations': 12, 'n_datas': 96, 'train_loss_TCO-iter=1': 0.07285933941602707, 'train_loss_TCO': 0.07285933941602707, 'train_loss_total': 0.07285933941602707, 'train_grad_norm': 1.1377301216125488, 'epoch': 11}
0:00:50.079776 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:50.087301 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.621425 - iteration 0
0:00:50.914265 - vxvyvz tensor([[ 0.0951,  0.0901, -0.0686]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.915346 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.916376 - dR tensor([[[-0.5164, -0.4703,  0.7156],
         [ 0.3376, -0.8798, -0.3346],
         [ 0.7870,  0.0688,  0.6131]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.917223 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.920564 - k: tensor([[[-0.5164, -0.4703,  0.7156, -0.0100],
         [ 0.3376, -0.8798, -0.3346,  0.0062],
         [ 0.7870,  0.0688,  0.6131,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.921470 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.922361 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.923031 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.923655 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.924296 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.75it/s, loss=0.0727]
0:00:50.508045 - bracket_assembly_nut_noaug_coarse--917955
0:00:50.508270 - {'grad_norm': 1.0816060304641724, 'grad_norm_std': inf, 'learning_rate': 2.916666666666667e-10, 'time_forward': 0.12468862533569336, 'time_backward': 0.08234047889709473, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268930.5093312, 'n_iterations': 13, 'n_datas': 104, 'train_loss_TCO-iter=1': 0.07271256297826767, 'train_loss_TCO': 0.07271256297826767, 'train_loss_total': 0.07271256297826767, 'train_grad_norm': 1.0816060304641724, 'epoch': 12}
0:00:50.508396 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:50.515946 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.050053 - iteration 0
0:00:51.341496 - vxvyvz tensor([[ 0.1020,  0.0846, -0.0628]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:51.342541 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.343579 - dR tensor([[[-0.5149, -0.4548,  0.7267],
         [ 0.3357, -0.8869, -0.3173],
         [ 0.7888,  0.0806,  0.6093]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:51.344471 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:51.347761 - k: tensor([[[-0.5149, -0.4548,  0.7267, -0.0100],
         [ 0.3357, -0.8869, -0.3173,  0.0062],
         [ 0.7888,  0.0806,  0.6093,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.348715 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.349623 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0188],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.350240 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.350882 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.351514 - k: tensor([0.0703], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.72it/s, loss=0.0721]
0:00:50.908734 - bracket_assembly_nut_noaug_coarse--917955
0:00:50.908945 - {'grad_norm': 1.0416784286499023, 'grad_norm_std': inf, 'learning_rate': 3.125e-10, 'time_forward': 0.12327194213867188, 'time_backward': 0.08471870422363281, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268930.9390242, 'n_iterations': 14, 'n_datas': 112, 'train_loss_TCO-iter=1': 0.07212232798337936, 'train_loss_TCO': 0.07212232798337936, 'train_loss_total': 0.07212232798337936, 'train_grad_norm': 1.0416784286499023, 'epoch': 13}
0:00:50.909064 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:50.916425 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.450404 - iteration 0
0:00:51.740991 - vxvyvz tensor([[ 0.1003,  0.0883, -0.0674]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:51.742066 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.743099 - dR tensor([[[-0.5043, -0.4506,  0.7366],
         [ 0.3169, -0.8901, -0.3275],
         [ 0.8033,  0.0683,  0.5917]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:51.743971 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:51.747286 - k: tensor([[[-0.5043, -0.4506,  0.7366, -0.0100],
         [ 0.3169, -0.8901, -0.3275,  0.0062],
         [ 0.8033,  0.0683,  0.5917,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.748236 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.749146 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.749766 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.750392 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.751036 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.70it/s, loss=0.0727]
0:00:51.327862 - bracket_assembly_nut_noaug_coarse--917955
0:00:51.328090 - {'grad_norm': 1.1240869760513306, 'grad_norm_std': inf, 'learning_rate': 3.3333333333333337e-10, 'time_forward': 0.12225604057312012, 'time_backward': 0.08666729927062988, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268931.3404686, 'n_iterations': 15, 'n_datas': 120, 'train_loss_TCO-iter=1': 0.07268618792295456, 'train_loss_TCO': 0.07268618792295456, 'train_loss_total': 0.07268618792295456, 'train_grad_norm': 1.1240869760513306, 'epoch': 14}
0:00:51.328220 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:51.335686 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.869797 - iteration 0
0:00:52.094027 - vxvyvz tensor([[ 0.1065,  0.0874, -0.0701]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.095047 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.096060 - dR tensor([[[-0.4928, -0.4888,  0.7199],
         [ 0.3552, -0.8683, -0.3463],
         [ 0.7944,  0.0851,  0.6015]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.096905 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.100292 - k: tensor([[[-0.4928, -0.4888,  0.7199, -0.0100],
         [ 0.3552, -0.8683, -0.3463,  0.0062],
         [ 0.7944,  0.0851,  0.6015,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.101213 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.102617 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0210],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.103354 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.104018 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.104627 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.73it/s, loss=0.0729]
0:00:51.676692 - bracket_assembly_nut_noaug_coarse--917955
0:00:51.676897 - {'grad_norm': 1.0090724229812622, 'grad_norm_std': inf, 'learning_rate': 3.541666666666667e-10, 'time_forward': 0.0566096305847168, 'time_backward': 0.08823728561401367, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268931.695653, 'n_iterations': 16, 'n_datas': 128, 'train_loss_TCO-iter=1': 0.07294361293315887, 'train_loss_TCO': 0.07294361293315887, 'train_loss_total': 0.07294361293315887, 'train_grad_norm': 1.0090724229812622, 'epoch': 15}
0:00:51.677010 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:51.684341 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.218321 - iteration 0
0:00:52.442077 - vxvyvz tensor([[ 0.1120,  0.0857, -0.0696]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.443082 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.444092 - dR tensor([[[-0.5204, -0.4548,  0.7227],
         [ 0.3394, -0.8868, -0.3136],
         [ 0.7835,  0.0821,  0.6159]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.444931 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.448314 - k: tensor([[[-0.5204, -0.4548,  0.7227, -0.0100],
         [ 0.3394, -0.8868, -0.3136,  0.0062],
         [ 0.7835,  0.0821,  0.6159,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.449217 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.450113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.451237 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.451953 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.452576 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.87it/s, loss=0.0728]
0:00:52.015576 - bracket_assembly_nut_noaug_coarse--917955
0:00:52.015803 - {'grad_norm': 1.103960394859314, 'grad_norm_std': inf, 'learning_rate': 3.7500000000000005e-10, 'time_forward': 0.055852651596069336, 'time_backward': 0.08600735664367676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268932.0412862, 'n_iterations': 17, 'n_datas': 136, 'train_loss_TCO-iter=1': 0.07277677208185196, 'train_loss_TCO': 0.07277677208185196, 'train_loss_total': 0.07277677208185196, 'train_grad_norm': 1.103960394859314, 'epoch': 16}
0:00:52.015917 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:52.023257 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.557289 - iteration 0
0:00:52.780591 - vxvyvz tensor([[ 0.1037,  0.0849, -0.0710]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.781587 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.782548 - dR tensor([[[-0.5088, -0.4575,  0.7292],
         [ 0.3439, -0.8846, -0.3151],
         [ 0.7892,  0.0905,  0.6074]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.783422 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.786666 - k: tensor([[[-0.5088, -0.4575,  0.7292, -0.0100],
         [ 0.3439, -0.8846, -0.3151,  0.0062],
         [ 0.7892,  0.0905,  0.6074,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.787626 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.789089 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.789723 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.790334 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.790975 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.073]
0:00:52.351549 - bracket_assembly_nut_noaug_coarse--917955
0:00:52.351816 - {'grad_norm': 1.1362617015838623, 'grad_norm_std': inf, 'learning_rate': 3.9583333333333336e-10, 'time_forward': 0.055338144302368164, 'time_backward': 0.07886123657226562, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683268932.3725936, 'n_iterations': 18, 'n_datas': 144, 'train_loss_TCO-iter=1': 0.0729646235704422, 'train_loss_TCO': 0.0729646235704422, 'train_loss_total': 0.0729646235704422, 'train_grad_norm': 1.1362617015838623, 'epoch': 17}
0:00:52.351940 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:52.359511 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.893588 - iteration 0
0:00:53.117086 - vxvyvz tensor([[ 0.1046,  0.0885, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:53.118055 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:53.119043 - dR tensor([[[-0.5139, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3086],
         [ 0.7849,  0.0933,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:53.119915 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:53.123125 - k: tensor([[[-0.5139, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3086,  0.0062],
         [ 0.7849,  0.0933,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.073]
       grad_fn=<CopySlices>)██████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.073]
0:04:01.946522 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:01.947458 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0223],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:01.948561 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:01.949236 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:01.949847 - k: tensor([0.0714], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.04it/s, loss=0.0732]
0:04:01.644453 - bracket_assembly_nut_noaug_coarse--917955
0:04:01.644720 - {'grad_norm': 1.1300280094146729, 'grad_norm_std': inf, 'learning_rate': 4.791666666666667e-10, 'time_forward': 0.056594133377075195, 'time_backward': 0.08181452751159668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269121.5344782, 'n_iterations': 22, 'n_datas': 176, 'train_loss_TCO-iter=1': 0.07320801168680191, 'train_loss_TCO': 0.07320801168680191, 'train_loss_total': 0.07320801168680191, 'train_grad_norm': 1.1300280094146729, 'epoch': 21}
0:04:01.644857 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:01.652353 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:02.186433 - iteration 0
0:04:02.409994 - vxvyvz tensor([[ 0.1003,  0.0870, -0.0651]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:02.410966 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:02.411986 - dR tensor([[[-0.5269, -0.4314,  0.7323],
         [ 0.3472, -0.8957, -0.2778],
         [ 0.7758,  0.1078,  0.6218]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:02.412858 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:02.416114 - k: tensor([[[-0.5269, -0.4314,  0.7323, -0.0100],
         [ 0.3472, -0.8957, -0.2778,  0.0062],
         [ 0.7758,  0.1078,  0.6218,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.417045 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.417955 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0195],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.418571 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:02.419924 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:02.420656 - k: tensor([0.0705], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0723]
0:04:01.972997 - bracket_assembly_nut_noaug_coarse--917955
0:04:01.973210 - {'grad_norm': 1.0012561082839966, 'grad_norm_std': inf, 'learning_rate': 5e-10, 'time_forward': 0.05598783493041992, 'time_backward': 0.0775899887084961, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269122.0009346, 'n_iterations': 23, 'n_datas': 184, 'train_loss_TCO-iter=1': 0.07228562980890274, 'train_loss_TCO': 0.07228562980890274, 'train_loss_total': 0.07228562980890274, 'train_grad_norm': 1.0012561082839966, 'epoch': 22}
0:04:01.973331 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:01.980696 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:02.514740 - iteration 0
0:04:02.737869 - vxvyvz tensor([[ 0.1038,  0.0863, -0.0708]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:02.738875 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:02.739894 - dR tensor([[[-0.5097, -0.4453,  0.7362],
         [ 0.3214, -0.8922, -0.3172],
         [ 0.7981,  0.0749,  0.5979]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:02.740757 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:02.744009 - k: tensor([[[-0.5097, -0.4453,  0.7362, -0.0100],
         [ 0.3214, -0.8922, -0.3172,  0.0062],
         [ 0.7981,  0.0749,  0.5979,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.744932 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.746308 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:02.746998 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:02.747645 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:02.748297 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.073]
0:04:02.301338 - bracket_assembly_nut_noaug_coarse--917955
0:04:02.301553 - {'grad_norm': 1.0831080675125122, 'grad_norm_std': inf, 'learning_rate': 5.208333333333333e-10, 'time_forward': 0.055268049240112305, 'time_backward': 0.07753348350524902, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269122.3287108, 'n_iterations': 24, 'n_datas': 192, 'train_loss_TCO-iter=1': 0.07297208160161972, 'train_loss_TCO': 0.07297208160161972, 'train_loss_total': 0.07297208160161972, 'train_grad_norm': 1.0831080675125122, 'epoch': 23}
0:04:02.301668 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:02.309208 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:02.843315 - iteration 0
0:04:03.067004 - vxvyvz tensor([[ 0.0953,  0.0821, -0.0694]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:03.068059 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:03.069056 - dR tensor([[[-0.5384, -0.4190,  0.7311],
         [ 0.3383, -0.9021, -0.2679],
         [ 0.7718,  0.1030,  0.6275]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:03.069890 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:03.073141 - k: tensor([[[-0.5384, -0.4190,  0.7311, -0.0100],
         [ 0.3383, -0.9021, -0.2679,  0.0062],
         [ 0.7718,  0.1030,  0.6275,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:03.074063 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:03.075489 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0208],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:03.076202 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:03.076839 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:03.077445 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0727]
         [ 0.3490, -0.8967, -0.2721],█| 1/1 [00:00<00:00,  7.26it/s, loss=0.073]
         [ 0.7810,  0.1178,  0.6134]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:04.047216 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:04.050423 - k: tensor([[[-0.5180, -0.4266,  0.7414, -0.0100],
         [ 0.3490, -0.8967, -0.2721,  0.0062],
         [ 0.7810,  0.1178,  0.6134,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.051387 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.052935 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0217],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.053558 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.054169 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.054784 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, loss=0.073]
0:04:03.606848 - bracket_assembly_nut_noaug_coarse--917955
0:04:03.607062 - {'grad_norm': 1.1123158931732178, 'grad_norm_std': inf, 'learning_rate': 6.041666666666667e-10, 'time_forward': 0.05536246299743652, 'time_backward': 0.07631301879882812, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269123.6338165, 'n_iterations': 28, 'n_datas': 224, 'train_loss_TCO-iter=1': 0.07304782420396805, 'train_loss_TCO': 0.07304782420396805, 'train_loss_total': 0.07304782420396805, 'train_grad_norm': 1.1123158931732178, 'epoch': 27}
0:04:03.607178 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:03.614563 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:04.148654 - iteration 0
0:04:04.371788 - vxvyvz tensor([[ 0.0994,  0.0836, -0.0685]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:04.372806 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:04.373762 - dR tensor([[[-0.5264, -0.4306,  0.7331],
         [ 0.3295, -0.8982, -0.2910],
         [ 0.7838,  0.0884,  0.6147]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:04.374613 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:04.377827 - k: tensor([[[-0.5264, -0.4306,  0.7331, -0.0100],
         [ 0.3295, -0.8982, -0.2910,  0.0062],
         [ 0.7838,  0.0884,  0.6147,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.378734 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.380207 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.380939 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.381552 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.382169 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, loss=0.0727]
0:04:03.942650 - bracket_assembly_nut_noaug_coarse--917955
0:04:03.942868 - {'grad_norm': 1.066240906715393, 'grad_norm_std': inf, 'learning_rate': 6.25e-10, 'time_forward': 0.05527925491333008, 'time_backward': 0.07662773132324219, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269123.9615927, 'n_iterations': 29, 'n_datas': 232, 'train_loss_TCO-iter=1': 0.07267860323190689, 'train_loss_TCO': 0.07267860323190689, 'train_loss_total': 0.07267860323190689, 'train_grad_norm': 1.066240906715393, 'epoch': 28}
0:04:03.942987 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:03.950505 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:04.484643 - iteration 0
0:04:04.707883 - vxvyvz tensor([[ 0.1038,  0.0863, -0.0708]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:04.708870 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:04.709839 - dR tensor([[[-0.5097, -0.4453,  0.7361],
         [ 0.3214, -0.8922, -0.3172],
         [ 0.7981,  0.0749,  0.5979]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:04.710682 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:04.713915 - k: tensor([[[-0.5097, -0.4453,  0.7361, -0.0100],
         [ 0.3214, -0.8922, -0.3172,  0.0062],
         [ 0.7981,  0.0749,  0.5979,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.714821 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.715761 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:04.716433 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.717465 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:04.718185 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, loss=0.073]
0:04:04.293526 - bracket_assembly_nut_noaug_coarse--917955
0:04:04.293749 - {'grad_norm': 1.0839422941207886, 'grad_norm_std': inf, 'learning_rate': 6.458333333333333e-10, 'time_forward': 0.05540156364440918, 'time_backward': 0.07623028755187988, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269124.297316, 'n_iterations': 30, 'n_datas': 240, 'train_loss_TCO-iter=1': 0.07299986481666565, 'train_loss_TCO': 0.07299986481666565, 'train_loss_total': 0.07299986481666565, 'train_grad_norm': 1.0839422941207886, 'epoch': 29}
0:04:04.293883 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:04.301328 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:04.835371 - iteration 0
0:04:05.058692 - vxvyvz tensor([[ 0.1066,  0.0866, -0.0675]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:05.059747 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:05.060750 - dR tensor([[[-0.5239, -0.4266,  0.7372],
         [ 0.3181, -0.9009, -0.2953],
         [ 0.7901,  0.0798,  0.6077]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:05.061609 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:05.064843 - k: tensor([[[-0.5239, -0.4266,  0.7372, -0.0100],
         [ 0.3181, -0.9009, -0.2953,  0.0062],
         [ 0.7901,  0.0798,  0.6077,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:05.065745 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:05.067192 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0203],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:05.067945 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:05.068578 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:05.069194 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, loss=0.0726]
0:04:05.816912 - iteration 0-0.2721],█| 1/1 [00:00<00:00,  7.26it/s, loss=0.073]
0:04:06.040226 - vxvyvz tensor([[ 0.1057,  0.0844, -0.0701]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:06.041216 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.042168 - dR tensor([[[-0.5077, -0.4815,  0.7144],
         [ 0.3631, -0.8716, -0.3294],
         [ 0.7813,  0.0921,  0.6173]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:06.042997 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:06.046271 - k: tensor([[[-0.5077, -0.4815,  0.7144, -0.0100],
         [ 0.3631, -0.8716, -0.3294,  0.0062],
         [ 0.7813,  0.0921,  0.6173,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.047728 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.048778 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0210],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.049417 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.050026 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.050639 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0729]
0:04:05.597796 - bracket_assembly_nut_noaug_coarse--917955
0:04:05.598002 - {'grad_norm': 1.0543749332427979, 'grad_norm_std': inf, 'learning_rate': 7.291666666666667e-10, 'time_forward': 0.055487871170043945, 'time_backward': 0.07742905616760254, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269125.6309733, 'n_iterations': 34, 'n_datas': 272, 'train_loss_TCO-iter=1': 0.07285641133785248, 'train_loss_TCO': 0.07285641133785248, 'train_loss_total': 0.07285641133785248, 'train_grad_norm': 1.0543749332427979, 'epoch': 33}
0:04:05.598118 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:05.605521 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.139577 - iteration 0
0:04:06.363069 - vxvyvz tensor([[ 0.1124,  0.0856, -0.0652]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:06.364119 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.365087 - dR tensor([[[-0.5097, -0.4551,  0.7302],
         [ 0.3526, -0.8846, -0.3052],
         [ 0.7848,  0.1019,  0.6113]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:06.365922 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:06.369230 - k: tensor([[[-0.5097, -0.4551,  0.7302, -0.0100],
         [ 0.3526, -0.8846, -0.3052,  0.0062],
         [ 0.7848,  0.1019,  0.6113,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.370685 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.371632 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0196],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.372292 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.372925 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.373544 - k: tensor([0.0705], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0724]
0:04:05.930441 - bracket_assembly_nut_noaug_coarse--917955
0:04:05.930652 - {'grad_norm': 1.098724126815796, 'grad_norm_std': inf, 'learning_rate': 7.500000000000001e-10, 'time_forward': 0.05572962760925293, 'time_backward': 0.07941317558288574, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269125.9558506, 'n_iterations': 35, 'n_datas': 280, 'train_loss_TCO-iter=1': 0.07236400246620178, 'train_loss_TCO': 0.07236400246620178, 'train_loss_total': 0.07236400246620178, 'train_grad_norm': 1.098724126815796, 'epoch': 34}
0:04:05.930767 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:05.938115 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.472250 - iteration 0
0:04:06.695560 - vxvyvz tensor([[ 0.1066,  0.0880, -0.0695]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:06.696581 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.697567 - dR tensor([[[-0.5325, -0.4205,  0.7346],
         [ 0.3255, -0.9029, -0.2809],
         [ 0.7813,  0.0895,  0.6177]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:06.698397 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:06.701668 - k: tensor([[[-0.5325, -0.4205,  0.7346, -0.0100],
         [ 0.3255, -0.9029, -0.2809,  0.0062],
         [ 0.7813,  0.0895,  0.6177,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.703021 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.704104 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:06.704761 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.705380 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:06.705997 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0728]
0:04:06.258309 - bracket_assembly_nut_noaug_coarse--917955
0:04:06.258528 - {'grad_norm': 1.1211427450180054, 'grad_norm_std': inf, 'learning_rate': 7.708333333333334e-10, 'time_forward': 0.05559682846069336, 'time_backward': 0.07681536674499512, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269126.2856314, 'n_iterations': 36, 'n_datas': 288, 'train_loss_TCO-iter=1': 0.0727926641702652, 'train_loss_TCO': 0.0727926641702652, 'train_loss_total': 0.0727926641702652, 'train_grad_norm': 1.1211427450180054, 'epoch': 35}
0:04:06.258648 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:06.266271 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:06.800431 - iteration 0
0:04:07.023884 - vxvyvz tensor([[ 0.1038,  0.0889, -0.0681]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:07.024884 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:07.025836 - dR tensor([[[-0.5273, -0.4319,  0.7317],
         [ 0.3319, -0.8974, -0.2906],
         [ 0.7822,  0.0896,  0.6165]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:07.026690 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:07.029939 - k: tensor([[[-0.5273, -0.4319,  0.7317, -0.0100],
         [ 0.3319, -0.8974, -0.2906,  0.0062],
         [ 0.7822,  0.0896,  0.6165,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.031499 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.032461 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0204],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.033092 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:07.033698 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:07.034303 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0726]
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, loss=0.0728]
0:04:07.225039 - bracket_assembly_nut_noaug_coarse--917955
0:04:07.225234 - {'grad_norm': 1.1043158769607544, 'grad_norm_std': inf, 'learning_rate': 8.333333333333334e-10, 'time_forward': 0.05545353889465332, 'time_backward': 0.07639217376708984, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269127.2540367, 'n_iterations': 39, 'n_datas': 312, 'train_loss_TCO-iter=1': 0.07275736331939697, 'train_loss_TCO': 0.07275736331939697, 'train_loss_total': 0.07275736331939697, 'train_grad_norm': 1.1043158769607544, 'epoch': 38}
0:04:07.225347 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:07.232837 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:07.766871 - iteration 0
0:04:07.990301 - vxvyvz tensor([[ 0.1021,  0.0852, -0.0700]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:07.991349 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:07.992352 - dR tensor([[[-0.5310, -0.4410,  0.7236],
         [ 0.3384, -0.8932, -0.2961],
         [ 0.7769,  0.0877,  0.6235]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:07.993215 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:07.996454 - k: tensor([[[-0.5310, -0.4410,  0.7236, -0.0100],
         [ 0.3384, -0.8932, -0.2961,  0.0062],
         [ 0.7769,  0.0877,  0.6235,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.997358 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.998254 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0210],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:07.999392 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.000142 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.000768 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0728]
0:04:07.564869 - bracket_assembly_nut_noaug_coarse--917955
0:04:07.565074 - {'grad_norm': 1.0066555738449097, 'grad_norm_std': inf, 'learning_rate': 8.541666666666667e-10, 'time_forward': 0.05561256408691406, 'time_backward': 0.07675838470458984, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269127.5804567, 'n_iterations': 40, 'n_datas': 320, 'train_loss_TCO-iter=1': 0.0727778822183609, 'train_loss_TCO': 0.0727778822183609, 'train_loss_total': 0.0727778822183609, 'train_grad_norm': 1.0066555738449097, 'epoch': 39}
0:04:07.565191 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:07.572630 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:08.106703 - iteration 0
0:04:08.330299 - vxvyvz tensor([[ 0.1012,  0.0898, -0.0703]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:08.331334 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:08.332346 - dR tensor([[[-0.5179, -0.4500,  0.7275],
         [ 0.3511, -0.8873, -0.2989],
         [ 0.7801,  0.1006,  0.6176]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:08.333180 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:08.336429 - k: tensor([[[-0.5179, -0.4500,  0.7275, -0.0100],
         [ 0.3511, -0.8873, -0.2989,  0.0062],
         [ 0.7801,  0.1006,  0.6176,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.337335 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.338840 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0211],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.339500 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.340158 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.340780 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0728]
0:04:07.898529 - bracket_assembly_nut_noaug_coarse--917955
0:04:07.898732 - {'grad_norm': 1.0141006708145142, 'grad_norm_std': inf, 'learning_rate': 8.75e-10, 'time_forward': 0.055817365646362305, 'time_backward': 0.07618999481201172, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269127.9198406, 'n_iterations': 41, 'n_datas': 328, 'train_loss_TCO-iter=1': 0.07282433658838272, 'train_loss_TCO': 0.07282433658838272, 'train_loss_total': 0.07282433658838272, 'train_grad_norm': 1.0141006708145142, 'epoch': 40}
0:04:07.898842 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:07.906197 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:08.440259 - iteration 0
0:04:08.663664 - vxvyvz tensor([[ 0.1045,  0.0876, -0.0710]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:08.664691 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:08.665667 - dR tensor([[[-0.5218, -0.4162,  0.7447],
         [ 0.3274, -0.9038, -0.2758],
         [ 0.7878,  0.0999,  0.6078]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:08.666494 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:08.669731 - k: tensor([[[-0.5218, -0.4162,  0.7447, -0.0100],
         [ 0.3274, -0.9038, -0.2758,  0.0062],
         [ 0.7878,  0.0999,  0.6078,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.671145 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.672211 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:08.672863 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.673472 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:08.674086 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.073]
0:04:08.233146 - bracket_assembly_nut_noaug_coarse--917955
0:04:08.233337 - {'grad_norm': 1.1266306638717651, 'grad_norm_std': inf, 'learning_rate': 8.958333333333333e-10, 'time_forward': 0.055605411529541016, 'time_backward': 0.07683849334716797, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269128.2537603, 'n_iterations': 42, 'n_datas': 336, 'train_loss_TCO-iter=1': 0.07296188175678253, 'train_loss_TCO': 0.07296188175678253, 'train_loss_total': 0.07296188175678253, 'train_grad_norm': 1.1266306638717651, 'epoch': 41}
0:04:08.233451 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:08.240822 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:08.774860 - iteration 0
0:04:08.998194 - vxvyvz tensor([[ 0.1003,  0.0856, -0.0693]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:08.999235 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:09.000243 - dR tensor([[[-0.5201, -0.4885,  0.7007],
         [ 0.3365, -0.8712, -0.3575],
         [ 0.7850,  0.0498,  0.6174]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:09.001090 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:09.004367 - k: tensor([[[-0.5201, -0.4885,  0.7007, -0.0100],
         [ 0.3365, -0.8712, -0.3575,  0.0062],
         [ 0.7850,  0.0498,  0.6174,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:09.005799 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:09.006759 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0208],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:09.007417 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:09.008071 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:09.008704 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0728]
0:04:08.563986 - bracket_assembly_nut_noaug_coarse--917955
0:04:08.564216 - {'grad_norm': 1.0203062295913696, 'grad_norm_std': inf, 'learning_rate': 9.166666666666666e-10, 'time_forward': 0.05556440353393555, 'time_backward': 0.07647466659545898, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269128.5880094, 'n_iterations': 43, 'n_datas': 344, 'train_loss_TCO-iter=1': 0.07280300557613373, 'train_loss_TCO': 0.07280300557613373, 'train_loss_total': 0.07280300557613373, 'train_grad_norm': 1.0203062295913696, 'epoch': 42}
0:04:08.564332 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:08.571759 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:09.105887 - iteration 0
0:04:09.329901 - vxvyvz tensor([[ 0.0986,  0.0920, -0.0725]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:09.330935 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:09.331967 - dR tensor([[[-0.5180, -0.4266,  0.7414],
         [ 0.3490, -0.8967, -0.2721],
         [ 0.7810,  0.1178,  0.6134]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:09.332841 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:09.682329 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],, loss=0.0728]
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:09.682959 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:09.683609 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:09.684269 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0728]
0:04:09.237246 - bracket_assembly_nut_noaug_coarse--917955
0:04:09.237442 - {'grad_norm': 1.1205782890319824, 'grad_norm_std': inf, 'learning_rate': 9.583333333333334e-10, 'time_forward': 0.055359601974487305, 'time_backward': 0.07707524299621582, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269129.264262, 'n_iterations': 45, 'n_datas': 360, 'train_loss_TCO-iter=1': 0.07275949418544769, 'train_loss_TCO': 0.07275949418544769, 'train_loss_total': 0.07275949418544769, 'train_grad_norm': 1.1205782890319824, 'epoch': 44}
0:04:09.237554 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:09.244942 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:09.779011 - iteration 0
0:04:10.002349 - vxvyvz tensor([[ 0.1017,  0.0874, -0.0696]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:10.003464 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.004486 - dR tensor([[[-0.5176, -0.4454,  0.7305],
         [ 0.3360, -0.8910, -0.3052],
         [ 0.7869,  0.0875,  0.6109]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:10.005319 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:10.008591 - k: tensor([[[-0.5176, -0.4454,  0.7305, -0.0100],
         [ 0.3360, -0.8910, -0.3052,  0.0062],
         [ 0.7869,  0.0875,  0.6109,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.009980 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.010955 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.011609 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.012265 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.012889 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0728]
0:04:09.566052 - bracket_assembly_nut_noaug_coarse--917955
0:04:09.566262 - {'grad_norm': 1.0185129642486572, 'grad_norm_std': inf, 'learning_rate': 9.791666666666667e-10, 'time_forward': 0.05562186241149902, 'time_backward': 0.07731771469116211, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269129.593034, 'n_iterations': 46, 'n_datas': 368, 'train_loss_TCO-iter=1': 0.07279300689697266, 'train_loss_TCO': 0.07279300689697266, 'train_loss_total': 0.07279300689697266, 'train_grad_norm': 1.0185129642486572, 'epoch': 45}
0:04:09.566375 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:09.573818 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.107886 - iteration 0
0:04:10.331580 - vxvyvz tensor([[ 0.1079,  0.0863, -0.0689]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:10.332636 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.333602 - dR tensor([[[-0.5093, -0.4582,  0.7285],
         [ 0.3540, -0.8831, -0.3079],
         [ 0.7844,  0.1011,  0.6119]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:10.334436 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:10.337709 - k: tensor([[[-0.5093, -0.4582,  0.7285, -0.0100],
         [ 0.3540, -0.8831, -0.3079,  0.0062],
         [ 0.7844,  0.1011,  0.6119,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.339121 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.340270 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0207],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.340910 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.341521 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.342137 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0727]
0:04:09.887206 - bracket_assembly_nut_noaug_coarse--917955
0:04:09.887416 - {'grad_norm': 1.1078332662582397, 'grad_norm_std': inf, 'learning_rate': 1e-09, 'time_forward': 0.05602765083312988, 'time_backward': 0.07777833938598633, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269129.9227982, 'n_iterations': 47, 'n_datas': 376, 'train_loss_TCO-iter=1': 0.07273665815591812, 'train_loss_TCO': 0.07273665815591812, 'train_loss_total': 0.07273665815591812, 'train_grad_norm': 1.1078332662582397, 'epoch': 46}
0:04:09.887530 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:09.894942 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.429038 - iteration 0
0:04:10.652593 - vxvyvz tensor([[ 0.0998,  0.0913, -0.0752]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:10.653625 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.654595 - dR tensor([[[-0.5215, -0.4470,  0.7268],
         [ 0.3445, -0.8896, -0.2999],
         [ 0.7806,  0.0940,  0.6179]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:10.655471 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:10.658704 - k: tensor([[[-0.5215, -0.4470,  0.7268, -0.0100],
         [ 0.3445, -0.8896, -0.2999,  0.0062],
         [ 0.7806,  0.0940,  0.6179,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.660491 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.661479 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0225],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.662112 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.662720 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.663369 - k: tensor([0.0715], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0733]
0:04:10.210119 - bracket_assembly_nut_noaug_coarse--917955
0:04:10.210324 - {'grad_norm': 0.9864000082015991, 'grad_norm_std': inf, 'learning_rate': 1.0208333333333334e-09, 'time_forward': 0.05606698989868164, 'time_backward': 0.07714319229125977, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269130.2434158, 'n_iterations': 48, 'n_datas': 384, 'train_loss_TCO-iter=1': 0.07334179431200027, 'train_loss_TCO': 0.07334179431200027, 'train_loss_total': 0.07334179431200027, 'train_grad_norm': 0.9864000082015991, 'epoch': 47}
0:04:10.210438 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:10.217827 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.751860 - iteration 0
0:04:10.975813 - vxvyvz tensor([[ 0.1045,  0.0876, -0.0710]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:10.976852 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:10.977820 - dR tensor([[[-0.5218, -0.4162,  0.7446],
         [ 0.3274, -0.9038, -0.2758],
         [ 0.7878,  0.0999,  0.6078]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:10.978657 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:10.981910 - k: tensor([[[-0.5218, -0.4162,  0.7446, -0.0100],
         [ 0.3274, -0.9038, -0.2758,  0.0062],
         [ 0.7878,  0.0999,  0.6078,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.983436 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.984390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:10.985020 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.985628 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:10.986244 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.073]
0:04:10.535882 - bracket_assembly_nut_noaug_coarse--917955
0:04:10.536086 - {'grad_norm': 1.1264927387237549, 'grad_norm_std': inf, 'learning_rate': 1.0416666666666667e-09, 'time_forward': 0.056136369705200195, 'time_backward': 0.07729601860046387, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269130.5664477, 'n_iterations': 49, 'n_datas': 392, 'train_loss_TCO-iter=1': 0.07295485585927963, 'train_loss_TCO': 0.07295485585927963, 'train_loss_total': 0.07295485585927963, 'train_grad_norm': 1.1264927387237549, 'epoch': 48}
0:04:10.536209 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:10.543618 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.077736 - iteration 0
0:04:11.300945 - vxvyvz tensor([[ 0.1048,  0.0915, -0.0715]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:11.302037 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.302996 - dR tensor([[[-0.5319, -0.4306,  0.7291],
         [ 0.3349, -0.8978, -0.2859],
         [ 0.7778,  0.0921,  0.6218]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:11.303908 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:11.307349 - k: tensor([[[-0.5319, -0.4306,  0.7291, -0.0100],
         [ 0.3349, -0.8978, -0.2859,  0.0062],
         [ 0.7778,  0.0921,  0.6218,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.308809 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.309812 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0215],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.310423 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:11.311016 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:11.311646 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0729]
         [ 0.7809,  0.1178,  0.6134,  0.1920],,  0.4165, -0.0100],, loss=0.0728]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.633233 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.634193 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0208],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:11.634799 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:11.635427 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:11.636060 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0728]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:11.004888 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.538772 - iteration 0
0:04:11.755303 - vxvyvz tensor([[-0.0071,  0.0220, -0.0267]], device='cuda:0')
0:04:11.756304 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.757249 - dR tensor([[[ 0.8637,  0.4773, -0.1617],
         [-0.1224,  0.5100,  0.8514],
         [ 0.4888, -0.7156,  0.4989]]], device='cuda:0')
0:04:11.758080 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:11.761156 - k: tensor([[[ 0.8637,  0.4773, -0.1617, -0.0100],
         [-0.1224,  0.5100,  0.8514,  0.0062],
         [ 0.4888, -0.7156,  0.4989,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.762051 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.762953 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0080],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.763602 - k: tensor([0.0049], device='cuda:0')
0:04:11.764253 - k: tensor([0.0003], device='cuda:0')
0:04:11.764869 - k: tensor([0.0667], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.79it/s]
0:04:11.252216 - bracket_assembly_nut_noaug_coarse--917955
0:04:11.252457 - {'grad_norm': 1.0283194780349731, 'grad_norm_std': inf, 'learning_rate': 1.0833333333333333e-09, 'time_forward': 0.05558943748474121, 'time_backward': 0.07722902297973633, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269131.2666605, 'n_iterations': 51, 'n_datas': 408, 'train_loss_TCO-iter=1': 0.07278245687484741, 'train_loss_TCO': 0.07278245687484741, 'train_loss_total': 0.07278245687484741, 'train_grad_norm': 1.0283194780349731, 'val_loss_TCO-iter=1': 0.07192646712064743, 'val_loss_TCO': 0.07192646712064743, 'val_loss_total': 0.07192646712064743, 'epoch': 50}
0:04:11.252590 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:11.260257 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:11.791005 - iteration 0
0:04:12.014441 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:12.015470 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.016474 - dR tensor([[[-0.5140, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3085],
         [ 0.7848,  0.0934,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:12.017310 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:12.020653 - k: tensor([[[-0.5140, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.021554 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.022455 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.023080 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.023741 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.024905 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.53it/s, loss=0.0731]
0:04:11.588369 - bracket_assembly_nut_noaug_coarse--917955
0:04:11.588573 - {'grad_norm': 1.146813154220581, 'grad_norm_std': inf, 'learning_rate': 1.1041666666666666e-09, 'time_forward': 0.052533626556396484, 'time_backward': 0.0762794017791748, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269131.6041927, 'n_iterations': 52, 'n_datas': 416, 'train_loss_TCO-iter=1': 0.07305654883384705, 'train_loss_TCO': 0.07305654883384705, 'train_loss_total': 0.07305654883384705, 'train_grad_norm': 1.146813154220581, 'epoch': 51}
0:04:11.588748 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:11.596230 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.130266 - iteration 0
0:04:12.353631 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:12.354694 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.355697 - dR tensor([[[-0.5140, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3085],
         [ 0.7848,  0.0934,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:12.356587 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:12.359801 - k: tensor([[[-0.5140, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.361299 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.362206 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.362832 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.363488 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.364146 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.073]
0:04:11.922802 - bracket_assembly_nut_noaug_coarse--917955
0:04:11.923019 - {'grad_norm': 1.146316409111023, 'grad_norm_std': inf, 'learning_rate': 1.125e-09, 'time_forward': 0.05559039115905762, 'time_backward': 0.07705044746398926, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269131.9441364, 'n_iterations': 53, 'n_datas': 424, 'train_loss_TCO-iter=1': 0.0730496421456337, 'train_loss_TCO': 0.0730496421456337, 'train_loss_total': 0.0730496421456337, 'train_grad_norm': 1.146316409111023, 'epoch': 52}
0:04:11.923158 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:11.930628 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.464780 - iteration 0
0:04:12.688939 - vxvyvz tensor([[ 0.1062,  0.0887, -0.0668]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:12.689950 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.690904 - dR tensor([[[-0.5207, -0.4473,  0.7272],
         [ 0.3450, -0.8894, -0.3000],
         [ 0.7809,  0.0947,  0.6174]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:12.691789 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:12.695018 - k: tensor([[[-0.5207, -0.4473,  0.7272, -0.0100],
         [ 0.3450, -0.8894, -0.3000,  0.0062],
         [ 0.7809,  0.0947,  0.6174,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.696486 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.697481 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0200],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:12.698107 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.698715 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:12.699353 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0725]
0:04:12.250683 - bracket_assembly_nut_noaug_coarse--917955
0:04:12.250891 - {'grad_norm': 1.0566582679748535, 'grad_norm_std': inf, 'learning_rate': 1.1458333333333333e-09, 'time_forward': 0.05645465850830078, 'time_backward': 0.07663679122924805, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269132.2789385, 'n_iterations': 54, 'n_datas': 432, 'train_loss_TCO-iter=1': 0.07249119132757187, 'train_loss_TCO': 0.07249119132757187, 'train_loss_total': 0.07249119132757187, 'train_grad_norm': 1.0566582679748535, 'epoch': 53}
0:04:12.251035 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:12.258530 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:12.792635 - iteration 0
0:04:13.016487 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:13.017503 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.018455 - dR tensor([[[-0.5140, -0.4543,  0.7277],
         [ 0.3462, -0.8860, -0.3085],
         [ 0.7848,  0.0934,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:13.019325 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:13.022598 - k: tensor([[[-0.5140, -0.4543,  0.7277, -0.0100],
         [ 0.3462, -0.8860, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.024024 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.025023 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.025651 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.026257 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.026870 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.073]
0:04:12.581307 - bracket_assembly_nut_noaug_coarse--917955
0:04:12.581525 - {'grad_norm': 1.1461082696914673, 'grad_norm_std': inf, 'learning_rate': 1.1666666666666668e-09, 'time_forward': 0.05606889724731445, 'time_backward': 0.07766413688659668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269132.6074235, 'n_iterations': 55, 'n_datas': 440, 'train_loss_TCO-iter=1': 0.07303300499916077, 'train_loss_TCO': 0.07303300499916077, 'train_loss_total': 0.07303300499916077, 'train_grad_norm': 1.1461082696914673, 'epoch': 54}
0:04:12.581650 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:12.589093 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.123145 - iteration 0
0:04:13.346427 - vxvyvz tensor([[ 0.0986,  0.0920, -0.0725]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:13.347488 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.348498 - dR tensor([[[-0.5180, -0.4266,  0.7414],
         [ 0.3490, -0.8967, -0.2721],
         [ 0.7809,  0.1178,  0.6134]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:13.349347 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:13.352607 - k: tensor([[[-0.5180, -0.4266,  0.7414, -0.0100],
         [ 0.3490, -0.8967, -0.2721,  0.0062],
         [ 0.7809,  0.1178,  0.6134,  0.1920],,  0.4165, -0.0100],, loss=0.0728]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.354038 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.354992 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0217],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.355649 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.356295 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.356935 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0731]
0:04:12.909111 - bracket_assembly_nut_noaug_coarse--917955
0:04:12.909329 - {'grad_norm': 1.112452745437622, 'grad_norm_std': inf, 'learning_rate': 1.1874999999999999e-09, 'time_forward': 0.05552530288696289, 'time_backward': 0.0765984058380127, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269132.9363086, 'n_iterations': 56, 'n_datas': 448, 'train_loss_TCO-iter=1': 0.07305184751749039, 'train_loss_TCO': 0.07305184751749039, 'train_loss_total': 0.07305184751749039, 'train_grad_norm': 1.112452745437622, 'epoch': 55}
0:04:12.909462 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:12.916958 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.451015 - iteration 0
0:04:13.674758 - vxvyvz tensor([[ 0.1045,  0.0876, -0.0709]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:13.675781 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.676775 - dR tensor([[[-0.5218, -0.4162,  0.7446],
         [ 0.3274, -0.9038, -0.2758],
         [ 0.7877,  0.0999,  0.6078]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:13.677595 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:13.680825 - k: tensor([[[-0.5218, -0.4162,  0.7446, -0.0100],
         [ 0.3274, -0.9038, -0.2758,  0.0062],
         [ 0.7877,  0.0999,  0.6078,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.681708 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.683200 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:13.683824 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.684466 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:13.685061 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.073]
0:04:13.249199 - bracket_assembly_nut_noaug_coarse--917955
0:04:13.249412 - {'grad_norm': 1.1268010139465332, 'grad_norm_std': inf, 'learning_rate': 1.2083333333333334e-09, 'time_forward': 0.05578041076660156, 'time_backward': 0.07726621627807617, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269133.2649837, 'n_iterations': 57, 'n_datas': 456, 'train_loss_TCO-iter=1': 0.07297763228416443, 'train_loss_TCO': 0.07297763228416443, 'train_loss_total': 0.07297763228416443, 'train_grad_norm': 1.1268010139465332, 'epoch': 56}
0:04:13.249535 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:13.256957 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:13.791039 - iteration 0
0:04:14.014559 - vxvyvz tensor([[ 0.0996,  0.0889, -0.0695]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:14.015633 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.016623 - dR tensor([[[-0.5215, -0.4478,  0.7263],
         [ 0.3115, -0.8924, -0.3265],
         [ 0.7943,  0.0560,  0.6049]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:14.017467 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:14.020731 - k: tensor([[[-0.5215, -0.4478,  0.7263, -0.0100],
         [ 0.3115, -0.8924, -0.3265,  0.0062],
         [ 0.7943,  0.0560,  0.6049,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.022131 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.023149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0208],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.023808 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.024467 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.025078 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0728]
0:04:13.582239 - bracket_assembly_nut_noaug_coarse--917955
0:04:13.582440 - {'grad_norm': 1.0466457605361938, 'grad_norm_std': inf, 'learning_rate': 1.2291666666666667e-09, 'time_forward': 0.0557856559753418, 'time_backward': 0.07646560668945312, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269133.604353, 'n_iterations': 58, 'n_datas': 464, 'train_loss_TCO-iter=1': 0.07284782081842422, 'train_loss_TCO': 0.07284782081842422, 'train_loss_total': 0.07284782081842422, 'train_grad_norm': 1.0466457605361938, 'epoch': 57}
0:04:13.582566 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:13.589899 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.123979 - iteration 0
0:04:14.347264 - vxvyvz tensor([[ 0.1003,  0.0882, -0.0674]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:14.348305 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.349300 - dR tensor([[[-0.5044, -0.4506,  0.7366],
         [ 0.3170, -0.8901, -0.3275],
         [ 0.8032,  0.0683,  0.5918]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:14.350141 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:14.353373 - k: tensor([[[-0.5044, -0.4506,  0.7366, -0.0100],
         [ 0.3170, -0.8901, -0.3275,  0.0062],
         [ 0.8032,  0.0683,  0.5918,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.354833 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.355807 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.356477 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.357097 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.357705 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, loss=0.0727]
0:04:13.922423 - bracket_assembly_nut_noaug_coarse--917955
0:04:13.922633 - {'grad_norm': 1.1243243217468262, 'grad_norm_std': inf, 'learning_rate': 1.25e-09, 'time_forward': 0.05549788475036621, 'time_backward': 0.07609081268310547, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269133.9365754, 'n_iterations': 59, 'n_datas': 472, 'train_loss_TCO-iter=1': 0.07267104834318161, 'train_loss_TCO': 0.07267104834318161, 'train_loss_total': 0.07267104834318161, 'train_grad_norm': 1.1243243217468262, 'epoch': 58}
0:04:13.922749 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:13.930166 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.464283 - iteration 0
0:04:14.687644 - vxvyvz tensor([[ 0.1061,  0.0877, -0.0732]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:14.688667 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.689654 - dR tensor([[[-0.5096, -0.4344,  0.7427],
         [ 0.3116, -0.8978, -0.3113],
         [ 0.8020,  0.0728,  0.5929]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:14.690485 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:14.693743 - k: tensor([[[-0.5096, -0.4344,  0.7427, -0.0100],
         [ 0.3116, -0.8978, -0.3113,  0.0062],
         [ 0.8020,  0.0728,  0.5929,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.695119 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.696160 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0220],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:14.696803 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.697412 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:14.698026 - k: tensor([0.0713], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0732]
0:04:14.254243 - bracket_assembly_nut_noaug_coarse--917955
0:04:14.254447 - {'grad_norm': 1.0414581298828125, 'grad_norm_std': inf, 'learning_rate': 1.2708333333333333e-09, 'time_forward': 0.055550336837768555, 'time_backward': 0.07698869705200195, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269134.277736, 'n_iterations': 60, 'n_datas': 480, 'train_loss_TCO-iter=1': 0.0732344314455986, 'train_loss_TCO': 0.0732344314455986, 'train_loss_total': 0.0732344314455986, 'train_grad_norm': 1.0414581298828125, 'epoch': 59}
0:04:14.254561 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:14.261984 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:14.796100 - iteration 0
0:04:15.019707 - vxvyvz tensor([[ 0.0951,  0.0901, -0.0686]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:15.020745 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.021703 - dR tensor([[[-0.5165, -0.4703,  0.7156],
         [ 0.3376, -0.8798, -0.3345],
         [ 0.7869,  0.0688,  0.6132]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:15.022537 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:15.025743 - k: tensor([[[-0.5165, -0.4703,  0.7156, -0.0100],
         [ 0.3376, -0.8798, -0.3345,  0.0062],
         [ 0.7869,  0.0688,  0.6132,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.027168 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.028184 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.028818 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.029426 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.030038 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0727]
0:04:14.594157 - bracket_assembly_nut_noaug_coarse--917955
0:04:14.594351 - {'grad_norm': 1.08164644241333, 'grad_norm_std': inf, 'learning_rate': 1.2916666666666667e-09, 'time_forward': 0.05577850341796875, 'time_backward': 0.07670736312866211, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269134.610996, 'n_iterations': 61, 'n_datas': 488, 'train_loss_TCO-iter=1': 0.07270477712154388, 'train_loss_TCO': 0.07270477712154388, 'train_loss_total': 0.07270477712154388, 'train_grad_norm': 1.08164644241333, 'epoch': 60}
0:04:14.594466 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:14.601881 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.135984 - iteration 0
0:04:15.359073 - vxvyvz tensor([[ 0.1051,  0.0902, -0.0677]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:15.360144 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.361153 - dR tensor([[[-0.5178, -0.4580,  0.7226],
         [ 0.3401, -0.8852, -0.3174],
         [ 0.7850,  0.0814,  0.6141]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:15.361984 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:15.365218 - k: tensor([[[-0.5178, -0.4580,  0.7226, -0.0100],
         [ 0.3401, -0.8852, -0.3174,  0.0062],
         [ 0.7850,  0.0814,  0.6141,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.366642 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.367650 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0203],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.368314 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.368944 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.369550 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, loss=0.0726]
0:04:14.928396 - bracket_assembly_nut_noaug_coarse--917955
0:04:14.928589 - {'grad_norm': 1.067805290222168, 'grad_norm_std': inf, 'learning_rate': 1.3125e-09, 'time_forward': 0.05538535118103027, 'time_backward': 0.07646989822387695, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269134.948819, 'n_iterations': 62, 'n_datas': 496, 'train_loss_TCO-iter=1': 0.07262036949396133, 'train_loss_TCO': 0.07262036949396133, 'train_loss_total': 0.07262036949396133, 'train_grad_norm': 1.067805290222168, 'epoch': 61}
0:04:14.928725 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:14.936022 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.470092 - iteration 0
0:04:15.693352 - vxvyvz tensor([[ 0.1044,  0.0870, -0.0684]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:15.694373 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.695365 - dR tensor([[[-0.5069, -0.4209,  0.7522],
         [ 0.3453, -0.8987, -0.2702],
         [ 0.7898,  0.1228,  0.6010]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:15.696244 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:15.699491 - k: tensor([[[-0.5069, -0.4209,  0.7522, -0.0100],
         [ 0.3453, -0.8987, -0.2702,  0.0062],
         [ 0.7898,  0.1228,  0.6010,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.700438 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.701926 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0205],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:15.702550 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.703164 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:15.703807 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0727]
0:04:15.257458 - bracket_assembly_nut_noaug_coarse--917955
0:04:15.257663 - {'grad_norm': 1.1141033172607422, 'grad_norm_std': inf, 'learning_rate': 1.3333333333333335e-09, 'time_forward': 0.055416107177734375, 'time_backward': 0.07695341110229492, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269135.283694, 'n_iterations': 63, 'n_datas': 504, 'train_loss_TCO-iter=1': 0.0726877823472023, 'train_loss_TCO': 0.0726877823472023, 'train_loss_total': 0.0726877823472023, 'train_grad_norm': 1.1141033172607422, 'epoch': 62}
0:04:15.257785 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:15.265214 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:15.799290 - iteration 0
0:04:16.022484 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:16.023552 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.024560 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3462, -0.8860, -0.3085],
         [ 0.7848,  0.0934,  0.6126]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:16.025403 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:16.028662 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3462, -0.8860, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6126,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.030102 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.031094 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.031757 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.032410 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.033025 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.39it/s, loss=0.0731]
0:04:15.593057 - bracket_assembly_nut_noaug_coarse--917955
0:04:15.593266 - {'grad_norm': 1.146803379058838, 'grad_norm_std': inf, 'learning_rate': 1.3541666666666666e-09, 'time_forward': 0.05548858642578125, 'time_backward': 0.07613801956176758, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269135.6118941, 'n_iterations': 64, 'n_datas': 512, 'train_loss_TCO-iter=1': 0.07305559515953064, 'train_loss_TCO': 0.07305559515953064, 'train_loss_total': 0.07305559515953064, 'train_grad_norm': 1.146803379058838, 'epoch': 63}
0:04:15.593390 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:15.600899 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.134956 - iteration 0
0:04:16.358160 - vxvyvz tensor([[ 0.1037,  0.0849, -0.0710]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:16.359219 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.360238 - dR tensor([[[-0.5089, -0.4575,  0.7292],
         [ 0.3440, -0.8846, -0.3150],
         [ 0.7891,  0.0905,  0.6075]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:16.361086 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:16.364300 - k: tensor([[[-0.5089, -0.4575,  0.7292, -0.0100],
         [ 0.3440, -0.8846, -0.3150,  0.0062],
         [ 0.7891,  0.0905,  0.6075,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.365724 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.366729 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.367390 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.368043 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.368677 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0729]
0:04:15.922192 - bracket_assembly_nut_noaug_coarse--917955
0:04:15.922405 - {'grad_norm': 1.1359951496124268, 'grad_norm_std': inf, 'learning_rate': 1.3750000000000001e-09, 'time_forward': 0.0555119514465332, 'time_backward': 0.07675766944885254, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269135.9481978, 'n_iterations': 65, 'n_datas': 520, 'train_loss_TCO-iter=1': 0.07293594628572464, 'train_loss_TCO': 0.07293594628572464, 'train_loss_total': 0.07293594628572464, 'train_grad_norm': 1.1359951496124268, 'epoch': 64}
0:04:15.922545 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:15.929988 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.464056 - iteration 0
0:04:16.687299 - vxvyvz tensor([[ 0.1025,  0.0864, -0.0706]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:16.688354 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.689333 - dR tensor([[[-0.5366, -0.4386,  0.7209],
         [ 0.3358, -0.8947, -0.2945],
         [ 0.7741,  0.0841,  0.6274]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:16.690170 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:16.693398 - k: tensor([[[-0.5366, -0.4386,  0.7209, -0.0100],
         [ 0.3358, -0.8947, -0.2945,  0.0062],
         [ 0.7741,  0.0841,  0.6274,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.694810 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.695848 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0212],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:16.696498 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.697118 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:16.697722 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, loss=0.0728]
0:04:16.241732 - bracket_assembly_nut_noaug_coarse--917955
0:04:16.241949 - {'grad_norm': 1.0992300510406494, 'grad_norm_std': inf, 'learning_rate': 1.3958333333333334e-09, 'time_forward': 0.05544543266296387, 'time_backward': 0.07667160034179688, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269136.2771332, 'n_iterations': 66, 'n_datas': 528, 'train_loss_TCO-iter=1': 0.0728369802236557, 'train_loss_TCO': 0.0728369802236557, 'train_loss_total': 0.0728369802236557, 'train_grad_norm': 1.0992300510406494, 'epoch': 65}
0:04:16.242080 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:16.249624 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:16.783753 - iteration 0
0:04:17.007296 - vxvyvz tensor([[ 0.1055,  0.0916, -0.0701]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:17.008334 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.009307 - dR tensor([[[-0.4923, -0.4271,  0.7584],
         [ 0.3334, -0.8974, -0.2890],
         [ 0.8040,  0.1105,  0.5842]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:17.010149 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:17.013411 - k: tensor([[[-0.4923, -0.4271,  0.7584, -0.0100],
         [ 0.3334, -0.8974, -0.2890,  0.0062],
         [ 0.8040,  0.1105,  0.5842,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.014874 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.015851 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0210],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.016496 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.017113 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.017720 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0729]
0:04:16.572053 - bracket_assembly_nut_noaug_coarse--917955
0:04:16.572260 - {'grad_norm': 1.1536834239959717, 'grad_norm_std': inf, 'learning_rate': 1.4166666666666667e-09, 'time_forward': 0.055860280990600586, 'time_backward': 0.07697296142578125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269136.597423, 'n_iterations': 67, 'n_datas': 536, 'train_loss_TCO-iter=1': 0.07294075191020966, 'train_loss_TCO': 0.07294075191020966, 'train_loss_total': 0.07294075191020966, 'train_grad_norm': 1.1536834239959717, 'epoch': 66}
0:04:16.572444 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:16.579870 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.113923 - iteration 0
0:04:17.337381 - vxvyvz tensor([[ 0.1022,  0.0879, -0.0672]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:17.338402 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.339405 - dR tensor([[[-0.5146, -0.4453,  0.7327],
         [ 0.3355, -0.8910, -0.3058],
         [ 0.7890,  0.0884,  0.6079]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:17.340275 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:17.343498 - k: tensor([[[-0.5146, -0.4453,  0.7327, -0.0100],
         [ 0.3355, -0.8910, -0.3058,  0.0062],
         [ 0.7890,  0.0884,  0.6079,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.344729 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.345981 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.346602 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.347244 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.347905 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0726]
0:04:16.900224 - bracket_assembly_nut_noaug_coarse--917955
0:04:16.900433 - {'grad_norm': 1.1254388093948364, 'grad_norm_std': inf, 'learning_rate': 1.4375e-09, 'time_forward': 0.05565357208251953, 'time_backward': 0.07728171348571777, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269136.9279327, 'n_iterations': 68, 'n_datas': 544, 'train_loss_TCO-iter=1': 0.07256090641021729, 'train_loss_TCO': 0.07256090641021729, 'train_loss_total': 0.07256090641021729, 'train_grad_norm': 1.1254388093948364, 'epoch': 67}
0:04:16.900557 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:16.908028 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.442146 - iteration 0
0:04:17.665466 - vxvyvz tensor([[ 0.1033,  0.0885, -0.0714]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:17.666493 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.667485 - dR tensor([[[-0.5056, -0.4487,  0.7369],
         [ 0.3425, -0.8883, -0.3059],
         [ 0.7919,  0.0977,  0.6028]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:17.668377 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:17.671588 - k: tensor([[[-0.5056, -0.4487,  0.7369, -0.0100],
         [ 0.3425, -0.8883, -0.3059,  0.0062],
         [ 0.7919,  0.0977,  0.6028,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.672544 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.673961 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0214],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:17.674648 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.675293 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:17.675950 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.073]
0:04:17.241493 - bracket_assembly_nut_noaug_coarse--917955
0:04:17.241698 - {'grad_norm': 1.0032804012298584, 'grad_norm_std': inf, 'learning_rate': 1.4583333333333334e-09, 'time_forward': 0.05555391311645508, 'time_backward': 0.07927298545837402, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269137.2580338, 'n_iterations': 69, 'n_datas': 552, 'train_loss_TCO-iter=1': 0.07301309704780579, 'train_loss_TCO': 0.07301309704780579, 'train_loss_total': 0.07301309704780579, 'train_grad_norm': 1.0032804012298584, 'epoch': 68}
0:04:17.241823 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:17.249353 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:17.783415 - iteration 0
0:04:18.007247 - vxvyvz tensor([[ 0.1077,  0.0927, -0.0734]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:18.008278 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.009283 - dR tensor([[[-0.5305, -0.3989,  0.7480],
         [ 0.3324, -0.9096, -0.2493],
         [ 0.7798,  0.1164,  0.6151]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:18.010125 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:18.013391 - k: tensor([[[-0.5305, -0.3989,  0.7480, -0.0100],
         [ 0.3324, -0.9096, -0.2493,  0.0062],
         [ 0.7798,  0.1164,  0.6151,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.014776 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.015863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0220],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.016508 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.017159 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.017771 - k: tensor([0.0713], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0732]
0:04:17.583068 - bracket_assembly_nut_noaug_coarse--917955
0:04:17.583291 - {'grad_norm': 1.1329435110092163, 'grad_norm_std': inf, 'learning_rate': 1.4791666666666667e-09, 'time_forward': 0.05613255500793457, 'time_backward': 0.07947921752929688, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269137.6000519, 'n_iterations': 70, 'n_datas': 560, 'train_loss_TCO-iter=1': 0.07319596409797668, 'train_loss_TCO': 0.07319596409797668, 'train_loss_total': 0.07319596409797668, 'train_grad_norm': 1.1329435110092163, 'epoch': 69}
0:04:17.583417 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:17.590840 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.124954 - iteration 0
0:04:18.348324 - vxvyvz tensor([[ 0.1048,  0.0793, -0.0712]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:18.349371 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.350345 - dR tensor([[[-0.5068, -0.4472,  0.7370],
         [ 0.3289, -0.8906, -0.3142],
         [ 0.7968,  0.0831,  0.5984]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:18.351215 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:18.354447 - k: tensor([[[-0.5068, -0.4472,  0.7370, -0.0100],
         [ 0.3289, -0.8906, -0.3142,  0.0062],
         [ 0.7968,  0.0831,  0.5984,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.355952 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.356948 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0214],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.357566 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.358181 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.358785 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.073]
0:04:17.930321 - bracket_assembly_nut_noaug_coarse--917955
0:04:17.930525 - {'grad_norm': 1.0215083360671997, 'grad_norm_std': inf, 'learning_rate': 1.5000000000000002e-09, 'time_forward': 0.0556187629699707, 'time_backward': 0.07731080055236816, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269137.938829, 'n_iterations': 71, 'n_datas': 568, 'train_loss_TCO-iter=1': 0.07303306460380554, 'train_loss_TCO': 0.07303306460380554, 'train_loss_total': 0.07303306460380554, 'train_grad_norm': 1.0215083360671997, 'epoch': 70}
0:04:17.930658 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:17.938088 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.472224 - iteration 0
0:04:18.695573 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:18.696602 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.697596 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8860, -0.3085],
         [ 0.7848,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:18.698424 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:18.701683 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8860, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.703487 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.704451 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:18.705081 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.705691 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:18.706296 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.073]
0:04:18.284366 - bracket_assembly_nut_noaug_coarse--917955
0:04:18.284574 - {'grad_norm': 1.1462509632110596, 'grad_norm_std': inf, 'learning_rate': 1.5208333333333333e-09, 'time_forward': 0.05592608451843262, 'time_backward': 0.07757449150085449, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269138.2865565, 'n_iterations': 72, 'n_datas': 576, 'train_loss_TCO-iter=1': 0.07302340120077133, 'train_loss_TCO': 0.07302340120077133, 'train_loss_total': 0.07302340120077133, 'train_grad_norm': 1.1462509632110596, 'epoch': 71}
0:04:18.284735 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:18.292158 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:18.826277 - iteration 0
0:04:19.049472 - vxvyvz tensor([[ 0.1077,  0.0927, -0.0734]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:19.050498 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.051483 - dR tensor([[[-0.5305, -0.3989,  0.7480],
         [ 0.3324, -0.9096, -0.2493],
         [ 0.7798,  0.1164,  0.6151]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:19.052372 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:19.055585 - k: tensor([[[-0.5305, -0.3989,  0.7480, -0.0100],
         [ 0.3324, -0.9096, -0.2493,  0.0062],
         [ 0.7798,  0.1164,  0.6151,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.057053 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.058013 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0220],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.058641 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.059279 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.059936 - k: tensor([0.0713], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0732]
0:04:18.611044 - bracket_assembly_nut_noaug_coarse--917955
0:04:18.611259 - {'grad_norm': 1.1327711343765259, 'grad_norm_std': inf, 'learning_rate': 1.5416666666666668e-09, 'time_forward': 0.05544543266296387, 'time_backward': 0.07724523544311523, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269138.6399426, 'n_iterations': 73, 'n_datas': 584, 'train_loss_TCO-iter=1': 0.07316295802593231, 'train_loss_TCO': 0.07316295802593231, 'train_loss_total': 0.07316295802593231, 'train_grad_norm': 1.1327711343765259, 'epoch': 72}
0:04:18.611386 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:18.618828 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.152944 - iteration 0
0:04:19.376396 - vxvyvz tensor([[ 0.1036,  0.0874, -0.0782]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:19.377397 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.378356 - dR tensor([[[-0.5089, -0.4831,  0.7125],
         [ 0.3165, -0.8747, -0.3670],
         [ 0.8005,  0.0387,  0.5981]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:19.379213 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:19.382428 - k: tensor([[[-0.5089, -0.4831,  0.7125, -0.0100],
         [ 0.3165, -0.8747, -0.3670,  0.0062],
         [ 0.8005,  0.0387,  0.5981,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.383918 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.384953 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0235],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.385572 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.386184 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.386792 - k: tensor([0.0718], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0738]
0:04:18.933872 - bracket_assembly_nut_noaug_coarse--917955
0:04:18.934069 - {'grad_norm': 1.05030357837677, 'grad_norm_std': inf, 'learning_rate': 1.5625000000000001e-09, 'time_forward': 0.05568075180053711, 'time_backward': 0.07729291915893555, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269138.966844, 'n_iterations': 74, 'n_datas': 592, 'train_loss_TCO-iter=1': 0.0737631544470787, 'train_loss_TCO': 0.0737631544470787, 'train_loss_total': 0.0737631544470787, 'train_grad_norm': 1.05030357837677, 'epoch': 73}
0:04:18.934195 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:18.941589 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.475658 - iteration 0
0:04:19.698837 - vxvyvz tensor([[ 0.1079,  0.0862, -0.0689]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:19.699932 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.700915 - dR tensor([[[-0.5093, -0.4582,  0.7284],
         [ 0.3541, -0.8831, -0.3079],
         [ 0.7844,  0.1011,  0.6120]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:19.701746 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:19.705017 - k: tensor([[[-0.5093, -0.4582,  0.7284, -0.0100],
         [ 0.3541, -0.8831, -0.3079,  0.0062],
         [ 0.7844,  0.1011,  0.6120,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.705935 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.707461 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0207],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:19.708122 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.708755 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:19.709370 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0727]
0:04:19.272405 - bracket_assembly_nut_noaug_coarse--917955
0:04:19.272633 - {'grad_norm': 1.1074013710021973, 'grad_norm_std': inf, 'learning_rate': 1.5833333333333334e-09, 'time_forward': 0.05552411079406738, 'time_backward': 0.07848429679870605, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269139.2907135, 'n_iterations': 75, 'n_datas': 600, 'train_loss_TCO-iter=1': 0.07271557301282883, 'train_loss_TCO': 0.07271557301282883, 'train_loss_total': 0.07271557301282883, 'train_grad_norm': 1.1074013710021973, 'epoch': 74}
0:04:19.272798 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:19.280160 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:19.814210 - iteration 0
0:04:20.037669 - vxvyvz tensor([[ 0.0966,  0.0890, -0.0664]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:20.038705 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.039700 - dR tensor([[[-0.5037, -0.4154,  0.7575],
         [ 0.3527, -0.8993, -0.2587],
         [ 0.7886,  0.1369,  0.5994]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:20.040584 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:20.043775 - k: tensor([[[-0.5037, -0.4154,  0.7575, -0.0100],
         [ 0.3527, -0.8993, -0.2587,  0.0062],
         [ 0.7886,  0.1369,  0.5994,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.044719 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.046217 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0199],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.046839 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.047486 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.048140 - k: tensor([0.0706], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0725]
0:04:19.603262 - bracket_assembly_nut_noaug_coarse--917955
0:04:19.603478 - {'grad_norm': 1.0284909009933472, 'grad_norm_std': inf, 'learning_rate': 1.6041666666666668e-09, 'time_forward': 0.055658817291259766, 'time_backward': 0.0768895149230957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269139.6277738, 'n_iterations': 76, 'n_datas': 608, 'train_loss_TCO-iter=1': 0.07251773774623871, 'train_loss_TCO': 0.07251773774623871, 'train_loss_total': 0.07251773774623871, 'train_grad_norm': 1.0284909009933472, 'epoch': 75}
0:04:19.603605 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:19.610897 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.144999 - iteration 0
0:04:20.368588 - vxvyvz tensor([[ 0.1096,  0.0876, -0.0685]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:20.369617 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.370574 - dR tensor([[[-0.5118, -0.4379,  0.7391],
         [ 0.3350, -0.8939, -0.2977],
         [ 0.7911,  0.0952,  0.6042]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:20.371450 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:20.374656 - k: tensor([[[-0.5118, -0.4379,  0.7391, -0.0100],
         [ 0.3350, -0.8939, -0.2977,  0.0062],
         [ 0.7911,  0.0952,  0.6042,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.376151 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.377168 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.377796 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.378407 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.379022 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0727]
0:04:19.942294 - bracket_assembly_nut_noaug_coarse--917955
0:04:19.942511 - {'grad_norm': 0.9884295463562012, 'grad_norm_std': inf, 'learning_rate': 1.6249999999999999e-09, 'time_forward': 0.05577969551086426, 'time_backward': 0.0771794319152832, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269139.9589841, 'n_iterations': 77, 'n_datas': 616, 'train_loss_TCO-iter=1': 0.07269234955310822, 'train_loss_TCO': 0.07269234955310822, 'train_loss_total': 0.07269234955310822, 'train_grad_norm': 0.9884295463562012, 'epoch': 76}
0:04:19.942636 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:19.950015 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.484099 - iteration 0
0:04:20.707237 - vxvyvz tensor([[ 0.1022,  0.0808, -0.0684]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:20.708292 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.709292 - dR tensor([[[-0.5107, -0.4566,  0.7284],
         [ 0.3332, -0.8862, -0.3219],
         [ 0.7925,  0.0784,  0.6048]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:20.710123 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:20.713345 - k: tensor([[[-0.5107, -0.4566,  0.7284, -0.0100],
         [ 0.3332, -0.8862, -0.3219,  0.0062],
         [ 0.7925,  0.0784,  0.6048,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.714797 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.715863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0205],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:20.716515 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.717132 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:20.717738 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.0727]
0:04:20.265747 - bracket_assembly_nut_noaug_coarse--917955
0:04:20.265963 - {'grad_norm': 1.0692908763885498, 'grad_norm_std': inf, 'learning_rate': 1.6458333333333334e-09, 'time_forward': 0.055423736572265625, 'time_backward': 0.0769186019897461, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269140.2973697, 'n_iterations': 78, 'n_datas': 624, 'train_loss_TCO-iter=1': 0.0727328360080719, 'train_loss_TCO': 0.0727328360080719, 'train_loss_total': 0.0727328360080719, 'train_grad_norm': 1.0692908763885498, 'epoch': 77}
0:04:20.266089 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:20.273555 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:20.807641 - iteration 0
0:04:21.030974 - vxvyvz tensor([[ 0.1042,  0.0825, -0.0681]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:21.032064 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.033045 - dR tensor([[[-0.5265, -0.4219,  0.7381],
         [ 0.3283, -0.9017, -0.2812],
         [ 0.7842,  0.0942,  0.6133]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:21.033872 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:21.037135 - k: tensor([[[-0.5265, -0.4219,  0.7381, -0.0100],
         [ 0.3283, -0.9017, -0.2812,  0.0062],
         [ 0.7842,  0.0942,  0.6133,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.038540 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.039572 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0204],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.040236 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.040859 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.041479 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0726]
0:04:20.601200 - bracket_assembly_nut_noaug_coarse--917955
0:04:20.601428 - {'grad_norm': 1.0526854991912842, 'grad_norm_std': inf, 'learning_rate': 1.6666666666666667e-09, 'time_forward': 0.0556340217590332, 'time_backward': 0.07679271697998047, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269140.6209757, 'n_iterations': 79, 'n_datas': 632, 'train_loss_TCO-iter=1': 0.07264833152294159, 'train_loss_TCO': 0.07264833152294159, 'train_loss_total': 0.07264833152294159, 'train_grad_norm': 1.0526854991912842, 'epoch': 78}
0:04:20.601552 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:20.608977 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.143087 - iteration 0
0:04:21.366273 - vxvyvz tensor([[ 0.0985,  0.0907, -0.0656]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:21.367345 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.368361 - dR tensor([[[-0.5114, -0.4746,  0.7164],
         [ 0.3615, -0.8751, -0.3217],
         [ 0.7796,  0.0944,  0.6191]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:21.369202 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:21.372460 - k: tensor([[[-0.5114, -0.4746,  0.7164, -0.0100],
         [ 0.3615, -0.8751, -0.3217,  0.0062],
         [ 0.7796,  0.0944,  0.6191,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.373857 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.374838 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0197],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.375486 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.376124 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.376731 - k: tensor([0.0706], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0724]
0:04:20.930449 - bracket_assembly_nut_noaug_coarse--917955
0:04:20.930664 - {'grad_norm': 1.0236982107162476, 'grad_norm_std': inf, 'learning_rate': 1.6875e-09, 'time_forward': 0.05550241470336914, 'time_backward': 0.0777444839477539, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269140.95722, 'n_iterations': 80, 'n_datas': 640, 'train_loss_TCO-iter=1': 0.07237415015697479, 'train_loss_TCO': 0.07237415015697479, 'train_loss_total': 0.07237415015697479, 'train_grad_norm': 1.0236982107162476, 'epoch': 79}
0:04:20.930786 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:20.938226 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.472364 - iteration 0
0:04:21.696080 - vxvyvz tensor([[ 0.1061,  0.0916, -0.0694]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:21.697084 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.698035 - dR tensor([[[-0.4927, -0.4263,  0.7586],
         [ 0.3265, -0.8987, -0.2929],
         [ 0.8066,  0.1033,  0.5819]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:21.698878 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:21.702181 - k: tensor([[[-0.4927, -0.4263,  0.7586, -0.0100],
         [ 0.3265, -0.8987, -0.2929,  0.0062],
         [ 0.8066,  0.1033,  0.5819,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.703645 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.704645 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0208],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:21.705275 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.705882 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:21.706486 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0729]
0:04:21.261930 - bracket_assembly_nut_noaug_coarse--917955
0:04:21.262146 - {'grad_norm': 1.0366417169570923, 'grad_norm_std': inf, 'learning_rate': 1.7083333333333333e-09, 'time_forward': 0.05594015121459961, 'time_backward': 0.07817506790161133, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269141.2874298, 'n_iterations': 81, 'n_datas': 648, 'train_loss_TCO-iter=1': 0.0729069709777832, 'train_loss_TCO': 0.0729069709777832, 'train_loss_total': 0.0729069709777832, 'train_grad_norm': 1.0366417169570923, 'epoch': 80}
0:04:21.262269 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:21.269799 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:21.803945 - iteration 0
0:04:22.027752 - vxvyvz tensor([[ 0.1011,  0.0896, -0.0742]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:22.028787 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.029749 - dR tensor([[[-0.5209, -0.4409,  0.7309],
         [ 0.3557, -0.8905, -0.2837],
         [ 0.7760,  0.1122,  0.6207]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:22.030588 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:22.034295 - k: tensor([[[-0.5209, -0.4409,  0.7309, -0.0100],
         [ 0.3557, -0.8905, -0.2837,  0.0062],
         [ 0.7760,  0.1122,  0.6207,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.035380 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.036326 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0223],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.036975 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.037583 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.038200 - k: tensor([0.0714], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0732]
0:04:21.594059 - bracket_assembly_nut_noaug_coarse--917955
0:04:21.594265 - {'grad_norm': 1.1297019720077515, 'grad_norm_std': inf, 'learning_rate': 1.7291666666666666e-09, 'time_forward': 0.056160926818847656, 'time_backward': 0.07911825180053711, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269141.6200504, 'n_iterations': 82, 'n_datas': 656, 'train_loss_TCO-iter=1': 0.07318887114524841, 'train_loss_TCO': 0.07318887114524841, 'train_loss_total': 0.07318887114524841, 'train_grad_norm': 1.1297019720077515, 'epoch': 81}
0:04:21.594455 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:21.601843 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.135913 - iteration 0
0:04:22.359324 - vxvyvz tensor([[ 0.1006,  0.0854, -0.0675]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:22.360362 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.361331 - dR tensor([[[-0.5203, -0.4182,  0.7446],
         [ 0.3436, -0.9007, -0.2658],
         [ 0.7818,  0.1175,  0.6123]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:22.362165 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:22.365409 - k: tensor([[[-0.5203, -0.4182,  0.7446, -0.0100],
         [ 0.3436, -0.9007, -0.2658,  0.0062],
         [ 0.7818,  0.1175,  0.6123,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.366835 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.367910 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.368552 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.369167 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.369774 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0726]
0:04:21.925219 - bracket_assembly_nut_noaug_coarse--917955
0:04:21.925444 - {'grad_norm': 1.0305832624435425, 'grad_norm_std': inf, 'learning_rate': 1.75e-09, 'time_forward': 0.05563950538635254, 'time_backward': 0.07722783088684082, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269141.9496968, 'n_iterations': 83, 'n_datas': 664, 'train_loss_TCO-iter=1': 0.07257835566997528, 'train_loss_TCO': 0.07257835566997528, 'train_loss_total': 0.07257835566997528, 'train_grad_norm': 1.0305832624435425, 'epoch': 82}
0:04:21.925571 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:21.932985 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.467031 - iteration 0
0:04:22.690243 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0721]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:22.691309 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.692318 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8859, -0.3085],
         [ 0.7848,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:22.693161 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:22.696397 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8859, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.697308 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.698758 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:22.699423 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.700073 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:22.700706 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.073]
0:04:22.248536 - bracket_assembly_nut_noaug_coarse--917955
0:04:22.248759 - {'grad_norm': 1.1466037034988403, 'grad_norm_std': inf, 'learning_rate': 1.7708333333333335e-09, 'time_forward': 0.055370330810546875, 'time_backward': 0.07729768753051758, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269142.2808506, 'n_iterations': 84, 'n_datas': 672, 'train_loss_TCO-iter=1': 0.07303571701049805, 'train_loss_TCO': 0.07303571701049805, 'train_loss_total': 0.07303571701049805, 'train_grad_norm': 1.1466037034988403, 'epoch': 83}
0:04:22.248892 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:22.256599 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:22.790682 - iteration 0
0:04:23.013831 - vxvyvz tensor([[ 0.1034,  0.0880, -0.0687]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:23.014879 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.015885 - dR tensor([[[-0.5029, -0.4467,  0.7400],
         [ 0.3324, -0.8902, -0.3115],
         [ 0.7979,  0.0893,  0.5962]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:23.016775 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:23.020033 - k: tensor([[[-0.5029, -0.4467,  0.7400, -0.0100],
         [ 0.3324, -0.8902, -0.3115,  0.0062],
         [ 0.7979,  0.0893,  0.5962,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.020954 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.022370 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.022998 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.023646 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.024294 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0728]
0:04:22.577217 - bracket_assembly_nut_noaug_coarse--917955
0:04:22.577414 - {'grad_norm': 1.1045740842819214, 'grad_norm_std': inf, 'learning_rate': 1.7916666666666666e-09, 'time_forward': 0.055342674255371094, 'time_backward': 0.07746195793151855, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269142.6045372, 'n_iterations': 85, 'n_datas': 680, 'train_loss_TCO-iter=1': 0.07277816534042358, 'train_loss_TCO': 0.07277816534042358, 'train_loss_total': 0.07277816534042358, 'train_grad_norm': 1.1045740842819214, 'epoch': 84}
0:04:22.577604 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:22.584963 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.119042 - iteration 0
0:04:23.342309 - vxvyvz tensor([[ 0.0997,  0.0926, -0.0659]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:23.343398 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.344420 - dR tensor([[[-0.5196, -0.4586,  0.7209],
         [ 0.3237, -0.8865, -0.3307],
         [ 0.7907,  0.0615,  0.6091]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:23.345253 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:23.348479 - k: tensor([[[-0.5196, -0.4586,  0.7209, -0.0100],
         [ 0.3237, -0.8865, -0.3307,  0.0062],
         [ 0.7907,  0.0615,  0.6091,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.349384 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.350885 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0198],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.351544 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.352190 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.352819 - k: tensor([0.0706], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0725]
0:04:22.903125 - bracket_assembly_nut_noaug_coarse--917955
0:04:22.903317 - {'grad_norm': 1.0726016759872437, 'grad_norm_std': inf, 'learning_rate': 1.8125e-09, 'time_forward': 0.05554509162902832, 'time_backward': 0.07685208320617676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269142.932531, 'n_iterations': 86, 'n_datas': 688, 'train_loss_TCO-iter=1': 0.0724664255976677, 'train_loss_TCO': 0.0724664255976677, 'train_loss_total': 0.0724664255976677, 'train_grad_norm': 1.0726016759872437, 'epoch': 85}
0:04:22.903449 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:22.910880 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.444963 - iteration 0
0:04:23.668521 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0720]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:23.669549 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.670527 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8859, -0.3085],
         [ 0.7848,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:23.671394 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:23.674585 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8859, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.675532 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.677003 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:23.677710 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.678320 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:23.678940 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.073]
0:04:23.236272 - bracket_assembly_nut_noaug_coarse--917955
0:04:23.236506 - {'grad_norm': 1.1456586122512817, 'grad_norm_std': inf, 'learning_rate': 1.8333333333333332e-09, 'time_forward': 0.055713653564453125, 'time_backward': 0.0775446891784668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269143.259321, 'n_iterations': 87, 'n_datas': 696, 'train_loss_TCO-iter=1': 0.07299429923295975, 'train_loss_TCO': 0.07299429923295975, 'train_loss_total': 0.07299429923295975, 'train_grad_norm': 1.1456586122512817, 'epoch': 86}
0:04:23.236770 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:23.244369 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:23.778522 - iteration 0
0:04:24.001861 - vxvyvz tensor([[ 0.1004,  0.0855, -0.0647]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:24.002839 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.003847 - dR tensor([[[-0.5256, -0.4194,  0.7402],
         [ 0.3240, -0.9031, -0.2817],
         [ 0.7866,  0.0917,  0.6106]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:24.004712 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:24.007930 - k: tensor([[[-0.5256, -0.4194,  0.7402, -0.0100],
         [ 0.3240, -0.9031, -0.2817,  0.0062],
         [ 0.7866,  0.0917,  0.6106,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.009352 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.010364 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0194],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.010994 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.011643 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.012295 - k: tensor([0.0705], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0723]
0:04:23.564329 - bracket_assembly_nut_noaug_coarse--917955
0:04:23.564526 - {'grad_norm': 1.0592764616012573, 'grad_norm_std': inf, 'learning_rate': 1.854166666666667e-09, 'time_forward': 0.05563521385192871, 'time_backward': 0.0771017074584961, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269143.5922039, 'n_iterations': 88, 'n_datas': 704, 'train_loss_TCO-iter=1': 0.07232802361249924, 'train_loss_TCO': 0.07232802361249924, 'train_loss_total': 0.07232802361249924, 'train_grad_norm': 1.0592764616012573, 'epoch': 87}
0:04:23.564652 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:23.571907 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.106006 - iteration 0
0:04:24.329378 - vxvyvz tensor([[ 0.1020,  0.0923, -0.0734]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:24.330413 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.331497 - dR tensor([[[-0.5175, -0.4392,  0.7343],
         [ 0.3462, -0.8923, -0.2897],
         [ 0.7825,  0.1043,  0.6138]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:24.332379 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:24.335566 - k: tensor([[[-0.5175, -0.4392,  0.7343, -0.0100],
         [ 0.3462, -0.8923, -0.2897,  0.0062],
         [ 0.7825,  0.1043,  0.6138,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.336530 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.337430 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0220],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.338565 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.339327 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.339980 - k: tensor([0.0713], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0732]
0:04:23.890754 - bracket_assembly_nut_noaug_coarse--917955
0:04:23.890982 - {'grad_norm': 1.0716298818588257, 'grad_norm_std': inf, 'learning_rate': 1.8750000000000002e-09, 'time_forward': 0.05567598342895508, 'time_backward': 0.07686209678649902, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269143.919638, 'n_iterations': 89, 'n_datas': 712, 'train_loss_TCO-iter=1': 0.07316301763057709, 'train_loss_TCO': 0.07316301763057709, 'train_loss_total': 0.07316301763057709, 'train_grad_norm': 1.0716298818588257, 'epoch': 88}
0:04:23.891170 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:23.898625 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.432727 - iteration 0
0:04:24.656173 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0720]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:24.657202 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.658177 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8859, -0.3085],
         [ 0.7848,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:24.659007 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:24.662249 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8859, -0.3085,  0.0062],
         [ 0.7848,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.663694 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.664747 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.665378 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.665988 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.666608 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, loss=0.073]
0:04:24.215914 - bracket_assembly_nut_noaug_coarse--917955
0:04:24.216160 - {'grad_norm': 1.1464147567749023, 'grad_norm_std': inf, 'learning_rate': 1.8958333333333334e-09, 'time_forward': 0.05563068389892578, 'time_backward': 0.07652401924133301, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269144.245855, 'n_iterations': 90, 'n_datas': 720, 'train_loss_TCO-iter=1': 0.07303264737129211, 'train_loss_TCO': 0.07303264737129211, 'train_loss_total': 0.07303264737129211, 'train_grad_norm': 1.1464147567749023, 'epoch': 89}
0:04:24.216287 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:24.223567 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.757661 - iteration 0
0:04:24.981197 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0720]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:24.982257 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:24.983270 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8859, -0.3085],
         [ 0.7847,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:24.984144 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:24.987328 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8859, -0.3085,  0.0062],
         [ 0.7847,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.988274 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.989756 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:24.990379 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.990987 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:24.991630 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.073]
0:04:24.551729 - bracket_assembly_nut_noaug_coarse--917955
0:04:24.551955 - {'grad_norm': 1.1465647220611572, 'grad_norm_std': inf, 'learning_rate': 1.916666666666667e-09, 'time_forward': 0.05569601058959961, 'time_backward': 0.07665038108825684, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269144.572645, 'n_iterations': 91, 'n_datas': 728, 'train_loss_TCO-iter=1': 0.07303289324045181, 'train_loss_TCO': 0.07303289324045181, 'train_loss_total': 0.07303289324045181, 'train_grad_norm': 1.1465647220611572, 'epoch': 90}
0:04:24.552115 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:24.559564 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:25.093628 - iteration 0
0:04:25.316968 - vxvyvz tensor([[ 0.1012,  0.0896, -0.0742]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:25.318006 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:25.318961 - dR tensor([[[-0.5209, -0.4409,  0.7309],
         [ 0.3557, -0.8905, -0.2837],
         [ 0.7759,  0.1122,  0.6207]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:25.319820 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:25.322965 - k: tensor([[[-0.5209, -0.4409,  0.7309, -0.0100],
         [ 0.3557, -0.8905, -0.2837,  0.0062],
         [ 0.7759,  0.1122,  0.6207,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.323928 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.325450 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0223],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.326091 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.326708 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.327351 - k: tensor([0.0714], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, loss=0.0732]
0:04:24.886400 - bracket_assembly_nut_noaug_coarse--917955
0:04:24.886617 - {'grad_norm': 1.1299254894256592, 'grad_norm_std': inf, 'learning_rate': 1.9375e-09, 'time_forward': 0.05540299415588379, 'time_backward': 0.07651591300964355, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269144.9066145, 'n_iterations': 92, 'n_datas': 736, 'train_loss_TCO-iter=1': 0.07319816946983337, 'train_loss_TCO': 0.07319816946983337, 'train_loss_total': 0.07319816946983337, 'train_grad_norm': 1.1299254894256592, 'epoch': 91}
0:04:24.886743 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:24.894141 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:25.428261 - iteration 0
0:04:25.651676 - vxvyvz tensor([[ 0.1046,  0.0884, -0.0720]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:25.652708 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:25.653708 - dR tensor([[[-0.5140, -0.4543,  0.7276],
         [ 0.3463, -0.8859, -0.3085],
         [ 0.7847,  0.0934,  0.6127]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:25.654540 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:25.657763 - k: tensor([[[-0.5140, -0.4543,  0.7276, -0.0100],
         [ 0.3463, -0.8859, -0.3085,  0.0062],
         [ 0.7847,  0.0934,  0.6127,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.659200 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.660251 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.660884 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.661494 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.662107 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.36it/s, loss=0.073]
0:04:25.988276 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],s, loss=0.073]
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:25.988922 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.989543 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:25.990156 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0726]
0:04:25.563689 - bracket_assembly_nut_noaug_coarse--917955
0:04:25.563882 - {'grad_norm': 1.0912160873413086, 'grad_norm_std': inf, 'learning_rate': 1.9791666666666666e-09, 'time_forward': 0.05569767951965332, 'time_backward': 0.07789349555969238, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269145.5708873, 'n_iterations': 94, 'n_datas': 752, 'train_loss_TCO-iter=1': 0.07260426133871078, 'train_loss_TCO': 0.07260426133871078, 'train_loss_total': 0.07260426133871078, 'train_grad_norm': 1.0912160873413086, 'epoch': 93}
0:04:25.564052 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:25.571636 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.105726 - iteration 0
0:04:26.328892 - vxvyvz tensor([[ 0.1094,  0.0880, -0.0723]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:26.329909 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.330998 - dR tensor([[[-0.5317, -0.4263,  0.7318],
         [ 0.3246, -0.9007, -0.2889],
         [ 0.7823,  0.0840,  0.6172]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:26.331890 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:26.335101 - k: tensor([[[-0.5317, -0.4263,  0.7318, -0.0100],
         [ 0.3246, -0.9007, -0.2889,  0.0062],
         [ 0.7823,  0.0840,  0.6172,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.336058 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.337457 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0217],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.338149 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:26.338750 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:26.339378 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.073]
0:04:25.892245 - bracket_assembly_nut_noaug_coarse--917955
0:04:25.892449 - {'grad_norm': 1.1120493412017822, 'grad_norm_std': inf, 'learning_rate': 2e-09, 'time_forward': 0.05533576011657715, 'time_backward': 0.07770061492919922, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269145.919813, 'n_iterations': 95, 'n_datas': 760, 'train_loss_TCO-iter=1': 0.0730350986123085, 'train_loss_TCO': 0.0730350986123085, 'train_loss_total': 0.0730350986123085, 'train_grad_norm': 1.1120493412017822, 'epoch': 94}
0:04:25.892576 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:25.900755 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.434813 - iteration 0
0:04:26.658605 - vxvyvz tensor([[ 0.0974,  0.0879, -0.0687]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:26.659627 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.660631 - dR tensor([[[-0.5258, -0.4401,  0.7279],
         [ 0.3464, -0.8924, -0.2893],
         [ 0.7769,  0.1001,  0.6216]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:26.661471 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:26.664731 - k: tensor([[[-0.5258, -0.4401,  0.7279, -0.0100],
         [ 0.3464, -0.8924, -0.2893,  0.0062],
         [ 0.7769,  0.1001,  0.6216,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.666157 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.667215 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:26.667891 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:26.668527 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:26.669142 - k: tensor([0.0709], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0727]
0:04:26.227699 - bracket_assembly_nut_noaug_coarse--917955
0:04:26.227931 - {'grad_norm': 1.0014245510101318, 'grad_norm_std': inf, 'learning_rate': 2.0208333333333332e-09, 'time_forward': 0.05602836608886719, 'time_backward': 0.07933974266052246, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269146.2512362, 'n_iterations': 96, 'n_datas': 768, 'train_loss_TCO-iter=1': 0.07266832143068314, 'train_loss_TCO': 0.07266832143068314, 'train_loss_total': 0.07266832143068314, 'train_grad_norm': 1.0014245510101318, 'epoch': 95}
0:04:26.228160 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:26.235615 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.769736 - iteration 0
0:04:26.993800 - vxvyvz tensor([[ 0.1038,  0.0863, -0.0708]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:26.994821 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:26.995844 - dR tensor([[[-0.5098, -0.4454,  0.7361],
         [ 0.3215, -0.8922, -0.3172],
         [ 0.7980,  0.0750,  0.5980]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:26.996717 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:26.999972 - k: tensor([[[-0.5098, -0.4454,  0.7361, -0.0100],
         [ 0.3215, -0.8922, -0.3172,  0.0062],
         [ 0.7980,  0.0750,  0.5980,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.001668 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.002663 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0212],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.003326 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:04:27.003989 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:27.004616 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.073]
0:04:26.566975 - bracket_assembly_nut_noaug_coarse--917955
0:04:26.567201 - {'grad_norm': 1.0830905437469482, 'grad_norm_std': inf, 'learning_rate': 2.0416666666666668e-09, 'time_forward': 0.05667853355407715, 'time_backward': 0.07801556587219238, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683269146.5853753, 'n_iterations': 97, 'n_datas': 776, 'train_loss_TCO-iter=1': 0.07298047840595245, 'train_loss_TCO': 0.07298047840595245, 'train_loss_total': 0.07298047840595245, 'train_grad_norm': 1.0830905437469482, 'epoch': 96}
0:04:26.567330 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:04:26.574800 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:27.108930 - iteration 0
0:04:27.332619 - vxvyvz tensor([[ 0.1045,  0.0876, -0.0709]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:04:27.333648 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:04:27.334610 - dR tensor([[[-0.5219, -0.4163,  0.7445],
         [ 0.3275, -0.9037, -0.2757],
         [ 0.7876,  0.0999,  0.6080]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:04:27.335482 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:04:27.338703 - k: tensor([[[-0.5219, -0.4163,  0.7445, -0.0100],
         [ 0.3275, -0.9037, -0.2757,  0.0062],
         [ 0.7876,  0.0999,  0.6080,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.339650 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.340582 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0213],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:04:27.341691 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:04:27.342423 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:04:27.343042 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                         | 0/1 [00:00<?, ?it/s, loss=0.073]
0:04:25.988276 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],s, loss=0.073]
0:04:25.988276 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],s, loss=0.073]