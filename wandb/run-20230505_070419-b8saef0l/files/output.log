  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:11.837840 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:12.364778 - iteration 0
0:00:14.020134 - vxvyvz tensor([[-0.0601,  0.0340, -0.0826]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:14.021264 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.022239 - dR tensor([[[-0.5740,  0.2634, -0.7754],
         [-0.3955, -0.9183, -0.0192],
         [-0.7170,  0.2956,  0.6312]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:14.023086 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:14.026783 - k: tensor([[[-0.5740,  0.2634, -0.7754, -0.0100],
         [-0.3955, -0.9183, -0.0192,  0.0062],
         [-0.7170,  0.2956,  0.6312,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.027646 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.028632 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0248],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:14.029262 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.029869 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:14.030468 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:03<00:00,  3.52s/it, loss=0.0772]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.322787 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:14.851163 - iteration 0
0:00:15.149195 - vxvyvz tensor([[-0.0249,  0.0247,  0.0123]], device='cuda:0')
0:00:15.150248 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.151221 - dR tensor([[[-0.4600, -0.7274, -0.5092],
         [-0.4680,  0.6860, -0.5571],
         [ 0.7545, -0.0180, -0.6560]]], device='cuda:0')
0:00:15.152075 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.155295 - k: tensor([[[-0.4600, -0.7274, -0.5092, -0.0100],
         [-0.4680,  0.6860, -0.5571,  0.0062],
         [ 0.7545, -0.0180, -0.6560,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.156182 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.157191 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0037],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.157829 - k: tensor([0.0034], device='cuda:0')
0:00:15.158424 - k: tensor([0.0003], device='cuda:0')
0:00:15.159030 - k: tensor([0.0628], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.00it/s]
0:00:14.561213 - bracket_assembly_nut_noaug_coarse--206204
0:00:14.561418 - {'grad_norm': 1.087014079093933, 'grad_norm_std': inf, 'learning_rate': 5.0000000000000004e-08, 'time_forward': 2.2281157970428467, 'time_backward': 0.6236915588378906, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270269.142995, 'n_iterations': 1, 'n_datas': 8, 'train_loss_TCO-iter=1': 0.07716220617294312, 'train_loss_TCO': 0.07716220617294312, 'train_[loss_total': 0.07716220617294312, 'train_loss_total': 0.07716220617294312, 'train_grad_norm': 1.087014079093933, 'val_loss_TCO-iter=1': 0.06647974252700806, 'val_loss_TCO': 0.06647974252700806, 'val_[loss_total': 0.06647974252700806, 'val_loss_total': 0.06647974252700806, 'epoch': 0}
0:00:14.561546 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:14.569486 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.092933 - iteration 0
0:00:15.401615 - vxvyvz tensor([[-0.0633,  0.0310, -0.0864]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.402700 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.403684 - dR tensor([[[-0.5976,  0.2886, -0.7480],
         [-0.3884, -0.9204, -0.0448],
         [-0.7014,  0.2638,  0.6622]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.404588 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.407593 - k: tensor([[[-0.5976,  0.2886, -0.7480, -0.0100],
         [-0.3884, -0.9204, -0.0448,  0.0062],
         [-0.7014,  0.2638,  0.6622,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.408528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.409433 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0259],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.410058 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.410657 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.411265 - k: tensor([0.0726], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, loss=0.0775]
0:00:14.965017 - bracket_assembly_nut_noaug_coarse--206204
0:00:14.965248 - {'grad_norm': 0.9903366565704346, 'grad_norm_std': inf, 'learning_rate': 7.500000000000001e-08, 'time_forward': 0.14077091217041016, 'time_backward': 0.0785524845123291, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270269.4727054, 'n_iterations': 2, 'n_datas': 16, 'train_loss_TCO-iter=1': 0.07746572047472, 'train_loss_TCO': 0.07746572047472, 'train_[loss_total': 0.07746572047472, 'train_loss_total': 0.07746572047472, 'train_grad_norm': 0.9903366565704346, 'epoch': 1}
0:00:14.965365 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.055999 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.581548 - iteration 0
0:00:15.880510 - vxvyvz tensor([[-0.0580,  0.0322, -0.0821]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:15.881561 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:15.882525 - dR tensor([[[-0.5799,  0.2726, -0.7678],
         [-0.3617, -0.9305, -0.0572],
         [-0.7300,  0.2445,  0.6382]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:15.883343 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:15.886502 - k: tensor([[[-0.5799,  0.2726, -0.7678, -0.0100],
         [-0.3617, -0.9305, -0.0572,  0.0062],
         [-0.7300,  0.2445,  0.6382,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.887439 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.888353 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0246],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:15.889012 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.889648 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:15.890255 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.36it/s, loss=0.0772]
0:00:15.456944 - bracket_assembly_nut_noaug_coarse--206204
0:00:15.457170 - {'grad_norm': 1.0729767084121704, 'grad_norm_std': inf, 'learning_rate': 1.0000000000000001e-07, 'time_forward': 0.13333892822265625, 'time_backward': 0.07729721069335938, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270269.9502652, 'n_iterations': 3, 'n_datas': 24, 'train_loss_TCO-iter=1': 0.07718610018491745, 'train_loss_TCO': 0.07718610018491745, 'train_[loss_total': 0.07718610018491745, 'train_loss_total': 0.07718610018491745, 'train_grad_norm': 1.0729767084121704, 'epoch': 2}
0:00:15.457402 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:15.543500 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.069033 - iteration 0
0:00:16.367073 - vxvyvz tensor([[-0.0590,  0.0414, -0.0836]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.368120 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.369154 - dR tensor([[[-0.5765,  0.2740, -0.7698],
         [-0.3913, -0.9196, -0.0343],
         [-0.7173,  0.2814,  0.6373]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.369997 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.372988 - k: tensor([[[-0.5765,  0.2740, -0.7698, -0.0100],
         [-0.3913, -0.9196, -0.0343,  0.0062],
         [-0.7173,  0.2814,  0.6373,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.373877 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.374738 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0251],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.375349 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.375946 - k: tensor([0.0004], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.376601 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.44it/s, loss=0.0773]
0:00:15.931145 - bracket_assembly_nut_noaug_coarse--206204
0:00:15.931388 - {'grad_norm': 1.243777871131897, 'grad_norm_std': inf, 'learning_rate': 1.2500000000000002e-07, 'time_forward': 0.13209819793701172, 'time_backward': 0.07655572891235352, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270270.4359467, 'n_iterations': 4, 'n_datas': 32, 'train_loss_TCO-iter=1': 0.07725337147712708, 'train_loss_TCO': 0.07725337147712708, 'train_[loss_total': 0.07725337147712708, 'train_loss_total': 0.07725337147712708, 'train_grad_norm': 1.243777871131897, 'epoch': 3}
0:00:15.931504 - None
0:00:17.853030 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],<?, ?it/s]0:00:16.042054 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.567607 - iteration 0
0:00:16.866742 - vxvyvz tensor([[-0.0559,  0.0326, -0.0848]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:16.867803 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:16.868838 - dR tensor([[[-0.5881,  0.2577, -0.7666],
         [-0.3598, -0.9323, -0.0373],
         [-0.7244,  0.2539,  0.6410]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:16.869700 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:16.872816 - k: tensor([[[-0.5881,  0.2577, -0.7666, -0.0100],
         [-0.3598, -0.9323, -0.0373,  0.0062],
         [-0.7244,  0.2539,  0.6410,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.873721 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.874624 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0255],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:16.875242 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.875851 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:16.876503 - k: tensor([0.0725], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.16it/s, loss=0.0774]
0:00:16.429118 - bracket_assembly_nut_noaug_coarse--206204
0:00:16.429352 - {'grad_norm': 0.9740713834762573, 'grad_norm_std': inf, 'learning_rate': 1.5000000000000002e-07, 'time_forward': 0.13356661796569824, 'time_backward': 0.07620477676391602, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270270.9354987, 'n_iterations': 5, 'n_datas': 40, 'train_loss_TCO-iter=1': 0.07742352783679962, 'train_loss_TCO': 0.07742352783679962, 'train_[loss_total': 0.07742352783679962, 'train_loss_total': 0.07742352783679962, 'train_grad_norm': 0.9740713834762573, 'epoch': 4}
0:00:16.429473 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:16.527810 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.053325 - iteration 0
0:00:17.353529 - vxvyvz tensor([[-0.0600,  0.0337, -0.0814]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:17.354621 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.355606 - dR tensor([[[-0.5746,  0.2655, -0.7742],
         [-0.3964, -0.9178, -0.0205],
         [-0.7160,  0.2951,  0.6326]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:17.356514 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:17.359653 - k: tensor([[[-0.5746,  0.2655, -0.7742, -0.0100],
         [-0.3964, -0.9178, -0.0205,  0.0062],
         [-0.7160,  0.2951,  0.6326,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.360611 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.361528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0244],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.362146 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.362747 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.363346 - k: tensor([0.0721], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.28it/s, loss=0.0771]
0:00:16.911624 - bracket_assembly_nut_noaug_coarse--206204
0:00:16.911862 - {'grad_norm': 1.0866936445236206, 'grad_norm_std': inf, 'learning_rate': 1.7500000000000002e-07, 'time_forward': 0.13454627990722656, 'time_backward': 0.07605481147766113, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270271.4220982, 'n_iterations': 6, 'n_datas': 48, 'train_loss_TCO-iter=1': 0.07708068937063217, 'train_loss_TCO': 0.07708068937063217, 'train_[loss_total': 0.07708068937063217, 'train_loss_total': 0.07708068937063217, 'train_grad_norm': 1.0866936445236206, 'epoch': 5}
0:00:16.912021 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:17.028424 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.553946 - iteration 0
0:00:17.851866 - vxvyvz tensor([[-0.0679,  0.0303, -0.0887]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:17.853030 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],<?, ?it/s]0:00:16.042054 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:17.854028 - dR tensor([[[-0.5650,  0.2856, -0.7741],
         [-0.4187, -0.9077, -0.0293],
         [-0.7110,  0.3075,  0.6324]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:17.854910 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:17.858146 - k: tensor([[[-0.5650,  0.2856, -0.7741, -0.0100],
         [-0.4187, -0.9077, -0.0293,  0.0062],
         [-0.7110,  0.3075,  0.6324,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.859041 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.859937 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0266],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:17.860612 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.861229 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:17.861850 - k: tensor([0.0729], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.10it/s, loss=0.0778]
0:00:17.414140 - bracket_assembly_nut_noaug_coarse--206204
0:00:17.414382 - {'grad_norm': 1.0107815265655518, 'grad_norm_std': inf, 'learning_rate': 2.0000000000000002e-07, 'time_forward': 0.13251829147338867, 'time_backward': 0.07745027542114258, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270271.9219687, 'n_iterations': 7, 'n_datas': 56, 'train_loss_TCO-iter=1': 0.07776150852441788, 'train_loss_TCO': 0.07776150852441788, 'train_[loss_total': 0.07776150852441788, 'train_loss_total': 0.07776150852441788, 'train_grad_norm': 1.0107815265655518, 'epoch': 6}
0:00:17.414559 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:17.510309 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.035838 - iteration 0
0:00:18.323994 - vxvyvz tensor([[-0.0558,  0.0284, -0.0832]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:18.325094 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.326087 - dR tensor([[[-0.5657,  0.3012, -0.7677],
         [-0.4107, -0.9102, -0.0545],
         [-0.7151,  0.2845,  0.6385]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:18.326931 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:18.330199 - k: tensor([[[-0.5657,  0.3012, -0.7677, -0.0100],
         [-0.4107, -0.9102, -0.0545,  0.0062],
         [-0.7151,  0.2845,  0.6385,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.331116 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.332006 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0250],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.332681 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.333300 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.333920 - k: tensor([0.0723], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  3.41it/s, loss=0.0772]
0:00:17.885399 - bracket_assembly_nut_noaug_coarse--206204
0:00:17.885615 - {'grad_norm': 1.0733907222747803, 'grad_norm_std': inf, 'learning_rate': 2.2500000000000002e-07, 'time_forward': 0.12271642684936523, 'time_backward': 0.07844972610473633, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270272.3950589, 'n_iterations': 8, 'n_datas': 64, 'train_loss_TCO-iter=1': 0.07717516273260117, 'train_loss_TCO': 0.07717516273260117, 'train_[loss_total': 0.07717516273260117, 'train_loss_total': 0.07717516273260117, 'train_grad_norm': 1.0733907222747803, 'epoch': 7}
0:00:17.885731 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:17.893396 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.418710 - iteration 0
0:00:18.706462 - vxvyvz tensor([[-0.0668,  0.0251, -0.0841]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:18.707535 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.708581 - dR tensor([[[-0.5821,  0.2434, -0.7759],
         [-0.3501, -0.9362, -0.0310],
         [-0.7339,  0.2535,  0.6301]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:18.709434 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:18.712623 - k: tensor([[[-0.5821,  0.2434, -0.7759, -0.0100],
         [-0.3501, -0.9362, -0.0310,  0.0062],
         [-0.7339,  0.2535,  0.6301,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.713546 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.714433 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0252],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:18.715042 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.715664 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:18.716309 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
       grad_fn=<CopySlices>)█████████| 1/1 [00:00<00:00,  4.94it/s, loss=0.0773]
0:00:18.277454 - bracket_assembly_nut_noaug_coarse--206204
0:00:18.277662 - {'grad_norm': 1.1382508277893066, 'grad_norm_std': inf, 'learning_rate': 2.5000000000000004e-07, 'time_forward': 0.12203669548034668, 'time_backward': 0.07664179801940918, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270272.775486, 'n_iterations': 9, 'n_datas': 72, 'train_loss_TCO-iter=1': 0.07734448462724686, 'train_loss_TCO': 0.07734448462724686, 'train_[loss_total': 0.07734448462724686, 'train_loss_total': 0.07734448462724686, 'train_grad_norm': 1.1382508277893066, 'epoch': 8}
0:00:18.277772 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:18.285338 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:18.810589 - iteration 0
0:00:19.101409 - vxvyvz tensor([[-0.0598,  0.0334, -0.0795]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:19.102457 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.103441 - dR tensor([[[-0.5758,  0.2694, -0.7719],
         [-0.3981, -0.9171, -0.0231],
         [-0.7141,  0.2939,  0.6353]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:19.104326 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:19.107509 - k: tensor([[[-0.5758,  0.2694, -0.7719, -0.0100],
         [-0.3981, -0.9171, -0.0231,  0.0062],
         [-0.7141,  0.2939,  0.6353,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.108466 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.109374 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0239],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.110013 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.110627 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.111228 - k: tensor([0.0719], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.89it/s, loss=0.0768]
0:00:18.702536 - bracket_assembly_nut_noaug_coarse--206204
0:00:18.702734 - {'grad_norm': 1.0857867002487183, 'grad_norm_std': inf, 'learning_rate': 2.75e-07, 'time_forward': 0.12499570846557617, 'time_backward': 0.07593369483947754, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270273.1696978, 'n_iterations': 10, 'n_datas': 80, 'train_loss_TCO-iter=1': 0.07683879137039185, 'train_loss_TCO': 0.07683879137039185, 'train_[loss_total': 0.07683879137039185, 'train_loss_total': 0.07683879137039185, 'train_grad_norm': 1.0857867002487183, 'epoch': 9}
0:00:18.702865 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:18.710298 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.235574 - iteration 0
0:00:19.525396 - vxvyvz tensor([[-0.0616,  0.0293, -0.0848]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:19.526464 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.527425 - dR tensor([[[-0.5620,  0.2708, -0.7816],
         [-0.3980, -0.9169, -0.0315],
         [-0.7251,  0.2933,  0.6230]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:19.528292 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:19.531508 - k: tensor([[[-0.5620,  0.2708, -0.7816, -0.0100],
         [-0.3980, -0.9169, -0.0315,  0.0062],
         [-0.7251,  0.2933,  0.6230,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.532478 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.533390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0255],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.534013 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.534615 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.535213 - k: tensor([0.0725], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.92it/s, loss=0.0774]
0:00:19.094498 - bracket_assembly_nut_noaug_coarse--206204
0:00:19.094701 - {'grad_norm': 1.0541257858276367, 'grad_norm_std': inf, 'learning_rate': 3.0000000000000004e-07, 'time_forward': 0.12394952774047852, 'time_backward': 0.07584214210510254, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270273.593603, 'n_iterations': 11, 'n_datas': 88, 'train_loss_TCO-iter=1': 0.07742390781641006, 'train_loss_TCO': 0.07742390781641006, 'train_[loss_total': 0.07742390781641006, 'train_loss_total': 0.07742390781641006, 'train_grad_norm': 1.0541257858276367, 'epoch': 10}
0:00:19.094816 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:19.102357 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.627575 - iteration 0
0:00:19.917716 - vxvyvz tensor([[-0.0602,  0.0281, -0.0850]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:19.918761 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:19.919746 - dR tensor([[[-0.5885,  0.2875, -0.7557],
         [-0.3728, -0.9258, -0.0619],
         [-0.7174,  0.2453,  0.6520]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:19.920648 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:19.923745 - k: tensor([[[-0.5885,  0.2875, -0.7557, -0.0100],
         [-0.3728, -0.9258, -0.0619,  0.0062],
         [-0.7174,  0.2453,  0.6520,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.924756 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.925675 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0255],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:19.926286 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.926889 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:19.927491 - k: tensor([0.0725], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.90it/s, loss=0.0774]
0:00:19.484805 - bracket_assembly_nut_noaug_coarse--206204
0:00:19.485025 - {'grad_norm': 1.0933071374893188, 'grad_norm_std': inf, 'learning_rate': 3.25e-07, 'time_forward': 0.12426233291625977, 'time_backward': 0.0762939453125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270273.9863214, 'n_iterations': 12, 'n_datas': 96, 'train_loss_TCO-iter=1': 0.07738073170185089, 'train_loss_TCO': 0.07738073170185089, 'train_[loss_total': 0.07738073170185089, 'train_loss_total': 0.07738073170185089, 'train_grad_norm': 1.0933071374893188, 'epoch': 11}
0:00:19.485140 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:19.492575 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.017733 - iteration 0
0:00:20.304980 - vxvyvz tensor([[-0.0541,  0.0336, -0.0842]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:20.306018 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.306986 - dR tensor([[[-0.5784,  0.2626, -0.7723],
         [-0.3705, -0.9280, -0.0380],
         [-0.7267,  0.2642,  0.6341]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:20.307831 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:20.311038 - k: tensor([[[-0.5784,  0.2626, -0.7723, -0.0100],
         [-0.3705, -0.9280, -0.0380,  0.0062],
         [-0.7267,  0.2642,  0.6341,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.311951 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.312894 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0253],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.313509 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.314108 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.314692 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.98it/s, loss=0.0773]
0:00:19.882888 - bracket_assembly_nut_noaug_coarse--206204
0:00:19.883094 - {'grad_norm': 1.1236863136291504, 'grad_norm_std': inf, 'learning_rate': 3.5000000000000004e-07, 'time_forward': 0.12106704711914062, 'time_backward': 0.07592892646789551, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270274.373123, 'n_iterations': 13, 'n_datas': 104, 'train_loss_TCO-iter=1': 0.07734455168247223, 'train_loss_TCO': 0.07734455168247223, 'train_[loss_total': 0.07734455168247223, 'train_loss_total': 0.07734455168247223, 'train_grad_norm': 1.1236863136291504, 'epoch': 12}
0:00:19.883199 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:19.890528 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.415733 - iteration 0
0:00:20.703899 - vxvyvz tensor([[-0.0581,  0.0322, -0.0814]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:20.705019 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.706020 - dR tensor([[[-0.5585,  0.2568, -0.7888],
         [-0.3683, -0.9288, -0.0416],
         [-0.7433,  0.2673,  0.6133]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:20.706862 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:20.710108 - k: tensor([[[-0.5585,  0.2568, -0.7888, -0.0100],
         [-0.3683, -0.9288, -0.0416,  0.0062],
         [-0.7433,  0.2673,  0.6133,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.711025 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:20.711914 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0244],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)█████████| 1/1 [00:00<00:00,  4.94it/s, loss=0.0773]
0:00:20.712585 - k: tensor([0.0047], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.713205 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:20.713848 - k: tensor([0.0721], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.94it/s, loss=0.0772]
0:00:20.270362 - bracket_assembly_nut_noaug_coarse--206204
0:00:20.270581 - {'grad_norm': 1.0603275299072266, 'grad_norm_std': inf, 'learning_rate': 3.75e-07, 'time_forward': 0.12230205535888672, 'time_backward': 0.0763545036315918, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270274.77274, 'n_iterations': 14, 'n_datas': 112, 'train_loss_TCO-iter=1': 0.07722567766904831, 'train_loss_TCO': 0.07722567766904831, 'train_[loss_total': 0.07722567766904831, 'train_loss_total': 0.07722567766904831, 'train_grad_norm': 1.0603275299072266, 'epoch': 13}
0:00:20.270693 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.278295 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:20.803566 - iteration 0
0:00:21.090893 - vxvyvz tensor([[-0.0628,  0.0277, -0.0855]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.091941 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.092984 - dR tensor([[[-0.5929,  0.3078, -0.7441],
         [-0.3691, -0.9252, -0.0885],
         [-0.7157,  0.2222,  0.6622]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.093838 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.097028 - k: tensor([[[-0.5929,  0.3078, -0.7441, -0.0100],
         [-0.3691, -0.9252, -0.0885,  0.0062],
         [-0.7157,  0.2222,  0.6622,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.097946 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.098862 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0257],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.099487 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.100088 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.100775 - k: tensor([0.0725], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  4.97it/s, loss=0.0774]
0:00:20.654778 - bracket_assembly_nut_noaug_coarse--206204
0:00:20.654996 - {'grad_norm': 1.0859531164169312, 'grad_norm_std': inf, 'learning_rate': 4.0000000000000003e-07, 'time_forward': 0.12157487869262695, 'time_backward': 0.07602334022521973, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270275.159403, 'n_iterations': 15, 'n_datas': 120, 'train_loss_TCO-iter=1': 0.07737434655427933, 'train_loss_TCO': 0.07737434655427933, 'train_[loss_total': 0.07737434655427933, 'train_loss_total': 0.07737434655427933, 'train_grad_norm': 1.0859531164169312, 'epoch': 14}
0:00:20.655176 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.662769 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.187971 - iteration 0
0:00:21.408842 - vxvyvz tensor([[-0.0574,  0.0296, -0.0837]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.409865 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.410843 - dR tensor([[[-0.5930,  0.2869, -0.7523],
         [-0.3914, -0.9193, -0.0421],
         [-0.7037,  0.2695,  0.6575]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.411679 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.414895 - k: tensor([[[-0.5930,  0.2869, -0.7523, -0.0100],
         [-0.3914, -0.9193, -0.0421,  0.0062],
         [-0.7037,  0.2695,  0.6575,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.415800 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.416750 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0251],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.417885 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.418604 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.419221 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.38it/s, loss=0.0771]
0:00:20.979100 - bracket_assembly_nut_noaug_coarse--206204
0:00:20.979314 - {'grad_norm': 1.115639328956604, 'grad_norm_std': inf, 'learning_rate': 4.2500000000000006e-07, 'time_forward': 0.055450439453125, 'time_backward': 0.07628822326660156, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270275.4781363, 'n_iterations': 16, 'n_datas': 128, 'train_loss_TCO-iter=1': 0.07713527977466583, 'train_loss_TCO': 0.07713527977466583, 'train_[loss_total': 0.07713527977466583, 'train_loss_total': 0.07713527977466583, 'train_grad_norm': 1.115639328956604, 'epoch': 15}
0:00:20.979495 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:20.987023 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.512251 - iteration 0
0:00:21.733232 - vxvyvz tensor([[-0.0541,  0.0310, -0.0915]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:21.734226 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.735225 - dR tensor([[[-0.5946,  0.2849, -0.7518],
         [-0.3929, -0.9188, -0.0374],
         [-0.7015,  0.2731,  0.6583]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:21.736084 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:21.739316 - k: tensor([[[-0.5946,  0.2849, -0.7518, -0.0100],
         [-0.3929, -0.9188, -0.0374,  0.0062],
         [-0.7015,  0.2731,  0.6583,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.740247 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.741210 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0274],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:21.742344 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.743075 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:21.743681 - k: tensor([0.0731], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.078]
0:00:21.304555 - bracket_assembly_nut_noaug_coarse--206204
0:00:21.304773 - {'grad_norm': 1.0711326599121094, 'grad_norm_std': inf, 'learning_rate': 4.5000000000000003e-07, 'time_forward': 0.055692434310913086, 'time_backward': 0.07830953598022461, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270275.8047614, 'n_iterations': 17, 'n_datas': 136, 'train_loss_TCO-iter=1': 0.07795917242765427, 'train_loss_TCO': 0.07795917242765427, 'train_[loss_total': 0.07795917242765427, 'train_loss_total': 0.07795917242765427, 'train_grad_norm': 1.0711326599121094, 'epoch': 16}
0:00:21.304888 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.312468 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:21.837666 - iteration 0
0:00:22.058680 - vxvyvz tensor([[-0.0559,  0.0273, -0.0889]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.059714 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.060718 - dR tensor([[[-0.5981,  0.2835, -0.7496],
         [-0.3728, -0.9264, -0.0529],
         [-0.7094,  0.2478,  0.6598]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.061583 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.064788 - k: tensor([[[-0.5981,  0.2835, -0.7496, -0.0100],
         [-0.3728, -0.9264, -0.0529,  0.0062],
         [-0.7094,  0.2478,  0.6598,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.065711 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.066679 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0267],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.067304 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.067966 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.069165 - k: tensor([0.0729], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0777]
0:00:21.635404 - bracket_assembly_nut_noaug_coarse--206204
0:00:21.635618 - {'grad_norm': 1.0363092422485352, 'grad_norm_std': inf, 'learning_rate': 4.7500000000000006e-07, 'time_forward': 0.055899858474731445, 'time_backward': 0.07783102989196777, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270276.1298451, 'n_iterations': 18, 'n_datas': 144, 'train_loss_TCO-iter=1': 0.07774136960506439, 'train_loss_TCO': 0.07774136960506439, 'train_[loss_total': 0.07774136960506439, 'train_loss_total': 0.07774136960506439, 'train_grad_norm': 1.0363092422485352, 'epoch': 17}
0:00:21.635788 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.643237 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.168441 - iteration 0
0:00:22.389296 - vxvyvz tensor([[-0.0613,  0.0293, -0.0900]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.390302 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.391292 - dR tensor([[[-0.5883,  0.2846, -0.7569],
         [-0.3836, -0.9222, -0.0485],
         [-0.7118,  0.2618,  0.6517]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.392161 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.395342 - k: tensor([[[-0.5883,  0.2846, -0.7569, -0.0100],
         [-0.3836, -0.9222, -0.0485,  0.0062],
         [-0.7118,  0.2618,  0.6517,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.396273 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.397218 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0270],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.397857 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.398659 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.399584 - k: tensor([0.0730], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0779]
0:00:21.957156 - bracket_assembly_nut_noaug_coarse--206204
0:00:21.957364 - {'grad_norm': 1.1283824443817139, 'grad_norm_std': inf, 'learning_rate': 5.000000000000001e-07, 'time_forward': 0.05548357963562012, 'time_backward': 0.07710504531860352, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270276.4596303, 'n_iterations': 19, 'n_datas': 152, 'train_loss_TCO-iter=1': 0.07792429625988007, 'train_loss_TCO': 0.07792429625988007, 'train_[loss_total': 0.07792429625988007, 'train_loss_total': 0.07792429625988007, 'train_grad_norm': 1.1283824443817139, 'epoch': 18}
0:00:21.957477 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:21.964907 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.490092 - iteration 0
0:00:22.710904 - vxvyvz tensor([[-0.0561,  0.0304, -0.0840]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:22.711907 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.712928 - dR tensor([[[-0.5926,  0.2964, -0.7490],
         [-0.3838, -0.9214, -0.0610],
         [-0.7082,  0.2513,  0.6598]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:22.713785 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:22.717044 - k: tensor([[[-0.5926,  0.2964, -0.7490, -0.0100],
         [-0.3838, -0.9214, -0.0610,  0.0062],
         [-0.7082,  0.2513,  0.6598,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.717973 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.719444 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0252],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:22.720061 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.720731 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:22.721349 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0771]
0:00:22.283478 - bracket_assembly_nut_noaug_coarse--206204
0:00:22.283701 - {'grad_norm': 1.0185925960540771, 'grad_norm_std': inf, 'learning_rate': 5.250000000000001e-07, 'time_forward': 0.05549263954162598, 'time_backward': 0.07758688926696777, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270276.7816212, 'n_iterations': 20, 'n_datas': 160, 'train_loss_TCO-iter=1': 0.07714720070362091, 'train_loss_TCO': 0.07714720070362091, 'train_[loss_total': 0.07714720070362091, 'train_loss_total': 0.07714720070362091, 'train_grad_norm': 1.0185925960540771, 'epoch': 19}
0:00:22.283815 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:22.291339 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:22.816553 - iteration 0
0:00:23.037580 - vxvyvz tensor([[-0.0590,  0.0314, -0.0723]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:23.038597 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.039550 - dR tensor([[[-0.5820,  0.2883, -0.7604],
         [-0.4059, -0.9132, -0.0355],
         [-0.7046,  0.2880,  0.6485]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:23.040410 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:23.043598 - k: tensor([[[-0.5820,  0.2883, -0.7604, -0.0100],
         [-0.4059, -0.9132, -0.0355,  0.0062],
         [-0.7046,  0.2880,  0.6485,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.044560 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.045484 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0217],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.046121 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.046728 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.047329 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.076]
0:00:22.608161 - bracket_assembly_nut_noaug_coarse--206204
0:00:22.608379 - {'grad_norm': 1.0795352458953857, 'grad_norm_std': inf, 'learning_rate': 5.5e-07, 'time_forward': 0.05551862716674805, 'time_backward': 0.0774080753326416, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270277.1079564, 'n_iterations': 21, 'n_datas': 168, 'train_loss_TCO-iter=1': 0.0760386511683464, 'train_loss_TCO': 0.0760386511683464, 'train_[loss_total': 0.0760386511683464, 'train_loss_total': 0.0760386511683464, 'train_grad_norm': 1.0795352458953857, 'epoch': 20}
0:00:22.608498 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:22.615861 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.141034 - iteration 0
0:00:23.362043 - vxvyvz tensor([[-0.0522,  0.0270, -0.0800]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:23.363070 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.364047 - dR tensor([[[-0.5983,  0.3104, -0.7387],
         [-0.3795, -0.9217, -0.0800],
         [-0.7058,  0.2325,  0.6692]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:23.364956 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:23.368165 - k: tensor([[[-0.5983,  0.3104, -0.7387, -0.0100],
         [-0.3795, -0.9217, -0.0800,  0.0062],
         [-0.7058,  0.2325,  0.6692,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.369136 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.370045 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0240],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.370658 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.371276 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.371903 - k: tensor([0.0720], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0768]
0:00:23.077507 - bracket_assembly_nut_noaug_coarse--206204
0:00:23.077751 - {'grad_norm': 0.9775468111038208, 'grad_norm_std': inf, 'learning_rate': 5.750000000000001e-07, 'time_forward': 0.055559635162353516, 'time_backward': 0.07752704620361328, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270277.4326425, 'n_iterations': 22, 'n_datas': 176, 'train_loss_TCO-iter=1': 0.07677525281906128, 'train_loss_TCO': 0.07677525281906128, 'train_[loss_total': 0.07677525281906128, 'train_loss_total': 0.07677525281906128, 'train_grad_norm': 0.9775468111038208, 'epoch': 21}
0:00:23.077940 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.085547 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.610786 - iteration 0
0:00:23.832396 - vxvyvz tensor([[-0.0588,  0.0309, -0.0704]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:23.833427 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.834393 - dR tensor([[[-0.5834,  0.2935, -0.7573],
         [-0.4082, -0.9121, -0.0390],
         [-0.7021,  0.2864,  0.6519]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:23.835227 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:23.838466 - k: tensor([[[-0.5834,  0.2935, -0.7573, -0.0100],
         [-0.4082, -0.9121, -0.0390,  0.0062],
         [-0.7021,  0.2864,  0.6519,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.839403 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.841116 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0211],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:23.841819 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.842428 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:23.843029 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0758]
0:00:23.409213 - bracket_assembly_nut_noaug_coarse--206204
0:00:23.409451 - {'grad_norm': 1.0765998363494873, 'grad_norm_std': inf, 'learning_rate': 6.000000000000001e-07, 'time_forward': 0.05658674240112305, 'time_backward': 0.07821464538574219, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270277.9038923, 'n_iterations': 23, 'n_datas': 184, 'train_loss_TCO-iter=1': 0.07582466304302216, 'train_loss_TCO': 0.07582466304302216, 'train_[loss_total': 0.07582466304302216, 'train_loss_total': 0.07582466304302216, 'train_grad_norm': 1.0765998363494873, 'epoch': 22}
0:00:23.409567 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.417174 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:23.942418 - iteration 0
0:00:24.163776 - vxvyvz tensor([[-0.0619,  0.0283, -0.0823]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.164840 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.165829 - dR tensor([[[-0.6076,  0.3110, -0.7308],
         [-0.3787, -0.9223, -0.0776],
         [-0.6981,  0.2296,  0.6782]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.166654 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.169940 - k: tensor([[[-0.6076,  0.3110, -0.7308, -0.0100],
         [-0.3787, -0.9223, -0.0776,  0.0062],
         [-0.6981,  0.2296,  0.6782,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.170838 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.172360 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0247],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.173015 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.173649 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.174251 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.077]
0:00:23.738482 - bracket_assembly_nut_noaug_coarse--206204
0:00:23.738698 - {'grad_norm': 1.105738878250122, 'grad_norm_std': inf, 'learning_rate': 6.25e-07, 'time_forward': 0.05615878105163574, 'time_backward': 0.07964658737182617, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270278.23645, 'n_iterations': 24, 'n_datas': 192, 'train_loss_TCO-iter=1': 0.07698948681354523, 'train_loss_TCO': 0.07698948681354523, 'train_[loss_total': 0.07698948681354523, 'train_loss_total': 0.07698948681354523, 'train_grad_norm': 1.105738878250122, 'epoch': 23}
0:00:23.738863 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:23.746412 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.271634 - iteration 0
0:00:24.493141 - vxvyvz tensor([[-0.0586,  0.0303, -0.0677]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.494162 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.495150 - dR tensor([[[-0.5851,  0.2996, -0.7536],
         [-0.4109, -0.9107, -0.0430],
         [-0.6992,  0.2845,  0.6559]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.495978 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.499204 - k: tensor([[[-0.5851,  0.2996, -0.7536, -0.0100],
         [-0.4109, -0.9107, -0.0430,  0.0062],
         [-0.6992,  0.2845,  0.6559,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.500113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.501689 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0203],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.502307 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.502909 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.503508 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0756]
0:00:24.060136 - bracket_assembly_nut_noaug_coarse--206204
0:00:24.060354 - {'grad_norm': 1.0747815370559692, 'grad_norm_std': inf, 'learning_rate': 6.5e-07, 'time_forward': 0.05622148513793945, 'time_backward': 0.07777047157287598, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270278.5639164, 'n_iterations': 25, 'n_datas': 200, 'train_loss_TCO-iter=1': 0.07559537142515182, 'train_loss_TCO': 0.07559537142515182, 'train_[loss_total': 0.07559537142515182, 'train_loss_total': 0.07559537142515182, 'train_grad_norm': 1.0747815370559692, 'epoch': 24}
0:00:24.060472 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.067834 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.592982 - iteration 0
0:00:24.813718 - vxvyvz tensor([[-0.0566,  0.0233, -0.0833]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:24.814711 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.815695 - dR tensor([[[-0.6085,  0.3093, -0.7308],
         [-0.4080, -0.9118, -0.0462],
         [-0.6806,  0.2700,  0.6810]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:24.816593 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:24.819771 - k: tensor([[[-0.6085,  0.3093, -0.7308, -0.0100],
         [-0.4080, -0.9118, -0.0462,  0.0062],
         [-0.6806,  0.2700,  0.6810,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.820739 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.821675 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0250],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:24.822325 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.823424 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:24.824142 - k: tensor([0.0723], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0771]
0:00:24.378860 - bracket_assembly_nut_noaug_coarse--206204
0:00:24.379079 - {'grad_norm': 0.9751315712928772, 'grad_norm_std': inf, 'learning_rate': 6.750000000000001e-07, 'time_forward': 0.05533027648925781, 'time_backward': 0.07817363739013672, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270278.8850627, 'n_iterations': 26, 'n_datas': 208, 'train_loss_TCO-iter=1': 0.07706929743289948, 'train_loss_TCO': 0.07706929743289948, 'train_[loss_total': 0.07706929743289948, 'train_loss_total': 0.07706929743289948, 'train_grad_norm': 0.9751315712928772, 'epoch': 25}
0:00:24.379192 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.386731 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:24.911976 - iteration 0
0:00:25.133068 - vxvyvz tensor([[-0.0561,  0.0300, -0.0755]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.134097 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.135069 - dR tensor([[[-0.5698,  0.2822, -0.7718],
         [-0.3785, -0.9238, -0.0584],
         [-0.7294,  0.2589,  0.6332]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.135893 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.139124 - k: tensor([[[-0.5698,  0.2822, -0.7718, -0.0100],
         [-0.3785, -0.9238, -0.0584,  0.0062],
         [-0.7294,  0.2589,  0.6332,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.140027 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.141505 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0226],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.142229 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.142837 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.143472 - k: tensor([0.0715], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0764]
0:00:24.701696 - bracket_assembly_nut_noaug_coarse--206204
0:00:24.701910 - {'grad_norm': 1.0664935111999512, 'grad_norm_std': inf, 'learning_rate': 7.000000000000001e-07, 'time_forward': 0.055733442306518555, 'time_backward': 0.07779645919799805, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270279.2038715, 'n_iterations': 27, 'n_datas': 216, 'train_loss_TCO-iter=1': 0.07641969621181488, 'train_loss_TCO': 0.07641969621181488, 'train_[loss_total': 0.07641969621181488, 'train_loss_total': 0.07641969621181488, 'train_grad_norm': 1.0664935111999512, 'epoch': 26}
0:00:24.702022 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:24.709422 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.234624 - iteration 0
0:00:25.455522 - vxvyvz tensor([[-0.0594,  0.0279, -0.0840]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.456597 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.457597 - dR tensor([[[-0.5957,  0.3033, -0.7438],
         [-0.3906, -0.9185, -0.0617],
         [-0.7019,  0.2537,  0.6656]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.458442 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.461698 - k: tensor([[[-0.5957,  0.3033, -0.7438, -0.0100],
         [-0.3906, -0.9185, -0.0617,  0.0062],
         [-0.7019,  0.2537,  0.6656,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.462635 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.464090 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0252],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.464835 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.465456 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.466072 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0772]
0:00:25.029115 - bracket_assembly_nut_noaug_coarse--206204
0:00:25.029328 - {'grad_norm': 1.1338798999786377, 'grad_norm_std': inf, 'learning_rate': 7.25e-07, 'time_forward': 0.055672645568847656, 'time_backward': 0.07828497886657715, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270279.526865, 'n_iterations': 28, 'n_datas': 224, 'train_loss_TCO-iter=1': 0.07717442512512207, 'train_loss_TCO': 0.07717442512512207, 'train_[loss_total': 0.07717442512512207, 'train_loss_total': 0.07717442512512207, 'train_grad_norm': 1.1338798999786377, 'epoch': 27}
0:00:25.029500 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.037007 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.562261 - iteration 0
0:00:25.783408 - vxvyvz tensor([[-0.0594,  0.0311, -0.0865]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:25.784509 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.785491 - dR tensor([[[-0.6094,  0.2904, -0.7377],
         [-0.3919, -0.9192, -0.0381],
         [-0.6892,  0.2659,  0.6740]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:25.786332 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:25.789560 - k: tensor([[[-0.6094,  0.2904, -0.7377, -0.0100],
         [-0.3919, -0.9192, -0.0381,  0.0062],
         [-0.6892,  0.2659,  0.6740,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.790460 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.791862 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0259],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:25.792643 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.793267 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:25.793887 - k: tensor([0.0726], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0774]
0:00:25.354219 - bracket_assembly_nut_noaug_coarse--206204
0:00:25.354445 - {'grad_norm': 1.0851850509643555, 'grad_norm_std': inf, 'learning_rate': 7.5e-07, 'time_forward': 0.05595040321350098, 'time_backward': 0.07818365097045898, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270279.8546746, 'n_iterations': 29, 'n_datas': 232, 'train_loss_TCO-iter=1': 0.07744146883487701, 'train_loss_TCO': 0.07744146883487701, 'train_[loss_total': 0.07744146883487701, 'train_loss_total': 0.07744146883487701, 'train_grad_norm': 1.0851850509643555, 'epoch': 28}
0:00:25.354554 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.361984 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:25.887176 - iteration 0
0:00:26.108672 - vxvyvz tensor([[-0.0591,  0.0249, -0.0824]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.109684 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.110667 - dR tensor([[[-0.5927,  0.3242, -0.7373],
         [-0.3896, -0.9166, -0.0898],
         [-0.7049,  0.2340,  0.6696]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.111525 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.114756 - k: tensor([[[-0.5927,  0.3242, -0.7373, -0.0100],
         [-0.3896, -0.9166, -0.0898,  0.0062],
         [-0.7049,  0.2340,  0.6696,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.115661 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.117247 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0247],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.117878 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.118482 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.119084 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0769]
0:00:25.673159 - bracket_assembly_nut_noaug_coarse--206204
0:00:25.673381 - {'grad_norm': 1.1063419580459595, 'grad_norm_std': inf, 'learning_rate': 7.750000000000001e-07, 'time_forward': 0.0561673641204834, 'time_backward': 0.0782783031463623, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270280.1799827, 'n_iterations': 30, 'n_datas': 240, 'train_loss_TCO-iter=1': 0.07692966610193253, 'train_loss_TCO': 0.07692966610193253, 'train_[loss_total': 0.07692966610193253, 'train_loss_total': 0.07692966610193253, 'train_grad_norm': 1.1063419580459595, 'epoch': 29}
0:00:25.673490 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:25.680959 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.206149 - iteration 0
0:00:26.426945 - vxvyvz tensor([[-0.0584,  0.0263, -0.0773]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.427970 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.428972 - dR tensor([[[-0.5742,  0.3107, -0.7575],
         [-0.4134, -0.9086, -0.0594],
         [-0.7067,  0.2790,  0.6501]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.429813 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.433005 - k: tensor([[[-0.5742,  0.3107, -0.7575, -0.0100],
         [-0.4134, -0.9086, -0.0594,  0.0062],
         [-0.7067,  0.2790,  0.6501,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.433932 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.435316 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0232],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.435972 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.436641 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.437263 - k: tensor([0.0717], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0766]
0:00:25.993537 - bracket_assembly_nut_noaug_coarse--206204
0:00:25.993746 - {'grad_norm': 1.04679536819458, 'grad_norm_std': inf, 'learning_rate': 8.000000000000001e-07, 'time_forward': 0.05534482002258301, 'time_backward': 0.07724356651306152, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270280.4986846, 'n_iterations': 31, 'n_datas': 248, 'train_loss_TCO-iter=1': 0.07658343762159348, 'train_loss_TCO': 0.07658343762159348, 'train_[loss_total': 0.07658343762159348, 'train_loss_total': 0.07658343762159348, 'train_grad_norm': 1.04679536819458, 'epoch': 30}
0:00:25.993924 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.001325 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.526459 - iteration 0
0:00:26.747272 - vxvyvz tensor([[-0.0561,  0.0278, -0.0862]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:26.748310 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.749326 - dR tensor([[[-0.5806,  0.2976, -0.7579],
         [-0.4052, -0.9129, -0.0481],
         [-0.7062,  0.2792,  0.6506]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:26.750167 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:26.753401 - k: tensor([[[-0.5806,  0.2976, -0.7579, -0.0100],
         [-0.4052, -0.9129, -0.0481,  0.0062],
         [-0.7062,  0.2792,  0.6506,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.754317 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.755884 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0259],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:26.756571 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.757191 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:26.757811 - k: tensor([0.0726], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0775]
0:00:26.321464 - bracket_assembly_nut_noaug_coarse--206204
0:00:26.321677 - {'grad_norm': 1.0128380060195923, 'grad_norm_std': inf, 'learning_rate': 8.250000000000001e-07, 'time_forward': 0.05553579330444336, 'time_backward': 0.0775306224822998, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270280.817828, 'n_iterations': 32, 'n_datas': 256, 'train_loss_TCO-iter=1': 0.0774545669555664, 'train_loss_TCO': 0.0774545669555664, 'train_[loss_total': 0.0774545669555664, 'train_loss_total': 0.0774545669555664, 'train_grad_norm': 1.0128380060195923, 'epoch': 31}
0:00:26.321853 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.329362 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:26.854552 - iteration 0
0:00:27.075804 - vxvyvz tensor([[-0.0537,  0.0270, -0.0826]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.076910 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.077893 - dR tensor([[[-0.5805,  0.3157, -0.7506],
         [-0.3939, -0.9156, -0.0804],
         [-0.7126,  0.2490,  0.6559]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.078729 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.081958 - k: tensor([[[-0.5805,  0.3157, -0.7506, -0.0100],
         [-0.3939, -0.9156, -0.0804,  0.0062],
         [-0.7126,  0.2490,  0.6559,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.082867 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.084477 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0248],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.085111 - k: tensor([0.0045], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.085730 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.086329 - k: tensor([0.0723], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0771]
0:00:26.645482 - bracket_assembly_nut_noaug_coarse--206204
0:00:26.645706 - {'grad_norm': 1.091442346572876, 'grad_norm_std': inf, 'learning_rate': 8.500000000000001e-07, 'time_forward': 0.0560612678527832, 'time_backward': 0.07722330093383789, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270281.1461136, 'n_iterations': 33, 'n_datas': 264, 'train_loss_TCO-iter=1': 0.07705215364694595, 'train_loss_TCO': 0.07705215364694595, 'train_[loss_total': 0.07705215364694595, 'train_loss_total': 0.07705215364694595, 'train_grad_norm': 1.091442346572876, 'epoch': 32}
0:00:26.645814 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.653311 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.178531 - iteration 0
0:00:27.400111 - vxvyvz tensor([[-0.0541,  0.0239, -0.0816]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.401190 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.402162 - dR tensor([[[-0.5730,  0.2961, -0.7642],
         [-0.3675, -0.9263, -0.0834],
         [-0.7326,  0.2331,  0.6396]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.402987 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.406196 - k: tensor([[[-0.5730,  0.2961, -0.7642, -0.0100],
         [-0.3675, -0.9263, -0.0834,  0.0062],
         [-0.7326,  0.2331,  0.6396,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.407097 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.408577 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0245],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.409258 - k: tensor([0.0046], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.409879 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.410481 - k: tensor([0.0721], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0771]
0:00:26.965762 - bracket_assembly_nut_noaug_coarse--206204
0:00:26.965977 - {'grad_norm': 1.1109424829483032, 'grad_norm_std': inf, 'learning_rate': 8.75e-07, 'time_forward': 0.05620384216308594, 'time_backward': 0.07680511474609375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270281.4698784, 'n_iterations': 34, 'n_datas': 272, 'train_loss_TCO-iter=1': 0.07706460356712341, 'train_loss_TCO': 0.07706460356712341, 'train_[loss_total': 0.07706460356712341, 'train_loss_total': 0.07706460356712341, 'train_grad_norm': 1.1109424829483032, 'epoch': 33}
0:00:26.966151 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:26.973644 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.498780 - iteration 0
0:00:27.719628 - vxvyvz tensor([[-0.0579,  0.0296, -0.0817]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:27.720715 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.721710 - dR tensor([[[-0.6156,  0.3090, -0.7249],
         [-0.3996, -0.9153, -0.0509],
         [-0.6792,  0.2583,  0.6869]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:27.722541 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:27.725763 - k: tensor([[[-0.6156,  0.3090, -0.7249, -0.0100],
         [-0.3996, -0.9153, -0.0509,  0.0062],
         [-0.6792,  0.2583,  0.6869,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.726667 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.728056 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0245],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:27.728827 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.729462 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:27.730062 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0769]
0:00:27.281324 - bracket_assembly_nut_noaug_coarse--206204
0:00:27.281543 - {'grad_norm': 1.086258053779602, 'grad_norm_std': inf, 'learning_rate': 9.000000000000001e-07, 'time_forward': 0.05546069145202637, 'time_backward': 0.07793283462524414, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270281.7906463, 'n_iterations': 35, 'n_datas': 280, 'train_loss_TCO-iter=1': 0.07685250043869019, 'train_loss_TCO': 0.07685250043869019, 'train_[loss_total': 0.07685250043869019, 'train_loss_total': 0.07685250043869019, 'train_grad_norm': 1.086258053779602, 'epoch': 34}
0:00:27.281658 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.289227 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:27.814424 - iteration 0
0:00:28.035354 - vxvyvz tensor([[-0.0538,  0.0243, -0.0798]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.036386 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.037378 - dR tensor([[[-0.6092,  0.3308, -0.7207],
         [-0.4296, -0.9016, -0.0506],
         [-0.6665,  0.2788,  0.6914]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.038229 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.041463 - k: tensor([[[-0.6092,  0.3308, -0.7207, -0.0100],
         [-0.4296, -0.9016, -0.0506,  0.0062],
         [-0.6665,  0.2788,  0.6914,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.042904 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.043910 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0239],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.044585 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.045205 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.045822 - k: tensor([0.0720], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0767]
0:00:27.596462 - bracket_assembly_nut_noaug_coarse--206204
0:00:27.596673 - {'grad_norm': 1.0360593795776367, 'grad_norm_std': inf, 'learning_rate': 9.25e-07, 'time_forward': 0.05568742752075195, 'time_backward': 0.07853555679321289, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270282.1070845, 'n_iterations': 36, 'n_datas': 288, 'train_loss_TCO-iter=1': 0.0766567811369896, 'train_loss_TCO': 0.0766567811369896, 'train_[loss_total': 0.0766567811369896, 'train_loss_total': 0.0766567811369896, 'train_grad_norm': 1.0360593795776367, 'epoch': 35}
0:00:27.596820 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.604342 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.129550 - iteration 0
0:00:28.351949 - vxvyvz tensor([[-0.0521,  0.0234, -0.0826]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.353074 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.354052 - dR tensor([[[-0.6072,  0.3309, -0.7224],
         [-0.4074, -0.9102, -0.0744],
         [-0.6821,  0.2491,  0.6875]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.354908 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.358207 - k: tensor([[[-0.6072,  0.3309, -0.7224, -0.0100],
         [-0.4074, -0.9102, -0.0744,  0.0062],
         [-0.6821,  0.2491,  0.6875,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.359123 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.360597 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0248],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.361305 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.361926 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.362527 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0769]
0:00:27.916490 - bracket_assembly_nut_noaug_coarse--206204
0:00:27.916687 - {'grad_norm': 0.9942905902862549, 'grad_norm_std': inf, 'learning_rate': 9.500000000000001e-07, 'time_forward': 0.05721902847290039, 'time_backward': 0.07791590690612793, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270282.423009, 'n_iterations': 37, 'n_datas': 296, 'train_loss_TCO-iter=1': 0.07690726220607758, 'train_loss_TCO': 0.07690726220607758, 'train_[loss_total': 0.07690726220607758, 'train_loss_total': 0.07690726220607758, 'train_grad_norm': 0.9942905902862549, 'epoch': 36}
0:00:27.916804 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:27.924083 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.449272 - iteration 0
0:00:28.669989 - vxvyvz tensor([[-0.0565,  0.0264, -0.0822]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.671004 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.671972 - dR tensor([[[-0.6030,  0.3319, -0.7254],
         [-0.3973, -0.9135, -0.0878],
         [-0.6918,  0.2353,  0.6827]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.672866 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.676033 - k: tensor([[[-0.6030,  0.3319, -0.7254, -0.0100],
         [-0.3973, -0.9135, -0.0878,  0.0062],
         [-0.6918,  0.2353,  0.6827,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.676995 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.678515 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0247],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.679130 - k: tensor([0.0044], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.679732 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.680367 - k: tensor([0.0722], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0769]
0:00:28.234304 - bracket_assembly_nut_noaug_coarse--206204
0:00:28.234526 - {'grad_norm': 1.0786340236663818, 'grad_norm_std': inf, 'learning_rate': 9.750000000000002e-07, 'time_forward': 0.055258750915527344, 'time_backward': 0.07726430892944336, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270282.7401795, 'n_iterations': 38, 'n_datas': 304, 'train_loss_TCO-iter=1': 0.0769357830286026, 'train_loss_TCO': 0.0769357830286026, 'train_[loss_total': 0.0769357830286026, 'train_loss_total': 0.0769357830286026, 'train_grad_norm': 1.0786340236663818, 'epoch': 37}
0:00:28.234644 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:28.242144 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.767366 - iteration 0
0:00:28.989081 - vxvyvz tensor([[-0.0589,  0.0247, -0.0845]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:28.990138 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:28.991129 - dR tensor([[[-0.5989,  0.3443, -0.7230],
         [-0.4103, -0.9073, -0.0922],
         [-0.6877,  0.2414,  0.6846]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:28.991959 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:28.995191 - k: tensor([[[-0.5989,  0.3443, -0.7230, -0.0100],
         [-0.4103, -0.9073, -0.0922,  0.0062],
         [-0.6877,  0.2414,  0.6846,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.996098 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.997574 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0254],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:28.998282 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.998891 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:28.999491 - k: tensor([0.0724], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0771]
0:00:28.551149 - bracket_assembly_nut_noaug_coarse--206204
0:00:28.551373 - {'grad_norm': 1.099412441253662, 'grad_norm_std': inf, 'learning_rate': 1.0000000000000002e-06, 'time_forward': 0.056473731994628906, 'time_backward': 0.07821154594421387, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270283.0603874, 'n_iterations': 39, 'n_datas': 312, 'train_loss_TCO-iter=1': 0.0770902931690216, 'train_loss_TCO': 0.0770902931690216, 'train_[loss_total': 0.0770902931690216, 'train_loss_total': 0.0770902931690216, 'train_grad_norm': 1.099412441253662, 'epoch': 38}
0:00:28.551482 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:28.559022 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.084258 - iteration 0
0:00:29.305173 - vxvyvz tensor([[-0.0536,  0.0255, -0.0830]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:29.306198 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.307187 - dR tensor([[[-0.6225,  0.3305, -0.7094],
         [-0.4085, -0.9104, -0.0656],
         [-0.6675,  0.2490,  0.7017]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:29.308014 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:29.311227 - k: tensor([[[-0.6225,  0.3305, -0.7094, -0.0100],
         [-0.4085, -0.9104, -0.0656,  0.0062],
         [-0.6675,  0.2490,  0.7017,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.312148 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.313718 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0249],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.314334 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.314938 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.315563 - k: tensor([0.0723], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0769]
0:00:28.871342 - bracket_assembly_nut_noaug_coarse--206204
0:00:28.871557 - {'grad_norm': 1.0384770631790161, 'grad_norm_std': inf, 'learning_rate': 1.025e-06, 'time_forward': 0.05550265312194824, 'time_backward': 0.07737207412719727, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270283.3755407, 'n_iterations': 40, 'n_datas': 320, 'train_loss_TCO-iter=1': 0.07692772895097733, 'train_loss_TCO': 0.07692772895097733, 'train_[loss_total': 0.07692772895097733, 'train_loss_total': 0.07692772895097733, 'train_grad_norm': 1.0384770631790161, 'epoch': 39}
0:00:28.871671 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:28.879206 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.404398 - iteration 0
0:00:29.625392 - vxvyvz tensor([[-0.0533,  0.0223, -0.0789]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:29.626433 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.627406 - dR tensor([[[-0.6136,  0.3529, -0.7064],
         [-0.3957, -0.9116, -0.1117],
         [-0.6833,  0.2110,  0.6990]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:29.628242 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:29.631449 - k: tensor([[[-0.6136,  0.3529, -0.7064, -0.0100],
         [-0.3957, -0.9116, -0.1117,  0.0062],
         [-0.6833,  0.2110,  0.6990,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.632390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.633905 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0237],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.634522 - k: tensor([0.0042], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.635121 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.635720 - k: tensor([0.0719], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0765]
0:00:29.189683 - bracket_assembly_nut_noaug_coarse--206204
0:00:29.189897 - {'grad_norm': 1.056366205215454, 'grad_norm_std': inf, 'learning_rate': 1.0500000000000001e-06, 'time_forward': 0.055558204650878906, 'time_backward': 0.07717490196228027, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270283.6956096, 'n_iterations': 41, 'n_datas': 328, 'train_loss_TCO-iter=1': 0.0764501765370369, 'train_loss_TCO': 0.0764501765370369, 'train_[loss_total': 0.0764501765370369, 'train_loss_total': 0.0764501765370369, 'train_grad_norm': 1.056366205215454, 'epoch': 40}
0:00:29.190022 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.197455 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.722651 - iteration 0
0:00:29.943525 - vxvyvz tensor([[-0.0514,  0.0243, -0.0705]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:29.944591 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:29.945562 - dR tensor([[[-0.6127,  0.3500, -0.7086],
         [-0.4148, -0.9056, -0.0886],
         [-0.6728,  0.2396,  0.7000]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:29.946400 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:29.949625 - k: tensor([[[-0.6127,  0.3500, -0.7086, -0.0100],
         [-0.4148, -0.9056, -0.0886,  0.0062],
         [-0.6728,  0.2396,  0.7000,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.950521 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.952001 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0212],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:29.952677 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.953295 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:29.953913 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0757]
0:00:29.506693 - bracket_assembly_nut_noaug_coarse--206204
0:00:29.506904 - {'grad_norm': 1.1088130474090576, 'grad_norm_std': inf, 'learning_rate': 1.075e-06, 'time_forward': 0.05550050735473633, 'time_backward': 0.077239990234375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270284.0138092, 'n_iterations': 42, 'n_datas': 336, 'train_loss_TCO-iter=1': 0.07567836344242096, 'train_loss_TCO': 0.07567836344242096, 'train_[loss_total': 0.07567836344242096, 'train_loss_total': 0.07567836344242096, 'train_grad_norm': 1.1088130474090576, 'epoch': 41}
0:00:29.507019 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.514465 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.039691 - iteration 0
0:00:30.260834 - vxvyvz tensor([[-0.0547,  0.0213, -0.0719]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.261835 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.262825 - dR tensor([[[-0.6126,  0.3607, -0.7033],
         [-0.3997, -0.9090, -0.1181],
         [-0.6819,  0.2088,  0.7010]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.263667 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.266854 - k: tensor([[[-0.6126,  0.3607, -0.7033, -0.0100],
         [-0.3997, -0.9090, -0.1181,  0.0062],
         [-0.6819,  0.2088,  0.7010,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.267751 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.269237 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.269952 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.270558 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.271158 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0758]
0:00:29.834376 - bracket_assembly_nut_noaug_coarse--206204
0:00:29.834595 - {'grad_norm': 1.085579514503479, 'grad_norm_std': inf, 'learning_rate': 1.1e-06, 'time_forward': 0.055707693099975586, 'time_backward': 0.07726764678955078, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270284.3310964, 'n_iterations': 43, 'n_datas': 344, 'train_loss_TCO-iter=1': 0.0758029893040657, 'train_loss_TCO': 0.0758029893040657, 'train_[loss_total': 0.0758029893040657, 'train_loss_total': 0.0758029893040657, 'train_grad_norm': 1.085579514503479, 'epoch': 42}
0:00:29.834759 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:29.842176 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.367359 - iteration 0
0:00:30.588363 - vxvyvz tensor([[-0.0554,  0.0213, -0.0720]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.589382 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.590352 - dR tensor([[[-0.6069,  0.3698, -0.7035],
         [-0.4096, -0.9041, -0.1219],
         [-0.6811,  0.2141,  0.7002]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.591179 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.594383 - k: tensor([[[-0.6069,  0.3698, -0.7035, -0.0100],
         [-0.4096, -0.9041, -0.1219,  0.0062],
         [-0.6811,  0.2141,  0.7002,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.595293 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.596179 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0216],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.596860 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.597987 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.598684 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0758]
0:00:30.154251 - bracket_assembly_nut_noaug_coarse--206204
0:00:30.154473 - {'grad_norm': 1.101326584815979, 'grad_norm_std': inf, 'learning_rate': 1.125e-06, 'time_forward': 0.05557894706726074, 'time_backward': 0.07689881324768066, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270284.6581876, 'n_iterations': 44, 'n_datas': 352, 'train_loss_TCO-iter=1': 0.07584653794765472, 'train_loss_TCO': 0.07584653794765472, 'train_[loss_total': 0.07584653794765472, 'train_loss_total': 0.07584653794765472, 'train_grad_norm': 1.101326584815979, 'epoch': 43}
0:00:30.154585 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:30.162104 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.687379 - iteration 0
0:00:30.908332 - vxvyvz tensor([[-0.0576,  0.0242, -0.0740]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:30.909374 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:30.910399 - dR tensor([[[-0.5987,  0.3501, -0.7204],
         [-0.4086, -0.9071, -0.1012],
         [-0.6889,  0.2338,  0.6861]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:30.911226 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:30.914440 - k: tensor([[[-0.5987,  0.3501, -0.7204, -0.0100],
         [-0.4086, -0.9071, -0.1012,  0.0062],
         [-0.6889,  0.2338,  0.6861,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.915551 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.916907 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0222],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:30.917546 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.918159 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:30.918760 - k: tensor([0.0714], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.076]
0:00:30.476275 - bracket_assembly_nut_noaug_coarse--206204
0:00:30.476476 - {'grad_norm': 1.0256397724151611, 'grad_norm_std': inf, 'learning_rate': 1.1500000000000002e-06, 'time_forward': 0.05572795867919922, 'time_backward': 0.0770115852355957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270284.9783382, 'n_iterations': 45, 'n_datas': 360, 'train_loss_TCO-iter=1': 0.07601754367351532, 'train_loss_TCO': 0.07601754367351532, 'train_[loss_total': 0.07601754367351532, 'train_loss_total': 0.07601754367351532, 'train_grad_norm': 1.0256397724151611, 'epoch': 44}
0:00:30.476592 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:30.483957 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.009166 - iteration 0
0:00:31.230096 - vxvyvz tensor([[-0.0501,  0.0148, -0.0771]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:31.231133 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.232133 - dR tensor([[[-0.6206,  0.3580, -0.6976],
         [-0.3888, -0.9131, -0.1226],
         [-0.6809,  0.1951,  0.7059]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:31.233030 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:31.236177 - k: tensor([[[-0.6206,  0.3580, -0.6976, -0.0100],
         [-0.3888, -0.9131, -0.1226,  0.0062],
         [-0.6809,  0.1951,  0.7059,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.237151 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.238592 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0231],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.239298 - k: tensor([0.0042], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.239905 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.240571 - k: tensor([0.0717], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0763]
0:00:30.799322 - bracket_assembly_nut_noaug_coarse--206204
0:00:30.799520 - {'grad_norm': 1.0203890800476074, 'grad_norm_std': inf, 'learning_rate': 1.175e-06, 'time_forward': 0.05558061599731445, 'time_backward': 0.07671713829040527, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270285.2999518, 'n_iterations': 46, 'n_datas': 368, 'train_loss_TCO-iter=1': 0.0762895941734314, 'train_loss_TCO': 0.0762895941734314, 'train_[loss_total': 0.0762895941734314, 'train_loss_total': 0.0762895941734314, 'train_grad_norm': 1.0203890800476074, 'epoch': 45}
0:00:30.799628 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:30.807016 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.332240 - iteration 0
0:00:31.553038 - vxvyvz tensor([[-0.0519,  0.0232, -0.0748]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:31.554023 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.554964 - dR tensor([[[-0.6300,  0.3114, -0.7115],
         [-0.3965, -0.9166, -0.0501],
         [-0.6678,  0.2506,  0.7009]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:31.555789 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:31.558997 - k: tensor([[[-0.6300,  0.3114, -0.7115, -0.0100],
         [-0.3965, -0.9166, -0.0501,  0.0062],
         [-0.6678,  0.2506,  0.7009,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.559893 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.560867 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0224],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.561500 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.562164 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.563230 - k: tensor([0.0715], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.37it/s, loss=0.0761]
0:00:31.113140 - bracket_assembly_nut_noaug_coarse--206204
0:00:31.113415 - {'grad_norm': 1.0949187278747559, 'grad_norm_std': inf, 'learning_rate': 1.2000000000000002e-06, 'time_forward': 0.055275678634643555, 'time_backward': 0.07670211791992188, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270285.6227744, 'n_iterations': 47, 'n_datas': 376, 'train_loss_TCO-iter=1': 0.07614138722419739, 'train_loss_TCO': 0.07614138722419739, 'train_[loss_total': 0.07614138722419739, 'train_loss_total': 0.07614138722419739, 'train_grad_norm': 1.0949187278747559, 'epoch': 46}
0:00:31.113528 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.121008 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.646232 - iteration 0
0:00:31.867045 - vxvyvz tensor([[-0.0630,  0.0235, -0.0764]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:31.868028 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.869048 - dR tensor([[[-0.6043,  0.3700, -0.7056],
         [-0.4174, -0.9014, -0.1152],
         [-0.6787,  0.2249,  0.6992]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:31.869900 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:31.873084 - k: tensor([[[-0.6043,  0.3700, -0.7056, -0.0100],
         [-0.4174, -0.9014, -0.1152,  0.0062],
         [-0.6787,  0.2249,  0.6992,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.874006 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.875801 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0229],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:31.876501 - k: tensor([0.0042], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.877122 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:31.877745 - k: tensor([0.0716], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0762]
0:00:31.433209 - bracket_assembly_nut_noaug_coarse--206204
0:00:31.433428 - {'grad_norm': 1.1405282020568848, 'grad_norm_std': inf, 'learning_rate': 1.2250000000000001e-06, 'time_forward': 0.05579829216003418, 'time_backward': 0.07678532600402832, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270285.937282, 'n_iterations': 48, 'n_datas': 384, 'train_loss_TCO-iter=1': 0.07620829343795776, 'train_loss_TCO': 0.07620829343795776, 'train_[loss_total': 0.07620829343795776, 'train_loss_total': 0.07620829343795776, 'train_grad_norm': 1.1405282020568848, 'epoch': 47}
0:00:31.433544 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.441085 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:31.966338 - iteration 0
0:00:32.187389 - vxvyvz tensor([[-0.0528,  0.0256, -0.0771]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.188464 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.189469 - dR tensor([[[-0.6013,  0.3730, -0.7066],
         [-0.4119, -0.9025, -0.1258],
         [-0.6846,  0.2155,  0.6963]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.190306 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.193512 - k: tensor([[[-0.6013,  0.3730, -0.7066, -0.0100],
         [-0.4119, -0.9025, -0.1258,  0.0062],
         [-0.6846,  0.2155,  0.6963,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.194896 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.195887 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0231],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.196548 - k: tensor([0.0043], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.197149 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.197751 - k: tensor([0.0717], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0763]
0:00:31.747120 - bracket_assembly_nut_noaug_coarse--206204
0:00:31.747350 - {'grad_norm': 1.0694565773010254, 'grad_norm_std': inf, 'learning_rate': 1.25e-06, 'time_forward': 0.05571317672729492, 'time_backward': 0.07724285125732422, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270286.2575426, 'n_iterations': 49, 'n_datas': 392, 'train_loss_TCO-iter=1': 0.07632044702768326, 'train_loss_TCO': 0.07632044702768326, 'train_[loss_total': 0.07632044702768326, 'train_loss_total': 0.07632044702768326, 'train_grad_norm': 1.0694565773010254, 'epoch': 48}
0:00:31.747460 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:31.755077 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.280265 - iteration 0
0:00:32.501246 - vxvyvz tensor([[-0.0529,  0.0213, -0.0705]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.502242 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.503200 - dR tensor([[[-0.6214,  0.4160, -0.6639],
         [-0.4288, -0.8898, -0.1561],
         [-0.6557,  0.1877,  0.7313]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.504076 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.507274 - k: tensor([[[-0.6214,  0.4160, -0.6639, -0.0100],
         [-0.4288, -0.8898, -0.1561,  0.0062],
         [-0.6557,  0.1877,  0.7313,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.508177 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.509725 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0212],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.510408 - k: tensor([0.0041], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.511013 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.511621 - k: tensor([0.0710], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0755]
0:00:32.070356 - bracket_assembly_nut_noaug_coarse--206204
0:00:32.070570 - {'grad_norm': 0.9806331396102905, 'grad_norm_std': inf, 'learning_rate': 1.275e-06, 'time_forward': 0.05562448501586914, 'time_backward': 0.07703900337219238, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270286.5713792, 'n_iterations': 50, 'n_datas': 400, 'train_loss_TCO-iter=1': 0.07545921951532364, 'train_loss_TCO': 0.07545921951532364, 'train_[loss_total': 0.07545921951532364, 'train_loss_total': 0.07545921951532364, 'train_grad_norm': 0.9806331396102905, 'epoch': 49}
0:00:32.070687 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.078223 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.603423 - iteration 0
0:00:32.824320 - vxvyvz tensor([[-0.0547,  0.0199, -0.0682]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:32.825348 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.826309 - dR tensor([[[-0.6172,  0.4136, -0.6693],
         [-0.4295, -0.8899, -0.1539],
         [-0.6593,  0.1925,  0.7268]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:32.827153 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.830399 - k: tensor([[[-0.6172,  0.4136, -0.6693, -0.0100],
         [-0.4295, -0.8899, -0.1539,  0.0062],
         [-0.6593,  0.1925,  0.7268,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.831293 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.832846 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0205],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:32.833500 - k: tensor([0.0040], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.834108 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:32.834708 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0752]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.214722 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.739782 - iteration 0
0:00:32.954226 - vxvyvz tensor([[-0.0098,  0.0193,  0.0113]], device='cuda:0')
0:00:32.955201 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.956113 - dR tensor([[[-0.5938, -0.7563,  0.2746],
         [-0.6123,  0.2034, -0.7640],
         [ 0.5219, -0.6218, -0.5839]]], device='cuda:0')
0:00:32.957002 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:32.959935 - k: tensor([[[-0.5938, -0.7563,  0.2746, -0.0100],
         [-0.6123,  0.2034, -0.7640,  0.0062],
         [ 0.5219, -0.6218, -0.5839,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.960892 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.961803 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0034],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.962408 - k: tensor([0.0049], device='cuda:0')
0:00:32.963016 - k: tensor([0.0003], device='cuda:0')
0:00:32.963613 - k: tensor([0.0629], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.79it/s]
0:00:32.440530 - bracket_assembly_nut_noaug_coarse--206204
0:00:32.440746 - {'grad_norm': 1.1056982278823853, 'grad_norm_std': inf, 'learning_rate': 1.3e-06, 'time_forward': 0.055503129959106445, 'time_backward': 0.07758831977844238, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270286.9451678, 'n_iterations': 51, 'n_datas': 408, 'train_loss_TCO-iter=1': 0.07519645243883133, 'train_loss_TCO': 0.07519645243883133, 'train_[loss_total': 0.07519645243883133, 'train_loss_total': 0.07519645243883133, 'train_grad_norm': 1.1056982278823853, 'val_loss_TCO-iter=1': 0.06808174401521683, 'val_loss_TCO': 0.06808174401521683, 'val_[loss_total': 0.06808174401521683, 'val_loss_total': 0.06808174401521683, 'epoch': 50}
0:00:32.440920 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.448380 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:32.970286 - iteration 0
0:00:33.190978 - vxvyvz tensor([[-0.0484,  0.0182, -0.0780]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:33.191960 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.192971 - dR tensor([[[-0.6250,  0.4069, -0.6662],
         [-0.4192, -0.8949, -0.1533],
         [-0.6585,  0.1834,  0.7299]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:33.193819 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:33.197014 - k: tensor([[[-0.6250,  0.4069, -0.6662, -0.0100],
         [-0.4192, -0.8949, -0.1533,  0.0062],
         [-0.6585,  0.1834,  0.7299,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.197934 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.198824 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0234],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.199436 - k: tensor([0.0041], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.200038 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.200702 - k: tensor([0.0718], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.56it/s, loss=0.0762]
0:00:32.753273 - bracket_assembly_nut_noaug_coarse--206204
0:00:32.753492 - {'grad_norm': 1.1731255054473877, 'grad_norm_std': inf, 'learning_rate': 1.3250000000000002e-06, 'time_forward': 0.051807403564453125, 'time_backward': 0.07656383514404297, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270287.2605886, 'n_iterations': 52, 'n_datas': 416, 'train_loss_TCO-iter=1': 0.07619672268629074, 'train_loss_TCO': 0.07619672268629074, 'train_[loss_total': 0.07619672268629074, 'train_loss_total': 0.07619672268629074, 'train_grad_norm': 1.1731255054473877, 'epoch': 51}
0:00:32.753618 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:32.761009 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.286216 - iteration 0
0:00:33.511143 - vxvyvz tensor([[-0.0499,  0.0220, -0.0624]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:33.512127 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.513158 - dR tensor([[[-0.6252,  0.3660, -0.6893],
         [-0.4248, -0.9005, -0.0928],
         [-0.6547,  0.2348,  0.7185]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:33.514011 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:33.517169 - k: tensor([[[-0.6252,  0.3660, -0.6893, -0.0100],
         [-0.4248, -0.9005, -0.0928,  0.0062],
         [-0.6547,  0.2348,  0.7185,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.518086 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.518979 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0187],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.519588 - k: tensor([0.0042], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.520756 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.521440 - k: tensor([0.0702], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0748]
0:00:33.075421 - bracket_assembly_nut_noaug_coarse--206204
0:00:33.075637 - {'grad_norm': 1.1334917545318604, 'grad_norm_std': inf, 'learning_rate': 1.3500000000000002e-06, 'time_forward': 0.05949544906616211, 'time_backward': 0.07616496086120605, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270287.5802913, 'n_iterations': 53, 'n_datas': 424, 'train_loss_TCO-iter=1': 0.07478772103786469, 'train_loss_TCO': 0.07478772103786469, 'train_[loss_total': 0.07478772103786469, 'train_loss_total': 0.07478772103786469, 'train_grad_norm': 1.1334917545318604, 'epoch': 52}
0:00:33.075750 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:33.083215 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.608395 - iteration 0
0:00:33.829511 - vxvyvz tensor([[-0.0476,  0.0175, -0.0751]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:33.830547 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.831501 - dR tensor([[[-0.6281,  0.4185, -0.6560],
         [-0.4239, -0.8910, -0.1626],
         [-0.6525,  0.1759,  0.7370]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:33.832370 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:33.835527 - k: tensor([[[-0.6281,  0.4185, -0.6560, -0.0100],
         [-0.4239, -0.8910, -0.1626,  0.0062],
         [-0.6525,  0.1759,  0.7370,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.836492 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.837980 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0225],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:33.838686 - k: tensor([0.0040], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.839291 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:33.839890 - k: tensor([0.0715], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, loss=0.0759]
0:00:33.389182 - bracket_assembly_nut_noaug_coarse--206204
0:00:33.389437 - {'grad_norm': 1.1762241125106812, 'grad_norm_std': inf, 'learning_rate': 1.3750000000000002e-06, 'time_forward': 0.05570697784423828, 'time_backward': 0.07567644119262695, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270287.8981917, 'n_iterations': 54, 'n_datas': 432, 'train_loss_TCO-iter=1': 0.07585225254297256, 'train_loss_TCO': 0.07585225254297256, 'train_[loss_total': 0.07585225254297256, 'train_loss_total': 0.07585225254297256, 'train_grad_norm': 1.1762241125106812, 'epoch': 53}
0:00:33.389553 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:33.397013 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:33.922221 - iteration 0
0:00:34.142970 - vxvyvz tensor([[-0.0512,  0.0188, -0.0373]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.143990 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.145000 - dR tensor([[[-0.6167,  0.4195, -0.6661],
         [-0.4580, -0.8794, -0.1299],
         [-0.6403,  0.2250,  0.7345]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.145845 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.149007 - k: tensor([[[-0.6167,  0.4195, -0.6661, -0.0100],
         [-0.4580, -0.8794, -0.1299,  0.0062],
         [-0.6403,  0.2250,  0.7345,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.150415 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.151419 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0112],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.152034 - k: tensor([0.0041], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.152699 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.153313 - k: tensor([0.0677], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, loss=0.0721]
0:00:33.705279 - bracket_assembly_nut_noaug_coarse--206204
0:00:33.705501 - {'grad_norm': 1.0376511812210083, 'grad_norm_std': inf, 'learning_rate': 1.4000000000000001e-06, 'time_forward': 0.05536842346191406, 'time_backward': 0.07597565650939941, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270288.2118764, 'n_iterations': 55, 'n_datas': 440, 'train_loss_TCO-iter=1': 0.07213536649942398, 'train_loss_TCO': 0.07213536649942398, 'train_[loss_total': 0.07213536649942398, 'train_loss_total': 0.07213536649942398, 'train_grad_norm': 1.0376511812210083, 'epoch': 54}
0:00:33.705616 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:33.713164 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.238331 - iteration 0
0:00:34.459140 - vxvyvz tensor([[-0.0493,  0.0198, -0.0726]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.460142 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.461156 - dR tensor([[[-0.6221,  0.3844, -0.6820],
         [-0.4208, -0.8988, -0.1227],
         [-0.6602,  0.2107,  0.7210]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.462000 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.465153 - k: tensor([[[-0.6221,  0.3844, -0.6820, -0.0100],
         [-0.4208, -0.8988, -0.1227,  0.0062],
         [-0.6602,  0.2107,  0.7210,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.466064 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.466952 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0218],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.467563 - k: tensor([0.0041], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.468760 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.469495 - k: tensor([0.0713], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, loss=0.0757]
0:00:34.015533 - bracket_assembly_nut_noaug_coarse--206204
0:00:34.015746 - {'grad_norm': 1.0321643352508545, 'grad_norm_std': inf, 'learning_rate': 1.425e-06, 'time_forward': 0.05536150932312012, 'time_backward': 0.0760650634765625, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270288.5281987, 'n_iterations': 56, 'n_datas': 448, 'train_loss_TCO-iter=1': 0.07572013884782791, 'train_loss_TCO': 0.07572013884782791, 'train_[loss_total': 0.07572013884782791, 'train_loss_total': 0.07572013884782791, 'train_grad_norm': 1.0321643352508545, 'epoch': 55}
0:00:34.015861 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:34.023240 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.548406 - iteration 0
0:00:34.769166 - vxvyvz tensor([[-0.0462,  0.0165, -0.0685]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:34.770230 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.771231 - dR tensor([[[-0.6334,  0.4389, -0.6373],
         [-0.4326, -0.8837, -0.1786],
         [-0.6416,  0.1625,  0.7496]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:34.772075 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:34.775319 - k: tensor([[[-0.6334,  0.4389, -0.6373, -0.0100],
         [-0.4326, -0.8837, -0.1786,  0.0062],
         [-0.6416,  0.1625,  0.7496,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.776567 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.777818 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0205],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:34.778460 - k: tensor([0.0039], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.779076 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:34.779697 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0751]
0:00:34.342213 - bracket_assembly_nut_noaug_coarse--206204
0:00:34.342431 - {'grad_norm': 1.1738771200180054, 'grad_norm_std': inf, 'learning_rate': 1.45e-06, 'time_forward': 0.05542325973510742, 'time_backward': 0.07762312889099121, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270288.8400226, 'n_iterations': 57, 'n_datas': 456, 'train_loss_TCO-iter=1': 0.07512588798999786, 'train_loss_TCO': 0.07512588798999786, 'train_[loss_total': 0.07512588798999786, 'train_loss_total': 0.07512588798999786, 'train_grad_norm': 1.1738771200180054, 'epoch': 56}
0:00:34.342546 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:34.349979 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:34.875201 - iteration 0
0:00:35.096192 - vxvyvz tensor([[-0.0486,  0.0250, -0.0708]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:35.097306 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:35.098317 - dR tensor([[[-0.6156,  0.3825, -0.6890],
         [-0.4049, -0.9036, -0.1398],
         [-0.6761,  0.1929,  0.7112]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:35.099144 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:35.102380 - k: tensor([[[-0.6156,  0.3825, -0.6890, -0.0100],
         [-0.4049, -0.9036, -0.1398,  0.0062],
         [-0.6761,  0.1929,  0.7112,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.103782 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.104850 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0212],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.105481 - k: tensor([0.0042], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.106098 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.106727 - k: tensor([0.0711], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0756]
0:00:35.737799 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],, loss=0.0762]
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0217],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:35.738463 - k: tensor([0.0040], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.739074 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:35.739680 - k: tensor([0.0712], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0756]
0:00:35.295949 - bracket_assembly_nut_noaug_coarse--206204
0:00:35.296248 - {'grad_norm': 1.12241792678833, 'grad_norm_std': inf, 'learning_rate': 1.525e-06, 'time_forward': 0.05547904968261719, 'time_backward': 0.07764220237731934, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270289.8000724, 'n_iterations': 60, 'n_datas': 480, 'train_loss_TCO-iter=1': 0.07557858526706696, 'train_loss_TCO': 0.07557858526706696, 'train_[loss_total': 0.07557858526706696, 'train_loss_total': 0.07557858526706696, 'train_grad_norm': 1.12241792678833, 'epoch': 59}
0:00:35.296435 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:35.304022 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:35.829284 - iteration 0
0:00:36.053774 - vxvyvz tensor([[-0.0469,  0.0189, -0.0674]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.054791 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.055751 - dR tensor([[[-0.6335,  0.4452, -0.6329],
         [-0.4386, -0.8804, -0.1803],
         [-0.6374,  0.1634,  0.7530]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.056641 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.059774 - k: tensor([[[-0.6335,  0.4452, -0.6329, -0.0100],
         [-0.4386, -0.8804, -0.1803,  0.0062],
         [-0.6374,  0.1634,  0.7530,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.060746 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.062167 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.062909 - k: tensor([0.0039], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.063519 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.064120 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.075]
0:00:35.617777 - bracket_assembly_nut_noaug_coarse--206204
0:00:35.617975 - {'grad_norm': 1.1946046352386475, 'grad_norm_std': inf, 'learning_rate': 1.5500000000000002e-06, 'time_forward': 0.059149980545043945, 'time_backward': 0.07781314849853516, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270290.1261616, 'n_iterations': 61, 'n_datas': 488, 'train_loss_TCO-iter=1': 0.0750230997800827, 'train_loss_TCO': 0.0750230997800827, 'train_[loss_total': 0.0750230997800827, 'train_loss_total': 0.0750230997800827, 'train_grad_norm': 1.1946046352386475, 'epoch': 60}
0:00:35.618081 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:35.625462 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.150652 - iteration 0
0:00:36.372412 - vxvyvz tensor([[-0.0467,  0.0174, -0.0584]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.373474 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.374424 - dR tensor([[[-0.6382,  0.4359, -0.6346],
         [-0.4422, -0.8823, -0.1613],
         [-0.6302,  0.1777,  0.7558]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.375259 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.378497 - k: tensor([[[-0.6382,  0.4359, -0.6346, -0.0100],
         [-0.4422, -0.8823, -0.1613,  0.0062],
         [-0.6302,  0.1777,  0.7558,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.379927 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.381013 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0175],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.381647 - k: tensor([0.0039], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.382263 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.382863 - k: tensor([0.0698], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0741]
0:00:35.938328 - bracket_assembly_nut_noaug_coarse--206204
0:00:35.938541 - {'grad_norm': 1.1492462158203125, 'grad_norm_std': inf, 'learning_rate': 1.5750000000000002e-06, 'time_forward': 0.05642867088317871, 'time_backward': 0.07800912857055664, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270290.443597, 'n_iterations': 62, 'n_datas': 496, 'train_loss_TCO-iter=1': 0.0740606039762497, 'train_loss_TCO': 0.0740606039762497, 'train_[loss_total': 0.0740606039762497, 'train_loss_total': 0.0740606039762497, 'train_grad_norm': 1.1492462158203125, 'epoch': 61}
0:00:35.938656 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:35.946097 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.471341 - iteration 0
0:00:36.692503 - vxvyvz tensor([[-0.0490,  0.0142, -0.0212]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:36.693527 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.694483 - dR tensor([[[-0.6296,  0.4756, -0.6144],
         [-0.4797, -0.8600, -0.1741],
         [-0.6112,  0.1851,  0.7695]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:36.695332 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:36.698565 - k: tensor([[[-0.6296,  0.4756, -0.6144, -0.0100],
         [-0.4797, -0.8600, -0.1741,  0.0062],
         [-0.6112,  0.1851,  0.7695,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.700026 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.701046 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0063],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:36.701692 - k: tensor([0.0038], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.702296 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:36.702895 - k: tensor([0.0661], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0703]
0:00:36.259225 - bracket_assembly_nut_noaug_coarse--206204
0:00:36.259446 - {'grad_norm': 1.0365835428237915, 'grad_norm_std': inf, 'learning_rate': 1.6000000000000001e-06, 'time_forward': 0.05586647987365723, 'time_backward': 0.07766222953796387, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270290.7631938, 'n_iterations': 63, 'n_datas': 504, 'train_loss_TCO-iter=1': 0.07026343047618866, 'train_loss_TCO': 0.07026343047618866, 'train_[loss_total': 0.07026343047618866, 'train_loss_total': 0.07026343047618866, 'train_grad_norm': 1.0365835428237915, 'epoch': 62}
0:00:36.259560 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:36.267020 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:36.792235 - iteration 0
0:00:37.013169 - vxvyvz tensor([[-0.0416,  0.0184, -0.0685]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:37.014171 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:37.015162 - dR tensor([[[-0.6128,  0.4487, -0.6504],
         [-0.4573, -0.8727, -0.1711],
         [-0.6444,  0.1926,  0.7400]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:37.016022 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:37.019260 - k: tensor([[[-0.6128,  0.4487, -0.6504, -0.0100],
         [-0.4573, -0.8727, -0.1711,  0.0062],
         [-0.6444,  0.1926,  0.7400,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.020162 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.021691 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.022327 - k: tensor([0.0039], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.022934 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.023533 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0751]
0:00:36.579096 - bracket_assembly_nut_noaug_coarse--206204
0:00:36.579312 - {'grad_norm': 1.0035609006881714, 'grad_norm_std': inf, 'learning_rate': 1.6250000000000001e-06, 'time_forward': 0.055512189865112305, 'time_backward': 0.07724380493164062, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270291.0834477, 'n_iterations': 64, 'n_datas': 512, 'train_loss_TCO-iter=1': 0.07510106265544891, 'train_loss_TCO': 0.07510106265544891, 'train_[loss_total': 0.07510106265544891, 'train_loss_total': 0.07510106265544891, 'train_grad_norm': 1.0035609006881714, 'epoch': 63}
0:00:36.579474 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:36.587027 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:37.112262 - iteration 0
0:00:37.333287 - vxvyvz tensor([[-0.0470,  0.0161, -0.0673]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:37.334289 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:37.335241 - dR tensor([[[-0.6501,  0.4692, -0.5978],
         [-0.4640, -0.8680, -0.1766],
         [-0.6017,  0.1626,  0.7820]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:37.336065 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:37.339269 - k: tensor([[[-0.6501,  0.4692, -0.5978, -0.0100],
         [-0.4640, -0.8680, -0.1766,  0.0062],
         [-0.6017,  0.1626,  0.7820,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.340168 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.341706 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0202],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:37.342326 - k: tensor([0.0038], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.342929 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:37.343527 - k: tensor([0.0707], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0748]
         [-0.6180,  0.1262,  0.7760,  0.1920],,  0.4165, -0.0100],, loss=0.0762]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.294999 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.296017 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0179],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.296702 - k: tensor([0.0037], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.297324 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.297945 - k: tensor([0.0700], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.074]
0:00:37.850060 - bracket_assembly_nut_noaug_coarse--206204
0:00:37.850276 - {'grad_norm': 1.1097400188446045, 'grad_norm_std': inf, 'learning_rate': 1.725e-06, 'time_forward': 0.05598855018615723, 'time_backward': 0.07686233520507812, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270292.3574162, 'n_iterations': 68, 'n_datas': 544, 'train_loss_TCO-iter=1': 0.07401487231254578, 'train_loss_TCO': 0.07401487231254578, 'train_[loss_total': 0.07401487231254578, 'train_loss_total': 0.07401487231254578, 'train_grad_norm': 1.1097400188446045, 'epoch': 67}
0:00:37.850389 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:37.857815 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.383064 - iteration 0
0:00:38.606999 - vxvyvz tensor([[-0.0433,  0.0120, -0.0528]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:38.608010 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.609051 - dR tensor([[[-0.6262,  0.4907, -0.6059],
         [-0.4774, -0.8557, -0.1995],
         [-0.6164,  0.1643,  0.7701]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:38.609901 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:38.613096 - k: tensor([[[-0.6262,  0.4907, -0.6059, -0.0100],
         [-0.4774, -0.8557, -0.1995,  0.0062],
         [-0.6164,  0.1643,  0.7701,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.614012 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.614946 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0158],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.616030 - k: tensor([0.0037], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.616772 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.617391 - k: tensor([0.0693], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0733]
0:00:38.172446 - bracket_assembly_nut_noaug_coarse--206204
0:00:38.172640 - {'grad_norm': 1.032941222190857, 'grad_norm_std': inf, 'learning_rate': 1.75e-06, 'time_forward': 0.05866050720214844, 'time_backward': 0.07743167877197266, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270292.6774623, 'n_iterations': 69, 'n_datas': 552, 'train_loss_TCO-iter=1': 0.07333274185657501, 'train_loss_TCO': 0.07333274185657501, 'train_[loss_total': 0.07333274185657501, 'train_loss_total': 0.07333274185657501, 'train_grad_norm': 1.032941222190857, 'epoch': 68}
0:00:38.172754 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:38.180045 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.705214 - iteration 0
0:00:38.926053 - vxvyvz tensor([[-0.0449,  0.0170, -0.0677]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:38.927054 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:38.928056 - dR tensor([[[-0.6184,  0.4574, -0.6390],
         [-0.4643, -0.8687, -0.1725],
         [-0.6340,  0.1900,  0.7496]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:38.928926 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:38.932032 - k: tensor([[[-0.6184,  0.4574, -0.6390, -0.0100],
         [-0.4643, -0.8687, -0.1725,  0.0062],
         [-0.6340,  0.1900,  0.7496,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.932981 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.934397 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0203],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:38.935122 - k: tensor([0.0039], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.935733 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:38.936378 - k: tensor([0.0708], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.075]
0:00:38.491785 - bracket_assembly_nut_noaug_coarse--206204
0:00:38.492029 - {'grad_norm': 1.1392041444778442, 'grad_norm_std': inf, 'learning_rate': 1.7750000000000002e-06, 'time_forward': 0.05529046058654785, 'time_backward': 0.07769989967346191, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270292.9969006, 'n_iterations': 70, 'n_datas': 560, 'train_loss_TCO-iter=1': 0.07500338554382324, 'train_loss_TCO': 0.07500338554382324, 'train_[loss_total': 0.07500338554382324, 'train_loss_total': 0.07500338554382324, 'train_grad_norm': 1.1392041444778442, 'epoch': 69}
0:00:38.492252 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:38.499576 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:39.024744 - iteration 0
0:00:39.246055 - vxvyvz tensor([[-0.0374,  0.0151, -0.0662]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:39.247082 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:39.248039 - dR tensor([[[-0.6557,  0.4902, -0.5742],
         [-0.4569, -0.8631, -0.2151],
         [-0.6010,  0.1213,  0.7900]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:39.248940 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:39.252096 - k: tensor([[[-0.6557,  0.4902, -0.5742, -0.0100],
         [-0.4569, -0.8631, -0.2151,  0.0062],
         [-0.6010,  0.1213,  0.7900,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.253070 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.254618 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0199],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:39.255235 - k: tensor([0.0036], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.255840 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:39.256503 - k: tensor([0.0706], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0746]
       grad_fn=<CopySlices>) 0.7760,  0.1920],,  0.4165, -0.0100],, loss=0.0762]
0:00:40.236316 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.237895 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0172],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.238523 - k: tensor([0.0036], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.239127 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.239727 - k: tensor([0.0697], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0736]
0:00:39.807517 - bracket_assembly_nut_noaug_coarse--206204
0:00:39.807725 - {'grad_norm': 1.0762526988983154, 'grad_norm_std': inf, 'learning_rate': 1.8750000000000003e-06, 'time_forward': 0.05521368980407715, 'time_backward': 0.0775611400604248, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270294.3000069, 'n_iterations': 74, 'n_datas': 592, 'train_loss_TCO-iter=1': 0.07362553477287292, 'train_loss_TCO': 0.07362553477287292, 'train_[loss_total': 0.07362553477287292, 'train_loss_total': 0.07362553477287292, 'train_grad_norm': 1.0762526988983154, 'epoch': 73}
0:00:39.807875 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:39.815232 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.340404 - iteration 0
0:00:40.561323 - vxvyvz tensor([[-0.0351,  0.0091, -0.0594]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:40.562344 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.563298 - dR tensor([[[-0.6389,  0.5353, -0.5525],
         [-0.4913, -0.8366, -0.2423],
         [-0.5919,  0.1166,  0.7975]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:40.564178 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:40.567343 - k: tensor([[[-0.6389,  0.5353, -0.5525, -0.0100],
         [-0.4913, -0.8366, -0.2423,  0.0062],
         [-0.5919,  0.1166,  0.7975,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.568279 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.569721 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0178],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.570447 - k: tensor([0.0035], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.571052 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.571655 - k: tensor([0.0699], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0738]
0:00:40.122474 - bracket_assembly_nut_noaug_coarse--206204
0:00:40.122693 - {'grad_norm': 1.1062225103378296, 'grad_norm_std': inf, 'learning_rate': 1.9000000000000002e-06, 'time_forward': 0.055443763732910156, 'time_backward': 0.07729125022888184, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270294.6316535, 'n_iterations': 75, 'n_datas': 600, 'train_loss_TCO-iter=1': 0.07381074130535126, 'train_loss_TCO': 0.07381074130535126, 'train_[loss_total': 0.07381074130535126, 'train_loss_total': 0.07381074130535126, 'train_grad_norm': 1.1062225103378296, 'epoch': 74}
0:00:40.122808 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:40.130173 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.655377 - iteration 0
0:00:40.876558 - vxvyvz tensor([[-0.0351,  0.0145, -0.0546]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:40.877577 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.878523 - dR tensor([[[-0.6227,  0.5552, -0.5514],
         [-0.5030, -0.8238, -0.2615],
         [-0.5994,  0.1145,  0.7922]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:40.879376 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:40.882598 - k: tensor([[[-0.6227,  0.5552, -0.5514, -0.0100],
         [-0.5030, -0.8238, -0.2615,  0.0062],
         [-0.5994,  0.1145,  0.7922,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.884061 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.885113 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0164],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:40.885731 - k: tensor([0.0036], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.886343 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:40.886948 - k: tensor([0.0695], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0734]
0:00:40.441433 - bracket_assembly_nut_noaug_coarse--206204
0:00:40.441614 - {'grad_norm': 1.0920464992523193, 'grad_norm_std': inf, 'learning_rate': 1.925e-06, 'time_forward': 0.05578207969665527, 'time_backward': 0.07721161842346191, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270294.9468465, 'n_iterations': 76, 'n_datas': 608, 'train_loss_TCO-iter=1': 0.07337076961994171, 'train_loss_TCO': 0.07337076961994171, 'train_[loss_total': 0.07337076961994171, 'train_loss_total': 0.07337076961994171, 'train_grad_norm': 1.0920464992523193, 'epoch': 75}
0:00:40.441746 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:40.449185 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:40.974411 - iteration 0
0:00:41.198421 - vxvyvz tensor([[-0.0446,  0.0062,  0.0114]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:41.199436 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:41.200657 - dR tensor([[[-0.6536,  0.5834, -0.4821],
         [-0.5232, -0.8086, -0.2692],
         [-0.5469,  0.0763,  0.8337]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:41.201614 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:41.204848 - k: tensor([[[-0.6536,  0.5834, -0.4821, -0.0100],
         [-0.5232, -0.8086, -0.2692,  0.0062],
         [-0.5469,  0.0763,  0.8337,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.205747 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.207130 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0034],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:41.207880 - k: tensor([0.0032], device='cuda:0', grad_fn=<MinBackward0>)
0:00:41.208508 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:41.209118 - k: tensor([0.0628], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, loss=0.0664]
0:00:40.761613 - bracket_assembly_nut_noaug_coarse--206204
0:00:40.761828 - {'grad_norm': 1.018750548362732, 'grad_norm_std': inf, 'learning_rate': 1.9500000000000004e-06, 'time_forward': 0.058933258056640625, 'time_backward': 0.07764267921447754, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270295.2693377, 'n_iterations': 77, 'n_datas': 616, 'train_loss_TCO-iter=1': 0.0664411187171936, 'train_loss_TCO': 0.0664411187171936, 'train_[loss_total': 0.0664411187171936, 'train_loss_total': 0.0664411187171936, 'train_grad_norm': 1.018750548362732, 'epoch': 76}
0:00:40.761944 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:40.769289 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:41.294506 - iteration 0
         [ 0.2313, -0.4099,  0.8823, -0.0175],,  0.4165, -0.0100],, loss=0.0762]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.158739 - k: tensor([0.0035], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.159344 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.159986 - k: tensor([0.0698], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0737]
0:00:41.713560 - bracket_assembly_nut_noaug_coarse--206204
0:00:41.713781 - {'grad_norm': 1.109865427017212, 'grad_norm_std': inf, 'learning_rate': 2.025e-06, 'time_forward': 0.05577826499938965, 'time_backward': 0.07706117630004883, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270296.2197604, 'n_iterations': 80, 'n_datas': 640, 'train_loss_TCO-iter=1': 0.07372092455625534, 'train_loss_TCO': 0.07372092455625534, 'train_[loss_total': 0.07372092455625534, 'train_loss_total': 0.07372092455625534, 'train_grad_norm': 1.109865427017212, 'epoch': 79}
0:00:41.713894 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:41.721309 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.246483 - iteration 0
0:00:42.467463 - vxvyvz tensor([[-0.0323,  0.0018, -0.0597]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:42.468556 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.469534 - dR tensor([[[-0.6760,  0.5395, -0.5019],
         [-0.4660, -0.8406, -0.2760],
         [-0.5708,  0.0474,  0.8197]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:42.470396 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:42.473603 - k: tensor([[[-0.6760,  0.5395, -0.5019, -0.0100],
         [-0.4660, -0.8406, -0.2760,  0.0062],
         [-0.5708,  0.0474,  0.8197,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.474497 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.475971 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0179],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.476622 - k: tensor([0.0034], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.477240 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.477840 - k: tensor([0.0700], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0737]
0:00:42.032418 - bracket_assembly_nut_noaug_coarse--206204
0:00:42.032614 - {'grad_norm': 1.0468547344207764, 'grad_norm_std': inf, 'learning_rate': 2.05e-06, 'time_forward': 0.05557584762573242, 'time_backward': 0.07713937759399414, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270296.5375886, 'n_iterations': 81, 'n_datas': 648, 'train_loss_TCO-iter=1': 0.07373663783073425, 'train_loss_TCO': 0.07373663783073425, 'train_[loss_total': 0.07373663783073425, 'train_loss_total': 0.07373663783073425, 'train_grad_norm': 1.0468547344207764, 'epoch': 80}
0:00:42.032789 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.040217 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.565444 - iteration 0
0:00:42.786964 - vxvyvz tensor([[-0.0306,  0.0064, -0.0617]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:42.788007 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.789034 - dR tensor([[[-0.6735,  0.5418, -0.5029],
         [-0.4934, -0.8361, -0.2399],
         [-0.5504,  0.0866,  0.8304]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:42.789872 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:42.793089 - k: tensor([[[-0.6735,  0.5418, -0.5029, -0.0100],
         [-0.4934, -0.8361, -0.2399,  0.0062],
         [-0.5504,  0.0866,  0.8304,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.793987 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.795392 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0185],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:42.796121 - k: tensor([0.0034], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.796769 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:42.797385 - k: tensor([0.0702], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0739]
0:00:42.356405 - bracket_assembly_nut_noaug_coarse--206204
0:00:42.356625 - {'grad_norm': 0.9762351512908936, 'grad_norm_std': inf, 'learning_rate': 2.075e-06, 'time_forward': 0.056194305419921875, 'time_backward': 0.07706451416015625, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270296.8570983, 'n_iterations': 82, 'n_datas': 656, 'train_loss_TCO-iter=1': 0.07390040159225464, 'train_loss_TCO': 0.07390040159225464, 'train_[loss_total': 0.07390040159225464, 'train_loss_total': 0.07390040159225464, 'train_grad_norm': 0.9762351512908936, 'epoch': 81}
0:00:42.356740 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.364101 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:42.889300 - iteration 0
0:00:43.110584 - vxvyvz tensor([[-0.0416,  0.0076, -0.0524]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:43.111609 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.112643 - dR tensor([[[-0.6447,  0.5587, -0.5217],
         [-0.5132, -0.8222, -0.2462],
         [-0.5665,  0.1090,  0.8168]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:43.113483 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:43.116677 - k: tensor([[[-0.6447,  0.5587, -0.5217, -0.0100],
         [-0.5132, -0.8222, -0.2462,  0.0062],
         [-0.5665,  0.1090,  0.8168,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.117599 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.119012 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0157],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.119768 - k: tensor([0.0034], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.120395 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.121033 - k: tensor([0.0692], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.073]
0:00:42.675914 - bracket_assembly_nut_noaug_coarse--206204
0:00:42.676129 - {'grad_norm': 1.1322498321533203, 'grad_norm_std': inf, 'learning_rate': 2.1000000000000002e-06, 'time_forward': 0.05595850944519043, 'time_backward': 0.07742571830749512, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270297.181105, 'n_iterations': 83, 'n_datas': 664, 'train_loss_TCO-iter=1': 0.07298366725444794, 'train_loss_TCO': 0.07298366725444794, 'train_[loss_total': 0.07298366725444794, 'train_loss_total': 0.07298366725444794, 'train_grad_norm': 1.1322498321533203, 'epoch': 82}
0:00:42.676265 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:42.683722 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.208889 - iteration 0
0:00:43.429888 - vxvyvz tensor([[-0.0298,  0.0074, -0.0565]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:43.430930 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:43.431925 - dR tensor([[[-0.6717,  0.5790, -0.4622],
         [-0.5095, -0.8139, -0.2791],
         [-0.5378,  0.0480,  0.8417]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:43.432811 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:43.435961 - k: tensor([[[-0.6717,  0.5790, -0.4622, -0.0100],
         [-0.5095, -0.8139, -0.2791,  0.0062],
         [-0.5378,  0.0480,  0.8417,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.436959 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.438425 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0169],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:43.439043 - k: tensor([0.0032], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.439691 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:43.440305 - k: tensor([0.0696], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0732]
       grad_fn=<CopySlices>) 0.8823, -0.0175],,  0.4165, -0.0100],, loss=0.0762]
0:00:44.396333 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.397773 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0175],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.398470 - k: tensor([0.0034], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.399077 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.399713 - k: tensor([0.0698], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0736]
0:00:43.955811 - bracket_assembly_nut_noaug_coarse--206204
0:00:43.956017 - {'grad_norm': 1.0577634572982788, 'grad_norm_std': inf, 'learning_rate': 2.2e-06, 'time_forward': 0.055567026138305664, 'time_backward': 0.07760071754455566, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270298.4600244, 'n_iterations': 87, 'n_datas': 696, 'train_loss_TCO-iter=1': 0.07358156889677048, 'train_loss_TCO': 0.07358156889677048, 'train_[loss_total': 0.07358156889677048, 'train_loss_total': 0.07358156889677048, 'train_grad_norm': 1.0577634572982788, 'epoch': 86}
0:00:43.956144 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:43.963626 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.488802 - iteration 0
0:00:44.709860 - vxvyvz tensor([[-0.0350, -0.0009, -0.0566]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:44.710904 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.711907 - dR tensor([[[-0.6980,  0.5676, -0.4366],
         [-0.4841, -0.8233, -0.2964],
         [-0.5277,  0.0044,  0.8494]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:44.712794 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:44.715957 - k: tensor([[[-0.6980,  0.5676, -0.4366, -0.0100],
         [-0.4841, -0.8233, -0.2964,  0.0062],
         [-0.5277,  0.0044,  0.8494,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.716929 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.718377 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0170],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:44.719097 - k: tensor([0.0032], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.719735 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:44.720353 - k: tensor([0.0696], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0732]
0:00:44.277052 - bracket_assembly_nut_noaug_coarse--206204
0:00:44.277266 - {'grad_norm': 1.1172709465026855, 'grad_norm_std': inf, 'learning_rate': 2.2250000000000003e-06, 'time_forward': 0.05575418472290039, 'time_backward': 0.07781195640563965, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270298.7808654, 'n_iterations': 88, 'n_datas': 704, 'train_loss_TCO-iter=1': 0.0732138380408287, 'train_loss_TCO': 0.0732138380408287, 'train_[loss_total': 0.0732138380408287, 'train_loss_total': 0.0732138380408287, 'train_grad_norm': 1.1172709465026855, 'epoch': 87}
0:00:44.277380 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:44.284924 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:44.810090 - iteration 0
0:00:45.031336 - vxvyvz tensor([[-0.0325,  0.0067, -0.0474]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:45.032398 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.033392 - dR tensor([[[-0.6909,  0.5932, -0.4132],
         [-0.4908, -0.8046, -0.3344],
         [-0.5308, -0.0283,  0.8470]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:45.034240 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:45.037501 - k: tensor([[[-0.6909,  0.5932, -0.4132, -0.0100],
         [-0.4908, -0.8046, -0.3344,  0.0062],
         [-0.5308, -0.0283,  0.8470,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.038402 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.039889 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0142],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.040547 - k: tensor([0.0031], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.041179 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.041782 - k: tensor([0.0687], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0722]
0:00:44.605479 - bracket_assembly_nut_noaug_coarse--206204
0:00:44.605700 - {'grad_norm': 1.0771631002426147, 'grad_norm_std': inf, 'learning_rate': 2.25e-06, 'time_forward': 0.05595588684082031, 'time_backward': 0.07805156707763672, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270299.102441, 'n_iterations': 89, 'n_datas': 712, 'train_loss_TCO-iter=1': 0.07222011685371399, 'train_loss_TCO': 0.07222011685371399, 'train_[loss_total': 0.07222011685371399, 'train_loss_total': 0.07222011685371399, 'train_grad_norm': 1.0771631002426147, 'epoch': 88}
0:00:44.605813 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:44.613315 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.138642 - iteration 0
0:00:45.359740 - vxvyvz tensor([[-0.0267,  0.0003, -0.0602]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:45.360777 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:45.361769 - dR tensor([[[-0.6862,  0.6045, -0.4045],
         [-0.5038, -0.7961, -0.3352],
         [-0.5247, -0.0262,  0.8509]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:45.362619 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:45.365847 - k: tensor([[[-0.6862,  0.6045, -0.4045, -0.0100],
         [-0.5038, -0.7961, -0.3352,  0.0062],
         [-0.5247, -0.0262,  0.8509,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.367254 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.368286 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0180],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:45.368944 - k: tensor([0.0031], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.369550 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:45.370150 - k: tensor([0.0700], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0734]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
       grad_fn=<CopySlices>)
0:00:46.392084 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.393024 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0102],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.394160 - k: tensor([0.0030], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.394845 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.395464 - k: tensor([0.0674], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0708]
0:00:45.966281 - bracket_assembly_nut_noaug_coarse--206204
0:00:45.966494 - {'grad_norm': 1.0678905248641968, 'grad_norm_std': inf, 'learning_rate': 2.35e-06, 'time_forward': 0.05846595764160156, 'time_backward': 0.07757186889648438, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270300.4557676, 'n_iterations': 93, 'n_datas': 744, 'train_loss_TCO-iter=1': 0.07077072560787201, 'train_loss_TCO': 0.07077072560787201, 'train_[loss_total': 0.07077072560787201, 'train_loss_total': 0.07077072560787201, 'train_grad_norm': 1.0678905248641968, 'epoch': 92}
0:00:45.966670 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:45.974064 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.499229 - iteration 0
0:00:46.720408 - vxvyvz tensor([[-0.0309, -0.0002, -0.0498]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:46.721467 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.722457 - dR tensor([[[-0.6855,  0.6084, -0.4000],
         [-0.5056, -0.7930, -0.3397],
         [-0.5239, -0.0306,  0.8512]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:46.723290 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:46.726497 - k: tensor([[[-0.6855,  0.6084, -0.4000, -0.0100],
         [-0.5056, -0.7930, -0.3397,  0.0062],
         [-0.5239, -0.0306,  0.8512,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.727393 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.728894 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0149],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:46.729546 - k: tensor([0.0031], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.730152 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:46.730753 - k: tensor([0.0690], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0724]
0:00:46.305541 - bracket_assembly_nut_noaug_coarse--206204
0:00:46.305757 - {'grad_norm': 1.074918508529663, 'grad_norm_std': inf, 'learning_rate': 2.375e-06, 'time_forward': 0.055670976638793945, 'time_backward': 0.07731127738952637, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270300.7907858, 'n_iterations': 94, 'n_datas': 752, 'train_loss_TCO-iter=1': 0.07241152971982956, 'train_loss_TCO': 0.07241152971982956, 'train_[loss_total': 0.07241152971982956, 'train_loss_total': 0.07241152971982956, 'train_grad_norm': 1.074918508529663, 'epoch': 93}
0:00:46.305872 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:46.313363 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:46.838553 - iteration 0
0:00:47.059756 - vxvyvz tensor([[-0.0260, -0.0091, -0.0395]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:47.060786 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:47.061784 - dR tensor([[[-0.6919,  0.6291, -0.3544],
         [-0.5161, -0.7741, -0.3665],
         [-0.5049, -0.0707,  0.8603]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:47.062628 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:47.065919 - k: tensor([[[-0.6919,  0.6291, -0.3544, -0.0100],
         [-0.5161, -0.7741, -0.3665,  0.0062],
         [-0.5049, -0.0707,  0.8603,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.067313 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.068366 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0119],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:47.069022 - k: tensor([0.0029], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.069627 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:47.070229 - k: tensor([0.0679], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0712]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:00:48.068016 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.069529 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0134],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.070148 - k: tensor([0.0029], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.070754 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.071358 - k: tensor([0.0685], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0717]
0:00:47.646490 - bracket_assembly_nut_noaug_coarse--206204
0:00:47.646754 - {'grad_norm': 1.050856351852417, 'grad_norm_std': inf, 'learning_rate': 2.475e-06, 'time_forward': 0.05607342720031738, 'time_backward': 0.07800889015197754, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270302.1321259, 'n_iterations': 98, 'n_datas': 784, 'train_loss_TCO-iter=1': 0.07171206921339035, 'train_loss_TCO': 0.07171206921339035, 'train_[loss_total': 0.07171206921339035, 'train_loss_total': 0.07171206921339035, 'train_grad_norm': 1.050856351852417, 'epoch': 97}
0:00:47.646891 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:47.654194 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.179409 - iteration 0
0:00:48.400313 - vxvyvz tensor([[-0.0218, -0.0077, -0.0248]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:48.401324 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.402287 - dR tensor([[[-0.7018,  0.6298, -0.3330],
         [-0.5206, -0.7725, -0.3637],
         [-0.4863, -0.0819,  0.8700]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:48.403109 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.406332 - k: tensor([[[-0.7018,  0.6298, -0.3330, -0.0100],
         [-0.5206, -0.7725, -0.3637,  0.0062],
         [-0.4863, -0.0819,  0.8700,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.407237 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.408517 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0074],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.409424 - k: tensor([0.0029], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.410129 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.410754 - k: tensor([0.0665], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0697]
0:00:47.977383 - bracket_assembly_nut_noaug_coarse--206204
0:00:47.977609 - {'grad_norm': 1.1706833839416504, 'grad_norm_std': inf, 'learning_rate': 2.5e-06, 'time_forward': 0.055576324462890625, 'time_backward': 0.07851099967956543, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270302.4721587, 'n_iterations': 99, 'n_datas': 792, 'train_loss_TCO-iter=1': 0.06969847530126572, 'train_loss_TCO': 0.06969847530126572, 'train_[loss_total': 0.06969847530126572, 'train_loss_total': 0.06969847530126572, 'train_grad_norm': 1.1706833839416504, 'epoch': 98}
0:00:47.977738 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:47.985296 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.510532 - iteration 0
0:00:48.731844 - vxvyvz tensor([[-0.0162, -0.0086, -0.0372]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:48.732893 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.733844 - dR tensor([[[-0.6928,  0.6623, -0.2853],
         [-0.5385, -0.7382, -0.4062],
         [-0.4796, -0.1277,  0.8681]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:48.734669 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:48.737857 - k: tensor([[[-0.6928,  0.6623, -0.2853, -0.0100],
         [-0.5385, -0.7382, -0.4062,  0.0062],
         [-0.4796, -0.1277,  0.8681,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.738816 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.740337 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0112],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:48.740996 - k: tensor([0.0029], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.741603 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:48.742207 - k: tensor([0.0677], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0709]
0:00:48.302441 - bracket_assembly_nut_noaug_coarse--206204
0:00:48.302670 - {'grad_norm': 1.064948320388794, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0560154914855957, 'time_backward': 0.0774531364440918, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270302.8023565, 'n_iterations': 100, 'n_datas': 800, 'train_loss_TCO-iter=1': 0.07093758881092072, 'train_loss_TCO': 0.07093758881092072, 'train_[loss_total': 0.07093758881092072, 'train_loss_total': 0.07093758881092072, 'train_grad_norm': 1.064948320388794, 'epoch': 99}
0:00:48.302783 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.310318 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.835608 - iteration 0
0:00:49.060279 - vxvyvz tensor([[-0.0178, -0.0004, -0.0347]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:49.061334 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.062312 - dR tensor([[[-0.7022,  0.6497, -0.2912],
         [-0.5227, -0.7482, -0.4087],
         [-0.4833, -0.1348,  0.8650]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:49.063139 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.066364 - k: tensor([[[-0.7022,  0.6497, -0.2912, -0.0100],
         [-0.5227, -0.7482, -0.4087,  0.0062],
         [-0.4833, -0.1348,  0.8650,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.067263 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.068804 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0104],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:49.069433 - k: tensor([0.0029], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.070055 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:49.070657 - k: tensor([0.0675], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0707]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:48.450964 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:48.976033 - iteration 0
0:00:49.190521 - vxvyvz tensor([[0.0061, 0.0123, 0.0099]], device='cuda:0')
0:00:49.191506 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.192502 - dR tensor([[[-0.6625, -0.3953,  0.6362],
         [-0.6430, -0.1355, -0.7538],
         [ 0.3842, -0.9085, -0.1644]]], device='cuda:0')
0:00:49.193352 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:49.196350 - k: tensor([[[-0.6625, -0.3953,  0.6362, -0.0100],
         [-0.6430, -0.1355, -0.7538,  0.0062],
         [ 0.3842, -0.9085, -0.1644,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.197282 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.198203 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0030],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:49.198824 - k: tensor([0.0048], device='cuda:0')
0:00:49.199439 - k: tensor([0.0003], device='cuda:0')
0:00:49.200079 - k: tensor([0.0630], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.67it/s]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:00:50.096057 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.097532 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0096],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.098145 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.098747 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.099346 - k: tensor([0.0672], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.42it/s, loss=0.0704]
0:00:49.664809 - bracket_assembly_nut_noaug_coarse--206204
0:00:49.665018 - {'grad_norm': 1.0661945343017578, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05522608757019043, 'time_backward': 0.07588958740234375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270304.1579404, 'n_iterations': 104, 'n_datas': 832, 'train_loss_TCO-iter=1': 0.07035969942808151, 'train_loss_TCO': 0.07035969942808151, 'train_[loss_total': 0.07035969942808151, 'train_loss_total': 0.07035969942808151, 'train_grad_norm': 1.0661945343017578, 'epoch': 103}
0:00:49.665191 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:49.672707 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.197880 - iteration 0
0:00:50.418960 - vxvyvz tensor([[-0.0158, -0.0173, -0.0387]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.420003 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.421007 - dR tensor([[[-0.7321,  0.6323, -0.2536],
         [-0.5189, -0.7587, -0.3938],
         [-0.4414, -0.1567,  0.8835]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.421829 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.424975 - k: tensor([[[-0.7321,  0.6323, -0.2536, -0.0100],
         [-0.5189, -0.7587, -0.3938,  0.0062],
         [-0.4414, -0.1567,  0.8835,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.425878 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.427319 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0116],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.427971 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.428622 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.429238 - k: tensor([0.0679], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.41it/s, loss=0.0709]
0:00:49.987521 - bracket_assembly_nut_noaug_coarse--206204
0:00:49.987722 - {'grad_norm': 1.0835212469100952, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05555438995361328, 'time_backward': 0.07566642761230469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270304.487561, 'n_iterations': 105, 'n_datas': 840, 'train_loss_TCO-iter=1': 0.07090960443019867, 'train_loss_TCO': 0.07090960443019867, 'train_[loss_total': 0.07090960443019867, 'train_loss_total': 0.07090960443019867, 'train_grad_norm': 1.0835212469100952, 'epoch': 104}
0:00:49.987838 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:49.995264 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.520477 - iteration 0
0:00:50.741310 - vxvyvz tensor([[-0.0199, -0.0117, -0.0137]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:50.742305 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.743285 - dR tensor([[[-0.6969,  0.6816, -0.2232],
         [-0.5621, -0.7123, -0.4203],
         [-0.4455, -0.1675,  0.8795]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:50.744155 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:50.747254 - k: tensor([[[-0.6969,  0.6816, -0.2232, -0.0100],
         [-0.5621, -0.7123, -0.4203,  0.0062],
         [-0.4455, -0.1675,  0.8795,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.748492 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.749779 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0041],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:50.750406 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.751025 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:50.751664 - k: tensor([0.0654], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.40it/s, loss=0.0684]
0:00:50.326995 - bracket_assembly_nut_noaug_coarse--206204
0:00:50.327212 - {'grad_norm': 1.1134816408157349, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05537772178649902, 'time_backward': 0.07595181465148926, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270304.810309, 'n_iterations': 106, 'n_datas': 848, 'train_loss_TCO-iter=1': 0.06842854619026184, 'train_loss_TCO': 0.06842854619026184, 'train_[loss_total': 0.06842854619026184, 'train_loss_total': 0.06842854619026184, 'train_grad_norm': 1.1134816408157349, 'epoch': 105}
0:00:50.327324 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:50.334707 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:50.859906 - iteration 0
0:00:51.080858 - vxvyvz tensor([[-0.0171, -0.0141, -0.0431]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:51.081858 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:51.082821 - dR tensor([[[-0.7038,  0.6584, -0.2667],
         [-0.5418, -0.7404, -0.3980],
         [-0.4595, -0.1356,  0.8778]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:51.083688 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:51.086940 - k: tensor([[[-0.7038,  0.6584, -0.2667, -0.0100],
         [-0.5418, -0.7404, -0.3980,  0.0062],
         [-0.4595, -0.1356,  0.8778,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.087881 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.089433 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0129],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:51.090144 - k: tensor([0.0028], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.090755 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:51.091359 - k: tensor([0.0683], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0714]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:00:52.190579 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.192008 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0071],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.192725 - k: tensor([0.0027], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.193348 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.193971 - k: tensor([0.0664], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0694]
0:00:51.754784 - bracket_assembly_nut_noaug_coarse--206204
0:00:51.754999 - {'grad_norm': 1.0840989351272583, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05568742752075195, 'time_backward': 0.07791662216186523, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270306.2545636, 'n_iterations': 110, 'n_datas': 880, 'train_loss_TCO-iter=1': 0.06941380351781845, 'train_loss_TCO': 0.06941380351781845, 'train_[loss_total': 0.06941380351781845, 'train_loss_total': 0.06941380351781845, 'train_grad_norm': 1.0840989351272583, 'epoch': 109}
0:00:51.755112 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:51.762535 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.287737 - iteration 0
0:00:52.508698 - vxvyvz tensor([[-0.0145, -0.0171, -0.0349]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.509702 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.510654 - dR tensor([[[-0.7247,  0.6598, -0.1987],
         [-0.5496, -0.7274, -0.4109],
         [-0.4156, -0.1886,  0.8898]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.511479 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.514692 - k: tensor([[[-0.7247,  0.6598, -0.1987, -0.0100],
         [-0.5496, -0.7274, -0.4109,  0.0062],
         [-0.4156, -0.1886,  0.8898,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.515624 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.517075 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0105],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.517796 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.518407 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.519011 - k: tensor([0.0675], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0704]
0:00:52.082416 - bracket_assembly_nut_noaug_coarse--206204
0:00:52.082633 - {'grad_norm': 1.0356169939041138, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055463314056396484, 'time_backward': 0.07738137245178223, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270306.5791044, 'n_iterations': 111, 'n_datas': 888, 'train_loss_TCO-iter=1': 0.07040691375732422, 'train_loss_TCO': 0.07040691375732422, 'train_[loss_total': 0.07040691375732422, 'train_loss_total': 0.07040691375732422, 'train_grad_norm': 1.0356169939041138, 'epoch': 110}
0:00:52.082744 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:52.090218 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.615382 - iteration 0
0:00:52.836644 - vxvyvz tensor([[-0.0124, -0.0168, -0.0058]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:52.837651 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.838603 - dR tensor([[[-0.7278,  0.6521, -0.2124],
         [-0.5449, -0.7379, -0.3983],
         [-0.4164, -0.1742,  0.8923]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:52.839411 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:52.842576 - k: tensor([[[-0.7278,  0.6521, -0.2124, -0.0100],
         [-0.5449, -0.7379, -0.3983,  0.0062],
         [-0.4164, -0.1742,  0.8923,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.843458 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.845022 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0017],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:52.845623 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.846211 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:52.846797 - k: tensor([0.0646], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0675]
0:00:52.410125 - bracket_assembly_nut_noaug_coarse--206204
0:00:52.410335 - {'grad_norm': 1.1650192737579346, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055531978607177734, 'time_backward': 0.07784056663513184, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270306.9072561, 'n_iterations': 112, 'n_datas': 896, 'train_loss_TCO-iter=1': 0.06754305958747864, 'train_loss_TCO': 0.06754305958747864, 'train_[loss_total': 0.06754305958747864, 'train_loss_total': 0.06754305958747864, 'train_grad_norm': 1.1650192737579346, 'epoch': 111}
0:00:52.410450 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:52.418033 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:52.943226 - iteration 0
0:00:53.164373 - vxvyvz tensor([[-0.0139, -0.0162, -0.0316]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:53.165397 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:53.166389 - dR tensor([[[-0.7124,  0.6813, -0.1683],
         [-0.5603, -0.6966, -0.4480],
         [-0.4225, -0.2249,  0.8780]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:53.167232 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:53.170430 - k: tensor([[[-0.7124,  0.6813, -0.1683, -0.0100],
         [-0.5603, -0.6966, -0.4480,  0.0062],
         [-0.4225, -0.2249,  0.8780,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.171326 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.172796 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0095],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:53.173490 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:53.174108 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:53.174716 - k: tensor([0.0671], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0701]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:00:54.124127 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.125149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0102],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.125762 - k: tensor([0.0026], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.126368 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.126970 - k: tensor([0.0674], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0703]
0:00:53.678913 - bracket_assembly_nut_noaug_coarse--206204
0:00:53.679123 - {'grad_norm': 1.043662428855896, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05606341361999512, 'time_backward': 0.0773770809173584, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270308.1871092, 'n_iterations': 116, 'n_datas': 928, 'train_loss_TCO-iter=1': 0.07030630111694336, 'train_loss_TCO': 0.07030630111694336, 'train_[loss_total': 0.07030630111694336, 'train_loss_total': 0.07030630111694336, 'train_grad_norm': 1.043662428855896, 'epoch': 115}
0:00:53.679238 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:53.686703 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.211964 - iteration 0
0:00:54.432944 - vxvyvz tensor([[-0.0191, -0.0212,  0.0928]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:54.433933 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.434882 - dR tensor([[[-0.7301,  0.6807, -0.0597],
         [-0.6018, -0.6819, -0.4157],
         [-0.3237, -0.2676,  0.9075]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:54.435741 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:54.438946 - k: tensor([[[-0.7301,  0.6807, -0.0597, -0.0100],
         [-0.6018, -0.6819, -0.4157,  0.0062],
         [-0.3237, -0.2676,  0.9075,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.439884 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.441382 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0278],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.441999 - k: tensor([0.0022], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.442606 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.443210 - k: tensor([0.0547], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0573]
0:00:54.003310 - bracket_assembly_nut_noaug_coarse--206204
0:00:54.003559 - {'grad_norm': 0.9596296548843384, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05551028251647949, 'time_backward': 0.07695579528808594, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270308.502888, 'n_iterations': 117, 'n_datas': 936, 'train_loss_TCO-iter=1': 0.05728025734424591, 'train_loss_TCO': 0.05728025734424591, 'train_[loss_total': 0.05728025734424591, 'train_loss_total': 0.05728025734424591, 'train_grad_norm': 0.9596296548843384, 'epoch': 116}
0:00:54.003742 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:54.011192 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.536392 - iteration 0
0:00:54.757663 - vxvyvz tensor([[-0.0105, -0.0195,  0.0235]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:54.758679 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.759671 - dR tensor([[[-0.7292,  0.6800, -0.0764],
         [-0.5783, -0.6721, -0.4624],
         [-0.3658, -0.2930,  0.8834]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:54.760541 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:54.763704 - k: tensor([[[-0.7292,  0.6800, -0.0764, -0.0100],
         [-0.5783, -0.6721, -0.4624,  0.0062],
         [-0.3658, -0.2930,  0.8834,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.764654 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.766112 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0070],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:54.766793 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.767401 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:54.768044 - k: tensor([0.0616], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0644]
0:00:54.347319 - bracket_assembly_nut_noaug_coarse--206204
0:00:54.347565 - {'grad_norm': 1.135655164718628, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05588722229003906, 'time_backward': 0.07702422142028809, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270308.827813, 'n_iterations': 118, 'n_datas': 944, 'train_loss_TCO-iter=1': 0.06436838954687119, 'train_loss_TCO': 0.06436838954687119, 'train_[loss_total': 0.06436838954687119, 'train_loss_total': 0.06436838954687119, 'train_grad_norm': 1.135655164718628, 'epoch': 117}
0:00:54.347681 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:54.355031 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:54.880241 - iteration 0
0:00:55.101398 - vxvyvz tensor([[-0.0058, -0.0257, -0.0348]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:55.102441 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:55.103395 - dR tensor([[[-0.7320,  0.6594, -0.1714],
         [-0.5450, -0.7176, -0.4336],
         [-0.4089, -0.2240,  0.8847]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:55.104268 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:55.107435 - k: tensor([[[-0.7320,  0.6594, -0.1714, -0.0100],
         [-0.5450, -0.7176, -0.4336,  0.0062],
         [-0.4089, -0.2240,  0.8847,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.108632 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.110020 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0104],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:55.110662 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:55.111269 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:55.111909 - k: tensor([0.0675], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0703]
0:00:54.696593 - bracket_assembly_nut_noaug_coarse--206204
0:00:54.696800 - {'grad_norm': 1.0210537910461426, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05584859848022461, 'time_backward': 0.07717537879943848, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270309.1718197, 'n_iterations': 119, 'n_datas': 952, 'train_loss_TCO-iter=1': 0.0703471377491951, 'train_loss_TCO': 0.0703471377491951, 'train_[loss_total': 0.0703471377491951, 'train_loss_total': 0.0703471377491951, 'train_grad_norm': 1.0210537910461426, 'epoch': 118}
0:00:54.696919 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]
         [ 0.2313, -0.4099,  0.8823,  0.1920],], device='cuda:0',,, loss=0.0762]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.122400 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0079],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.123017 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.123652 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.124269 - k: tensor([0.0666], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.0694]
0:00:55.679318 - bracket_assembly_nut_noaug_coarse--206204
0:00:55.679562 - {'grad_norm': 1.0182788372039795, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055786848068237305, 'time_backward': 0.08009934425354004, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270310.1871622, 'n_iterations': 122, 'n_datas': 976, 'train_loss_TCO-iter=1': 0.06943996995687485, 'train_loss_TCO': 0.06943996995687485, 'train_[loss_total': 0.06943996995687485, 'train_loss_total': 0.06943996995687485, 'train_grad_norm': 1.0182788372039795, 'epoch': 121}
0:00:55.679740 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:55.687099 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.212291 - iteration 0
0:00:56.433254 - vxvyvz tensor([[-0.0013, -0.0289,  0.0050]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:56.434243 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.435211 - dR tensor([[[-0.7480,  0.6598, -0.0718],
         [-0.5561, -0.6820, -0.4750],
         [-0.3624, -0.3153,  0.8771]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:56.436081 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:56.439248 - k: tensor([[[-0.7480,  0.6598, -0.0718, -0.0100],
         [-0.5561, -0.6820, -0.4750,  0.0062],
         [-0.3624, -0.3153,  0.8771,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.440181 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.441614 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0015],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.442304 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.442909 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.443510 - k: tensor([0.0635], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0662]
0:00:55.996670 - bracket_assembly_nut_noaug_coarse--206204
0:00:55.996858 - {'grad_norm': 1.0805649757385254, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05536484718322754, 'time_backward': 0.07777714729309082, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270310.504038, 'n_iterations': 123, 'n_datas': 984, 'train_loss_TCO-iter=1': 0.06619201600551605, 'train_loss_TCO': 0.06619201600551605, 'train_[loss_total': 0.06619201600551605, 'train_loss_total': 0.06619201600551605, 'train_grad_norm': 1.0805649757385254, 'epoch': 122}
0:00:55.996983 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:56.004255 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.529429 - iteration 0
0:00:56.750379 - vxvyvz tensor([[-0.0022, -0.0225, -0.0030]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:56.751396 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.752397 - dR tensor([[[-0.7462,  0.6515, -0.1368],
         [-0.5468, -0.7171, -0.4322],
         [-0.3797, -0.2477,  0.8913]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:56.753261 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:56.756471 - k: tensor([[[-0.7462,  0.6515, -0.1368, -0.0100],
         [-0.5468, -0.7171, -0.4322,  0.0062],
         [-0.3797, -0.2477,  0.8913,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.757416 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:56.758918 - k: tensor([[[-7.8929e-01,  4.5115e-01,  4.1651e-01, -1.0004e-02],
         [-5.6879e-01, -7.9274e-01, -2.1920e-01,  6.1788e-03],
         [ 2.3129e-01, -4.0992e-01,  8.8231e-01, -9.0500e-04],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0', grad_fn=<CopySlices>)
0:00:56.759536 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.760191 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:56.760843 - k: tensor([0.0643], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.067]
0:00:56.321670 - bracket_assembly_nut_noaug_coarse--206204
0:00:56.321877 - {'grad_norm': 1.0768333673477173, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05557107925415039, 'time_backward': 0.07853555679321289, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270310.8220742, 'n_iterations': 124, 'n_datas': 992, 'train_loss_TCO-iter=1': 0.06704940646886826, 'train_loss_TCO': 0.06704940646886826, 'train_[loss_total': 0.06704940646886826, 'train_loss_total': 0.06704940646886826, 'train_grad_norm': 1.0768333673477173, 'epoch': 123}
0:00:56.321994 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:56.329373 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:56.854559 - iteration 0
0:00:57.075636 - vxvyvz tensor([[-0.0022, -0.0291,  0.0241]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:57.076675 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.077658 - dR tensor([[[-0.7542,  0.6464, -0.1154],
         [-0.5561, -0.7222, -0.4113],
         [-0.3492, -0.2460,  0.9042]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:57.078483 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:57.081681 - k: tensor([[[-0.7542,  0.6464, -0.1154, -0.0100],
         [-0.5561, -0.7222, -0.4113,  0.0062],
         [-0.3492, -0.2460,  0.9042,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.082593 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.084098 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0072],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.084769 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.085376 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.085978 - k: tensor([0.0616], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0642]
0:00:56.646135 - bracket_assembly_nut_noaug_coarse--206204
0:00:56.646363 - {'grad_norm': 1.1738131046295166, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05565166473388672, 'time_backward': 0.07814145088195801, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270311.1467912, 'n_iterations': 125, 'n_datas': 1000, 'train_loss_TCO-iter=1': 0.06423725932836533, 'train_loss_TCO': 0.06423725932836533, 'train_[loss_total': 0.06423725932836533, 'train_loss_total': 0.06423725932836533, 'train_grad_norm': 1.1738131046295166, 'epoch': 124}
0:00:56.646476 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:56.653822 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.178996 - iteration 0
0:00:57.400341 - vxvyvz tensor([[-0.0013, -0.0293, -0.0149]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:57.401360 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:57.402310 - dR tensor([[[-0.7440,  0.6531, -0.1412],
         [-0.5411, -0.7129, -0.4461],
         [-0.3920, -0.2555,  0.8838]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:57.403134 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:57.406351 - k: tensor([[[-0.7440,  0.6531, -0.1412, -0.0100],
         [-0.5411, -0.7129, -0.4461,  0.0062],
         [-0.3920, -0.2555,  0.8838,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.407794 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.408833 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0045],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:57.409448 - k: tensor([0.0025], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.410049 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:57.410650 - k: tensor([0.0655], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0683]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
       grad_fn=<CopySlices>)
0:00:58.380580 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.382032 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0364],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.382732 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.383337 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.383978 - k: tensor([0.0518], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0541]
0:00:57.934280 - bracket_assembly_nut_noaug_coarse--206204
0:00:57.934494 - {'grad_norm': 1.005831241607666, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05573272705078125, 'time_backward': 0.0771634578704834, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270312.443761, 'n_iterations': 129, 'n_datas': 1032, 'train_loss_TCO-iter=1': 0.05411806330084801, 'train_loss_TCO': 0.05411806330084801, 'train_[loss_total': 0.05411806330084801, 'train_loss_total': 0.05411806330084801, 'train_grad_norm': 1.005831241607666, 'epoch': 128}
0:00:57.934610 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:57.942052 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.467285 - iteration 0
0:00:58.688402 - vxvyvz tensor([[-0.0026, -0.0290,  0.0546]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:58.689427 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.690380 - dR tensor([[[-0.7473,  0.6644,  0.0042],
         [-0.5896, -0.6602, -0.4654],
         [-0.3064, -0.3503,  0.8851]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:58.691209 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:58.694424 - k: tensor([[[-0.7473,  0.6644,  0.0042, -0.0100],
         [-0.5896, -0.6602, -0.4654,  0.0062],
         [-0.3064, -0.3503,  0.8851,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.695316 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.696879 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0164],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:58.697493 - k: tensor([0.0022], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.698097 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:58.698698 - k: tensor([0.0585], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.061]
0:00:58.253587 - bracket_assembly_nut_noaug_coarse--206204
0:00:58.253840 - {'grad_norm': 1.0743695497512817, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055641889572143555, 'time_backward': 0.07766532897949219, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270312.759087, 'n_iterations': 130, 'n_datas': 1040, 'train_loss_TCO-iter=1': 0.06102152168750763, 'train_loss_TCO': 0.06102152168750763, 'train_[loss_total': 0.06102152168750763, 'train_loss_total': 0.06102152168750763, 'train_grad_norm': 1.0743695497512817, 'epoch': 129}
0:00:58.254062 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:58.261667 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:58.786967 - iteration 0
0:00:59.009279 - vxvyvz tensor([[ 0.0033, -0.0359, -0.0085]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:59.010307 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:59.011260 - dR tensor([[[-0.7526,  0.6456, -0.1295],
         [-0.5383, -0.7165, -0.4438],
         [-0.3793, -0.2643,  0.8867]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:59.012133 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:59.015302 - k: tensor([[[-0.7526,  0.6456, -0.1295, -0.0100],
         [-0.5383, -0.7165, -0.4438,  0.0062],
         [-0.3793, -0.2643,  0.8867,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.016249 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.017784 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0025],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.018411 - k: tensor([0.0024], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.019017 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.019657 - k: tensor([0.0648], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0676]
0:00:58.572772 - bracket_assembly_nut_noaug_coarse--206204
0:00:58.572986 - {'grad_norm': 1.167724370956421, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057131290435791016, 'time_backward': 0.0775303840637207, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270313.0799181, 'n_iterations': 131, 'n_datas': 1048, 'train_loss_TCO-iter=1': 0.0676010474562645, 'train_loss_TCO': 0.0676010474562645, 'train_[loss_total': 0.0676010474562645, 'train_loss_total': 0.0676010474562645, 'train_grad_norm': 1.167724370956421, 'epoch': 130}
0:00:58.573102 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:58.580535 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:59.105684 - iteration 0
0:00:59.326691 - vxvyvz tensor([[ 0.0099, -0.0297, -0.0144]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:00:59.327746 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:00:59.328746 - dR tensor([[[-0.7679,  0.6359, -0.0770],
         [-0.5402, -0.7075, -0.4555],
         [-0.3441, -0.3082,  0.8869]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:00:59.329586 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:00:59.332791 - k: tensor([[[-0.7679,  0.6359, -0.0770, -0.0100],
         [-0.5402, -0.7075, -0.4555,  0.0062],
         [-0.3441, -0.3082,  0.8869,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.333962 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.335264 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0043],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:00:59.335922 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.336568 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:00:59.337188 - k: tensor([0.0654], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.068]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:00.286870 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.287936 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0043],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.288594 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.289215 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.289818 - k: tensor([0.0654], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.068]
0:00:59.841264 - bracket_assembly_nut_noaug_coarse--206204
0:00:59.841475 - {'grad_norm': 0.9634189009666443, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0558934211730957, 'time_backward': 0.07741117477416992, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270314.3498976, 'n_iterations': 135, 'n_datas': 1080, 'train_loss_TCO-iter=1': 0.06804989278316498, 'train_loss_TCO': 0.06804989278316498, 'train_[loss_total': 0.06804989278316498, 'train_loss_total': 0.06804989278316498, 'train_grad_norm': 0.9634189009666443, 'epoch': 134}
0:00:59.841587 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:00:59.849005 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.374225 - iteration 0
0:01:00.595503 - vxvyvz tensor([[ 0.0061, -0.0371,  0.0066]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:00.596564 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.597543 - dR tensor([[[-0.7627,  0.6433, -0.0666],
         [-0.5504, -0.6997, -0.4554],
         [-0.3395, -0.3107,  0.8878]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:00.598364 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:00.601570 - k: tensor([[[-0.7627,  0.6433, -0.0666, -0.0100],
         [-0.5504, -0.6997, -0.4554,  0.0062],
         [-0.3395, -0.3107,  0.8878,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.602465 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.604058 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0020],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.604710 - k: tensor([0.0023], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.605328 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.605927 - k: tensor([0.0633], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.066]
0:01:00.162453 - bracket_assembly_nut_noaug_coarse--206204
0:01:00.162666 - {'grad_norm': 1.0815417766571045, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05595541000366211, 'time_backward': 0.07764434814453125, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270314.6662347, 'n_iterations': 136, 'n_datas': 1088, 'train_loss_TCO-iter=1': 0.06595489382743835, 'train_loss_TCO': 0.06595489382743835, 'train_[loss_total': 0.06595489382743835, 'train_loss_total': 0.06595489382743835, 'train_grad_norm': 1.0815417766571045, 'epoch': 135}
0:01:00.162779 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:00.170213 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.695420 - iteration 0
0:01:00.916770 - vxvyvz tensor([[-0.0043, -0.0341,  0.1388]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:00.917835 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:00.918818 - dR tensor([[[-0.7648,  0.6407,  0.0673],
         [-0.6063, -0.6807, -0.4112],
         [-0.2177, -0.3553,  0.9091]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:00.919689 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:00.922921 - k: tensor([[[-0.7648,  0.6407,  0.0673, -0.0100],
         [-0.6063, -0.6807, -0.4112,  0.0062],
         [-0.2177, -0.3553,  0.9091,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.923863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.925349 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0416],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:00.926062 - k: tensor([0.0018], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.926683 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:00.927300 - k: tensor([0.0501], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0523]
0:01:00.484504 - bracket_assembly_nut_noaug_coarse--206204
0:01:00.484715 - {'grad_norm': 0.9921029806137085, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05615687370300293, 'time_backward': 0.0788261890411377, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270314.9889376, 'n_iterations': 137, 'n_datas': 1096, 'train_loss_TCO-iter=1': 0.05226735770702362, 'train_loss_TCO': 0.05226735770702362, 'train_[loss_total': 0.05226735770702362, 'train_loss_total': 0.05226735770702362, 'train_grad_norm': 0.9921029806137085, 'epoch': 136}
0:01:00.484832 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:00.492209 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.017428 - iteration 0
0:01:01.238547 - vxvyvz tensor([[ 0.0067, -0.0381, -0.0059]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:01.239578 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.240598 - dR tensor([[[-0.7869,  0.6164, -0.0276],
         [-0.5400, -0.7097, -0.4524],
         [-0.2984, -0.3411,  0.8914]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:01.241453 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:01.244656 - k: tensor([[[-0.7869,  0.6164, -0.0276, -0.0100],
         [-0.5400, -0.7097, -0.4524,  0.0062],
         [-0.2984, -0.3411,  0.8914,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.245580 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.247083 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0018],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.247735 - k: tensor([0.0021], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.248356 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.249003 - k: tensor([0.0646], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.067]
0:01:00.804874 - bracket_assembly_nut_noaug_coarse--206204
0:01:00.805093 - {'grad_norm': 1.1173979043960571, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055769920349121094, 'time_backward': 0.07742142677307129, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270315.309018, 'n_iterations': 138, 'n_datas': 1104, 'train_loss_TCO-iter=1': 0.06699392944574356, 'train_loss_TCO': 0.06699392944574356, 'train_[loss_total': 0.06699392944574356, 'train_loss_total': 0.06699392944574356, 'train_grad_norm': 1.1173979043960571, 'epoch': 137}
0:01:00.805206 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:00.812769 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.337931 - iteration 0
0:01:01.559067 - vxvyvz tensor([[ 0.0079, -0.0415, -0.0114]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:01.560111 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:01.561122 - dR tensor([[[-0.7535,  0.6558, -0.0469],
         [-0.5706, -0.6877, -0.4488],
         [-0.3266, -0.3114,  0.8924]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:01.561989 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:01.565191 - k: tensor([[[-0.7535,  0.6558, -0.0469, -0.0100],
         [-0.5706, -0.6877, -0.4488,  0.0062],
         [-0.3266, -0.3114,  0.8924,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.566096 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.567223 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0034],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:01.568177 - k: tensor([0.0022], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.568905 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:01.569531 - k: tensor([0.0651], device='cuda:0', grad_fn=<MinBackward0>)
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
       grad_fn=<CopySlices>)
0:01:02.540092 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.541480 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0454],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.542097 - k: tensor([0.0017], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.542698 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.543297 - k: tensor([0.0489], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0509]
0:01:02.098400 - bracket_assembly_nut_noaug_coarse--206204
0:01:02.098623 - {'grad_norm': 0.9857993125915527, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05583381652832031, 'time_backward': 0.07761979103088379, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270316.6035993, 'n_iterations': 142, 'n_datas': 1136, 'train_loss_TCO-iter=1': 0.05088450387120247, 'train_loss_TCO': 0.05088450387120247, 'train_[loss_total': 0.05088450387120247, 'train_loss_total': 0.05088450387120247, 'train_grad_norm': 0.9857993125915527, 'epoch': 141}
0:01:02.098738 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.106112 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.631317 - iteration 0
0:01:02.852465 - vxvyvz tensor([[ 0.0056, -0.0427, -0.0095]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:02.853472 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.854420 - dR tensor([[[-0.7700,  0.6379, -0.0073],
         [-0.5622, -0.6839, -0.4649],
         [-0.3016, -0.3539,  0.8853]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:02.855255 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:02.858457 - k: tensor([[[-0.7700,  0.6379, -0.0073, -0.0100],
         [-0.5622, -0.6839, -0.4649,  0.0062],
         [-0.3016, -0.3539,  0.8853,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.859356 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.860823 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0028],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:02.861526 - k: tensor([0.0021], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.862129 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:02.862733 - k: tensor([0.0649], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0674]
0:01:02.415736 - bracket_assembly_nut_noaug_coarse--206204
0:01:02.415931 - {'grad_norm': 0.9848930835723877, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05562591552734375, 'time_backward': 0.07761549949645996, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270316.9230413, 'n_iterations': 143, 'n_datas': 1144, 'train_loss_TCO-iter=1': 0.06737252324819565, 'train_loss_TCO': 0.06737252324819565, 'train_[loss_total': 0.06737252324819565, 'train_loss_total': 0.06737252324819565, 'train_grad_norm': 0.9848930835723877, 'epoch': 142}
0:01:02.416045 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.423391 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:02.948602 - iteration 0
0:01:03.170168 - vxvyvz tensor([[ 0.0135, -0.0442, -0.0048]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:03.171219 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.172233 - dR tensor([[[-0.7931,  0.6077, -0.0409],
         [-0.5340, -0.7260, -0.4333],
         [-0.2930, -0.3218,  0.9003]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:03.173107 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:03.176297 - k: tensor([[[-0.7931,  0.6077, -0.0409, -0.0100],
         [-0.5340, -0.7260, -0.4333,  0.0062],
         [-0.2930, -0.3218,  0.9003,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.177239 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.178730 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0014],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.179343 - k: tensor([0.0020], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.179987 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.180630 - k: tensor([0.0645], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0669]
0:01:02.741208 - bracket_assembly_nut_noaug_coarse--206204
0:01:02.741425 - {'grad_norm': 1.0216054916381836, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05620598793029785, 'time_backward': 0.07746505737304688, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270317.2407856, 'n_iterations': 144, 'n_datas': 1152, 'train_loss_TCO-iter=1': 0.06685319542884827, 'train_loss_TCO': 0.06685319542884827, 'train_[loss_total': 0.06685319542884827, 'train_loss_total': 0.06685319542884827, 'train_grad_norm': 1.0216054916381836, 'epoch': 143}
0:01:02.741597 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:02.749083 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.274331 - iteration 0
0:01:03.495263 - vxvyvz tensor([[ 0.0151, -0.0382,  0.0186]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:03.496330 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:03.497328 - dR tensor([[[-0.7564,  0.6538,  0.0214],
         [-0.5911, -0.6691, -0.4504],
         [-0.2801, -0.3533,  0.8926]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:03.498157 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:03.501387 - k: tensor([[[-0.7564,  0.6538,  0.0214, -0.0100],
         [-0.5911, -0.6691, -0.4504,  0.0062],
         [-0.2801, -0.3533,  0.8926,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.502339 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.503783 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0056],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:03.504459 - k: tensor([0.0020], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.505080 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:03.505682 - k: tensor([0.0621], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0645]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:04.473372 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.474850 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0502],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.475479 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.476123 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.476765 - k: tensor([0.0473], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0492]
0:01:04.036670 - bracket_assembly_nut_noaug_coarse--206204
0:01:04.036866 - {'grad_norm': 0.9300926923751831, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0557103157043457, 'time_backward': 0.07801175117492676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270318.5374122, 'n_iterations': 148, 'n_datas': 1184, 'train_loss_TCO-iter=1': 0.049168046563863754, 'train_loss_TCO': 0.049168046563863754, 'train_[loss_total': 0.049168046563863754, 'train_loss_total': 0.049168046563863754, 'train_grad_norm': 0.9300926923751831, 'epoch': 147}
0:01:04.036981 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.044383 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:04.569585 - iteration 0
0:01:04.790916 - vxvyvz tensor([[ 0.0120, -0.0440,  0.0014]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:04.791987 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:04.792995 - dR tensor([[[-0.7810,  0.6243,  0.0163],
         [-0.5602, -0.6888, -0.4601],
         [-0.2760, -0.3685,  0.8877]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:04.793821 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:04.797046 - k: tensor([[[-0.7810,  0.6243,  0.0163, -0.0100],
         [-0.5602, -0.6888, -0.4601,  0.0062],
         [-0.2760, -0.3685,  0.8877,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.797949 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:04.799477 - k: tensor([[[-7.8929e-01,  4.5115e-01,  4.1651e-01, -1.0004e-02],
         [-5.6879e-01, -7.9274e-01, -2.1920e-01,  6.1788e-03],
         [ 2.3129e-01, -4.0992e-01,  8.8231e-01,  4.1483e-04],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0', grad_fn=<CopySlices>)
0:01:04.800137 - k: tensor([0.0020], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.800778 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:04.801391 - k: tensor([0.0639], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0662]
0:01:04.352731 - bracket_assembly_nut_noaug_coarse--206204
0:01:04.352938 - {'grad_norm': 1.0448153018951416, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05604100227355957, 'time_backward': 0.07776165008544922, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270318.86192, 'n_iterations': 149, 'n_datas': 1192, 'train_loss_TCO-iter=1': 0.06618756055831909, 'train_loss_TCO': 0.06618756055831909, 'train_[loss_total': 0.06618756055831909, 'train_loss_total': 0.06618756055831909, 'train_grad_norm': 1.0448153018951416, 'epoch': 148}
0:01:04.353045 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.360487 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:04.885705 - iteration 0
0:01:05.107020 - vxvyvz tensor([[ 0.0218, -0.0448,  0.0176]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:05.108056 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.109068 - dR tensor([[[-0.7958,  0.6049,  0.0274],
         [-0.5564, -0.7127, -0.4272],
         [-0.2389, -0.3552,  0.9037]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:05.109933 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:05.113147 - k: tensor([[[-0.7958,  0.6049,  0.0274, -0.0100],
         [-0.5564, -0.7127, -0.4272,  0.0062],
         [-0.2389, -0.3552,  0.9037,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.114642 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.115681 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0053],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.116310 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.116955 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.117559 - k: tensor([0.0622], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0644]
0:01:04.671340 - bracket_assembly_nut_noaug_coarse--206204
0:01:04.671557 - {'grad_norm': 1.041624665260315, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05612921714782715, 'time_backward': 0.0783078670501709, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270319.1785443, 'n_iterations': 150, 'n_datas': 1200, 'train_loss_TCO-iter=1': 0.0644429624080658, 'train_loss_TCO': 0.0644429624080658, 'train_[loss_total': 0.0644429624080658, 'train_loss_total': 0.0644429624080658, 'train_grad_norm': 1.041624665260315, 'epoch': 149}
0:01:04.671674 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.679132 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.204342 - iteration 0
0:01:05.425321 - vxvyvz tensor([[ 0.0171, -0.0491,  0.0338]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:05.426311 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.427293 - dR tensor([[[-0.7961,  0.6044,  0.0292],
         [-0.5515, -0.7048, -0.4463],
         [-0.2491, -0.3714,  0.8944]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:05.428158 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:05.431350 - k: tensor([[[-0.7961,  0.6044,  0.0292, -0.0100],
         [-0.5515, -0.7048, -0.4463,  0.0062],
         [-0.2491, -0.3714,  0.8944,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.432300 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.433760 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0101],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:05.434449 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.435055 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:05.435688 - k: tensor([0.0606], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0628]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:04.816043 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.341055 - iteration 0
0:01:05.555817 - vxvyvz tensor([[0.0227, 0.0038, 0.0079]], device='cuda:0')
0:01:05.556831 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.557751 - dR tensor([[[-0.7177, -0.1338,  0.6834],
         [-0.6244, -0.3106, -0.7166],
         [ 0.3082, -0.9411,  0.1394]]], device='cuda:0')
0:01:05.558573 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:05.561598 - k: tensor([[[-0.7177, -0.1338,  0.6834, -0.0100],
         [-0.6244, -0.3106, -0.7166,  0.0062],
         [ 0.3082, -0.9411,  0.1394,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.562501 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.563395 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0024],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:05.564045 - k: tensor([0.0036], device='cuda:0')
0:01:05.564680 - k: tensor([0.0003], device='cuda:0')
0:01:05.565297 - k: tensor([0.0632], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.58it/s]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:06.462390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.463305 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0044],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.463976 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.464636 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.465270 - k: tensor([0.0625], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0647]
0:01:06.035984 - bracket_assembly_nut_noaug_coarse--206204
0:01:06.036256 - {'grad_norm': 1.0278255939483643, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05687117576599121, 'time_backward': 0.0775301456451416, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270320.5254576, 'n_iterations': 154, 'n_datas': 1232, 'train_loss_TCO-iter=1': 0.06473858654499054, 'train_loss_TCO': 0.06473858654499054, 'train_[loss_total': 0.06473858654499054, 'train_loss_total': 0.06473858654499054, 'train_grad_norm': 1.0278255939483643, 'epoch': 153}
0:01:06.036494 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.044285 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.569637 - iteration 0
0:01:06.792155 - vxvyvz tensor([[ 0.0222, -0.0483,  0.0036]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:06.793219 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.794205 - dR tensor([[[-0.8037,  0.5924,  0.0559],
         [-0.5383, -0.6838, -0.4926],
         [-0.2536, -0.4260,  0.8685]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:06.795055 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:06.798845 - k: tensor([[[-0.8037,  0.5924,  0.0559, -0.0100],
         [-0.5383, -0.6838, -0.4926,  0.0062],
         [-0.2536, -0.4260,  0.8685,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.799881 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.800898 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0011],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:06.801544 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.802178 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:06.802799 - k: tensor([0.0636], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0659]
0:01:06.368120 - bracket_assembly_nut_noaug_coarse--206204
0:01:06.368404 - {'grad_norm': 1.0583088397979736, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057695865631103516, 'time_backward': 0.07743239402770996, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270320.8629882, 'n_iterations': 155, 'n_datas': 1240, 'train_loss_TCO-iter=1': 0.06586521118879318, 'train_loss_TCO': 0.06586521118879318, 'train_[loss_total': 0.06586521118879318, 'train_loss_total': 0.06586521118879318, 'train_grad_norm': 1.0583088397979736, 'epoch': 154}
0:01:06.368605 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.376277 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:06.901553 - iteration 0
0:01:07.123546 - vxvyvz tensor([[ 0.0186, -0.0543,  0.0027]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:07.124639 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.125621 - dR tensor([[[-0.7929,  0.6080,  0.0406],
         [-0.5605, -0.7016, -0.4400],
         [-0.2390, -0.3716,  0.8971]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:07.126559 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:07.130404 - k: tensor([[[-0.7929,  0.6080,  0.0406, -0.0100],
         [-0.5605, -0.7016, -0.4400,  0.0062],
         [-0.2390, -0.3716,  0.8971,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.131382 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.132318 - k: tensor([[[-7.8929e-01,  4.5115e-01,  4.1651e-01, -1.0004e-02],
         [-5.6879e-01, -7.9274e-01, -2.1920e-01,  6.1788e-03],
         [ 2.3129e-01, -4.0992e-01,  8.8231e-01,  7.9785e-04],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0', grad_fn=<CopySlices>)
0:01:07.132991 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.133654 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.134272 - k: tensor([0.0637], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0659]
0:01:06.704434 - bracket_assembly_nut_noaug_coarse--206204
0:01:06.704687 - {'grad_norm': 1.1230491399765015, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057126760482788086, 'time_backward': 0.07732009887695312, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270321.1943018, 'n_iterations': 156, 'n_datas': 1248, 'train_loss_TCO-iter=1': 0.06593691557645798, 'train_loss_TCO': 0.06593691557645798, 'train_[loss_total': 0.06593691557645798, 'train_loss_total': 0.06593691557645798, 'train_grad_norm': 1.1230491399765015, 'epoch': 155}
0:01:06.704812 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:06.712535 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.237818 - iteration 0
0:01:07.460474 - vxvyvz tensor([[ 0.0217, -0.0461, -0.0039]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:07.461522 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.462497 - dR tensor([[[-0.7874,  0.6153,  0.0381],
         [-0.5622, -0.6912, -0.4540],
         [-0.2530, -0.3789,  0.8902]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:07.463344 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:07.467190 - k: tensor([[[-0.7874,  0.6153,  0.0381, -0.0100],
         [-0.5622, -0.6912, -0.4540,  0.0062],
         [-0.2530, -0.3789,  0.8902,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.468264 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.469219 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823, -0.0012],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:07.469851 - k: tensor([0.0019], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.470474 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:07.471100 - k: tensor([0.0644], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.16it/s, loss=0.0666]
0:01:07.039670 - bracket_assembly_nut_noaug_coarse--206204
0:01:07.039907 - {'grad_norm': 0.9784078598022461, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05776262283325195, 'time_backward': 0.07803821563720703, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270321.5319774, 'n_iterations': 157, 'n_datas': 1256, 'train_loss_TCO-iter=1': 0.06663869321346283, 'train_loss_TCO': 0.06663869321346283, 'train_[loss_total': 0.06663869321346283, 'train_loss_total': 0.06663869321346283, 'train_grad_norm': 0.9784078598022461, 'epoch': 156}
0:01:07.040110 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:07.047616 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:07.572807 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0034],], device='cuda:0',,, loss=0.0762]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.459437 - k: tensor([0.0018], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.460084 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.460730 - k: tensor([0.0629], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.065]
0:01:08.023277 - bracket_assembly_nut_noaug_coarse--206204
0:01:08.023543 - {'grad_norm': 1.0497735738754272, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05614757537841797, 'time_backward': 0.07752656936645508, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270322.5208812, 'n_iterations': 160, 'n_datas': 1280, 'train_loss_TCO-iter=1': 0.06503012031316757, 'train_loss_TCO': 0.06503012031316757, 'train_[loss_total': 0.06503012031316757, 'train_loss_total': 0.06503012031316757, 'train_grad_norm': 1.0497735738754272, 'epoch': 159}
0:01:08.023667 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.031044 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:08.556221 - iteration 0
0:01:08.777624 - vxvyvz tensor([[ 0.0252, -0.0614,  0.0654]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:08.778725 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:08.779716 - dR tensor([[[-0.8112,  0.5834,  0.0395],
         [-0.5474, -0.7340, -0.4020],
         [-0.2055, -0.3477,  0.9148]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:08.780594 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:08.783791 - k: tensor([[[-0.8112,  0.5834,  0.0395, -0.0100],
         [-0.5474, -0.7340, -0.4020,  0.0062],
         [-0.2055, -0.3477,  0.9148,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.784831 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.785730 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0196],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:08.786818 - k: tensor([0.0017], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.787484 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:08.788136 - k: tensor([0.0575], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0595]
0:01:08.351645 - bracket_assembly_nut_noaug_coarse--206204
0:01:08.351895 - {'grad_norm': 1.167447805404663, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05610203742980957, 'time_backward': 0.07766604423522949, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270322.8485427, 'n_iterations': 161, 'n_datas': 1288, 'train_loss_TCO-iter=1': 0.059516627341508865, 'train_loss_TCO': 0.059516627341508865, 'train_[loss_total': 0.059516627341508865, 'train_loss_total': 0.059516627341508865, 'train_grad_norm': 1.167447805404663, 'epoch': 160}
0:01:08.352036 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.359751 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:08.884978 - iteration 0
0:01:09.106726 - vxvyvz tensor([[ 0.0226, -0.0590,  0.0262]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:09.107821 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.108840 - dR tensor([[[-0.8171,  0.5739,  0.0549],
         [-0.5420, -0.7323, -0.4123],
         [-0.1964, -0.3667,  0.9094]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:09.109686 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:09.112931 - k: tensor([[[-0.8171,  0.5739,  0.0549, -0.0100],
         [-0.5420, -0.7323, -0.4123,  0.0062],
         [-0.1964, -0.3667,  0.9094,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.114377 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.115389 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0079],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.116043 - k: tensor([0.0017], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.116693 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.117310 - k: tensor([0.0614], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0634]
0:01:08.684979 - bracket_assembly_nut_noaug_coarse--206204
0:01:08.685226 - {'grad_norm': 1.0879154205322266, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05661344528198242, 'time_backward': 0.07762503623962402, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270323.177595, 'n_iterations': 162, 'n_datas': 1296, 'train_loss_TCO-iter=1': 0.06339820474386215, 'train_loss_TCO': 0.06339820474386215, 'train_[loss_total': 0.06339820474386215, 'train_loss_total': 0.06339820474386215, 'train_grad_norm': 1.0879154205322266, 'epoch': 161}
0:01:08.685421 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:08.692914 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.218110 - iteration 0
0:01:09.439454 - vxvyvz tensor([[ 0.0218, -0.0544,  0.1220]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:09.440583 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.441556 - dR tensor([[[-0.7859,  0.5993,  0.1525],
         [-0.5994, -0.6776, -0.4261],
         [-0.1520, -0.4263,  0.8917]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:09.442384 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:09.445635 - k: tensor([[[-0.7859,  0.5993,  0.1525, -0.0100],
         [-0.5994, -0.6776, -0.4261,  0.0062],
         [-0.1520, -0.4263,  0.8917,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.447116 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.448173 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0366],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.448831 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.449453 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.450086 - k: tensor([0.0518], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0537]
0:01:09.012845 - bracket_assembly_nut_noaug_coarse--206204
0:01:09.013083 - {'grad_norm': 1.0941495895385742, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056229352951049805, 'time_backward': 0.07804179191589355, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270323.5107975, 'n_iterations': 163, 'n_datas': 1304, 'train_loss_TCO-iter=1': 0.05367042124271393, 'train_loss_TCO': 0.05367042124271393, 'train_[loss_total': 0.05367042124271393, 'train_loss_total': 0.05367042124271393, 'train_grad_norm': 1.0941495895385742, 'epoch': 162}
0:01:09.013206 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:09.020644 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.545841 - iteration 0
0:01:09.767239 - vxvyvz tensor([[ 0.0226, -0.0607,  0.0025]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:09.768343 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:09.769353 - dR tensor([[[-0.8098,  0.5839,  0.0570],
         [-0.5447, -0.7122, -0.4428],
         [-0.2180, -0.3896,  0.8948]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:09.770267 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:09.773558 - k: tensor([[[-0.8098,  0.5839,  0.0570, -0.0100],
         [-0.5447, -0.7122, -0.4428,  0.0062],
         [-0.2180, -0.3896,  0.8948,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.774992 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:09.775994 - k: tensor([[[-7.8929e-01,  4.5115e-01,  4.1651e-01, -1.0004e-02],
         [-5.6879e-01, -7.9274e-01, -2.1920e-01,  6.1788e-03],
         [ 2.3129e-01, -4.0992e-01,  8.8231e-01,  7.6406e-04],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0', grad_fn=<CopySlices>)
0:01:09.776656 - k: tensor([0.0018], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.777277 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:09.777884 - k: tensor([0.0637], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0659]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
       grad_fn=<CopySlices>)
0:01:10.765736 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.766722 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0086],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:10.767342 - k: tensor([0.0017], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.767989 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:10.768633 - k: tensor([0.0611], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0632]
0:01:10.333633 - bracket_assembly_nut_noaug_coarse--206204
0:01:10.333876 - {'grad_norm': 1.1006580591201782, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056337594985961914, 'time_backward': 0.07794499397277832, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270324.8292868, 'n_iterations': 167, 'n_datas': 1336, 'train_loss_TCO-iter=1': 0.06319895386695862, 'train_loss_TCO': 0.06319895386695862, 'train_[loss_total': 0.06319895386695862, 'train_loss_total': 0.06319895386695862, 'train_grad_norm': 1.1006580591201782, 'epoch': 166}
0:01:10.333990 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:10.341329 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:10.866529 - iteration 0
0:01:11.087929 - vxvyvz tensor([[ 0.0184, -0.0576,  0.2013]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:11.089013 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.090012 - dR tensor([[[-0.7921,  0.5815,  0.1854],
         [-0.6057, -0.7117, -0.3558],
         [-0.0749, -0.3942,  0.9160]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:11.090852 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:11.094088 - k: tensor([[[-0.7921,  0.5815,  0.1854, -0.0100],
         [-0.6057, -0.7117, -0.3558,  0.0062],
         [-0.0749, -0.3942,  0.9160,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.095540 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.096638 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0604],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.097285 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.097892 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.098497 - k: tensor([0.0439], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0454]
0:01:10.668967 - bracket_assembly_nut_noaug_coarse--206204
0:01:10.669194 - {'grad_norm': 1.032853126525879, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05622386932373047, 'time_backward': 0.0774850845336914, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270325.158683, 'n_iterations': 168, 'n_datas': 1344, 'train_loss_TCO-iter=1': 0.045425862073898315, 'train_loss_TCO': 0.045425862073898315, 'train_[loss_total': 0.045425862073898315, 'train_loss_total': 0.045425862073898315, 'train_grad_norm': 1.032853126525879, 'epoch': 167}
0:01:10.669312 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:10.676712 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.201928 - iteration 0
0:01:11.423246 - vxvyvz tensor([[ 0.0271, -0.0615,  0.0799]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:11.424369 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.425394 - dR tensor([[[-0.7843,  0.6074,  0.1267],
         [-0.5994, -0.6890, -0.4074],
         [-0.1601, -0.3954,  0.9044]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:11.426322 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:11.429627 - k: tensor([[[-0.7843,  0.6074,  0.1267, -0.0100],
         [-0.5994, -0.6890, -0.4074,  0.0062],
         [-0.1601, -0.3954,  0.9044,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.430631 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.431528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0240],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.432711 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.433429 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.434040 - k: tensor([0.0560], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0579]
0:01:10.997536 - bracket_assembly_nut_noaug_coarse--206204
0:01:10.997777 - {'grad_norm': 1.1095385551452637, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05639314651489258, 'time_backward': 0.0774998664855957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270325.4942536, 'n_iterations': 169, 'n_datas': 1352, 'train_loss_TCO-iter=1': 0.057887036353349686, 'train_loss_TCO': 0.057887036353349686, 'train_[loss_total': 0.057887036353349686, 'train_loss_total': 0.057887036353349686, 'train_grad_norm': 1.1095385551452637, 'epoch': 168}
0:01:10.997967 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:11.005448 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.530628 - iteration 0
0:01:11.752091 - vxvyvz tensor([[ 0.0334, -0.0642,  0.0326]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:11.753132 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:11.754089 - dR tensor([[[-0.7949,  0.6011,  0.0823],
         [-0.5736, -0.7003, -0.4248],
         [-0.1977, -0.3849,  0.9015]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:11.754991 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:11.758208 - k: tensor([[[-0.7949,  0.6011,  0.0823, -0.0100],
         [-0.5736, -0.7003, -0.4248,  0.0062],
         [-0.1977, -0.3849,  0.9015,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.759985 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.761029 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0098],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:11.761653 - k: tensor([0.0017], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.762265 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:11.762871 - k: tensor([0.0607], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0628]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:12.758597 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.759612 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0051],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:12.760245 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.760897 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:12.761503 - k: tensor([0.0623], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0643]
0:01:12.330505 - bracket_assembly_nut_noaug_coarse--206204
0:01:12.330745 - {'grad_norm': 1.0281248092651367, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05608844757080078, 'time_backward': 0.07715845108032227, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270326.82129, 'n_iterations': 173, 'n_datas': 1384, 'train_loss_TCO-iter=1': 0.06426995247602463, 'train_loss_TCO': 0.06426995247602463, 'train_[loss_total': 0.06426995247602463, 'train_loss_total': 0.06426995247602463, 'train_grad_norm': 1.0281248092651367, 'epoch': 172}
0:01:12.330870 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.338222 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:12.863401 - iteration 0
0:01:13.084759 - vxvyvz tensor([[ 0.0306, -0.0630,  0.0359]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.085899 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.086890 - dR tensor([[[-0.8057,  0.5837,  0.1010],
         [-0.5654, -0.7068, -0.4251],
         [-0.1767, -0.3996,  0.8995]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.087753 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.090969 - k: tensor([[[-0.8057,  0.5837,  0.1010, -0.0100],
         [-0.5654, -0.7068, -0.4251,  0.0062],
         [-0.1767, -0.3996,  0.8995,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.092475 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.093557 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0108],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.094176 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.094783 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.095388 - k: tensor([0.0604], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0623]
0:01:12.654635 - bracket_assembly_nut_noaug_coarse--206204
0:01:12.654883 - {'grad_norm': 1.0380598306655884, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05620741844177246, 'time_backward': 0.07706475257873535, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270327.155187, 'n_iterations': 174, 'n_datas': 1392, 'train_loss_TCO-iter=1': 0.06233593076467514, 'train_loss_TCO': 0.06233593076467514, 'train_[loss_total': 0.06233593076467514, 'train_loss_total': 0.06233593076467514, 'train_grad_norm': 1.0380598306655884, 'epoch': 173}
0:01:12.655003 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.662384 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.187638 - iteration 0
0:01:13.408759 - vxvyvz tensor([[ 0.0356, -0.0736,  0.0258]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.409771 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.410829 - dR tensor([[[-0.7989,  0.5959,  0.0812],
         [-0.5744, -0.7160, -0.3967],
         [-0.1783, -0.3636,  0.9143]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.411716 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.414914 - k: tensor([[[-0.7989,  0.5959,  0.0812, -0.0100],
         [-0.5744, -0.7160, -0.3967,  0.0062],
         [-0.1783, -0.3636,  0.9143,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.416466 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.417508 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0077],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.418129 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.418735 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.419340 - k: tensor([0.0614], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0634]
0:01:12.982392 - bracket_assembly_nut_noaug_coarse--206204
0:01:12.982635 - {'grad_norm': 1.112795352935791, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0559689998626709, 'time_backward': 0.07739090919494629, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270327.4794633, 'n_iterations': 175, 'n_datas': 1400, 'train_loss_TCO-iter=1': 0.06336913257837296, 'train_loss_TCO': 0.06336913257837296, 'train_[loss_total': 0.06336913257837296, 'train_loss_total': 0.06336913257837296, 'train_grad_norm': 1.112795352935791, 'epoch': 174}
0:01:12.982760 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:12.990183 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.515368 - iteration 0
0:01:13.737070 - vxvyvz tensor([[ 0.0385, -0.0721,  0.0631]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:13.738146 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:13.739116 - dR tensor([[[-0.8055,  0.5874,  0.0783],
         [-0.5653, -0.7221, -0.3988],
         [-0.1777, -0.3655,  0.9137]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:13.739991 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:13.743249 - k: tensor([[[-0.8055,  0.5874,  0.0783, -0.0100],
         [-0.5653, -0.7221, -0.3988,  0.0062],
         [-0.1777, -0.3655,  0.9137,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.744836 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.745862 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0189],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:13.746497 - k: tensor([0.0016], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.747116 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:13.747757 - k: tensor([0.0577], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0596]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:14.741728 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:14.743152 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0104],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:14.743886 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:14.744533 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:14.745161 - k: tensor([0.0605], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0623]
0:01:14.306992 - bracket_assembly_nut_noaug_coarse--206204
0:01:14.307263 - {'grad_norm': 1.0770385265350342, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056154489517211914, 'time_backward': 0.07829070091247559, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270328.8061109, 'n_iterations': 179, 'n_datas': 1432, 'train_loss_TCO-iter=1': 0.06233169883489609, 'train_loss_TCO': 0.06233169883489609, 'train_[loss_total': 0.06233169883489609, 'train_loss_total': 0.06233169883489609, 'train_grad_norm': 1.0770385265350342, 'epoch': 178}
0:01:14.307426 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:14.315154 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:14.840421 - iteration 0
0:01:15.061961 - vxvyvz tensor([[ 0.0401, -0.0726,  0.0310]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.063061 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.064102 - dR tensor([[[-0.8164,  0.5678,  0.1052],
         [-0.5595, -0.7329, -0.3870],
         [-0.1426, -0.3748,  0.9161]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.064984 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.068197 - k: tensor([[[-0.8164,  0.5678,  0.1052, -0.0100],
         [-0.5595, -0.7329, -0.3870,  0.0062],
         [-0.1426, -0.3748,  0.9161,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.069783 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.070690 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0093],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.071317 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.071966 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.072618 - k: tensor([0.0609], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0627]
0:01:14.671595 - bracket_assembly_nut_noaug_coarse--206204
0:01:14.671817 - {'grad_norm': 1.0905661582946777, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0565638542175293, 'time_backward': 0.07840776443481445, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270329.133916, 'n_iterations': 180, 'n_datas': 1440, 'train_loss_TCO-iter=1': 0.06267809122800827, 'train_loss_TCO': 0.06267809122800827, 'train_[loss_total': 0.06267809122800827, 'train_loss_total': 0.06267809122800827, 'train_grad_norm': 1.0905661582946777, 'epoch': 179}
0:01:14.671946 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:14.679269 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.204535 - iteration 0
0:01:15.426247 - vxvyvz tensor([[ 0.0464, -0.0687,  0.0256]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.427253 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.428266 - dR tensor([[[-0.8159,  0.5653,  0.1212],
         [-0.5579, -0.7150, -0.4213],
         [-0.1515, -0.4114,  0.8988]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.429169 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.432437 - k: tensor([[[-0.8159,  0.5653,  0.1212, -0.0100],
         [-0.5579, -0.7150, -0.4213,  0.0062],
         [-0.1515, -0.4114,  0.8988,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.433920 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.434973 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0077],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.435624 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.436251 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.436894 - k: tensor([0.0614], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0633]
0:01:15.000736 - bracket_assembly_nut_noaug_coarse--206204
0:01:15.000962 - {'grad_norm': 1.0469591617584229, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056589365005493164, 'time_backward': 0.07788205146789551, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270329.498901, 'n_iterations': 181, 'n_datas': 1448, 'train_loss_TCO-iter=1': 0.06328801810741425, 'train_loss_TCO': 0.06328801810741425, 'train_[loss_total': 0.06328801810741425, 'train_loss_total': 0.06328801810741425, 'train_grad_norm': 1.0469591617584229, 'epoch': 180}
0:01:15.001087 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:15.008529 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.533706 - iteration 0
0:01:15.755523 - vxvyvz tensor([[ 0.0390, -0.0688,  0.0428]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:15.756665 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:15.757651 - dR tensor([[[-0.8203,  0.5592,  0.1199],
         [-0.5579, -0.7361, -0.3834],
         [-0.1261, -0.3814,  0.9158]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:15.758568 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:15.761815 - k: tensor([[[-0.8203,  0.5592,  0.1199, -0.0100],
         [-0.5579, -0.7361, -0.3834,  0.0062],
         [-0.1261, -0.3814,  0.9158,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.763365 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.764372 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0128],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:15.765038 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.765671 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:15.766278 - k: tensor([0.0597], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0615]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',,, loss=0.0762]
0:01:16.712874 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:16.714400 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0078],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:16.715028 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:16.715708 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:16.716331 - k: tensor([0.0614], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0632]
0:01:16.280661 - bracket_assembly_nut_noaug_coarse--206204
0:01:16.280894 - {'grad_norm': 1.01591956615448, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0560297966003418, 'time_backward': 0.07749247550964355, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270330.7765996, 'n_iterations': 185, 'n_datas': 1480, 'train_loss_TCO-iter=1': 0.06322362273931503, 'train_loss_TCO': 0.06322362273931503, 'train_[loss_total': 0.06322362273931503, 'train_loss_total': 0.06322362273931503, 'train_grad_norm': 1.01591956615448, 'epoch': 184}
0:01:16.281076 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:16.288558 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:16.813735 - iteration 0
0:01:17.035412 - vxvyvz tensor([[ 0.0420, -0.0729,  0.0622]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.036478 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.037454 - dR tensor([[[-0.8200,  0.5540,  0.1438],
         [-0.5613, -0.7291, -0.3916],
         [-0.1121, -0.4018,  0.9088]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.038287 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.041545 - k: tensor([[[-0.8200,  0.5540,  0.1438, -0.0100],
         [-0.5613, -0.7291, -0.3916,  0.0062],
         [-0.1121, -0.4018,  0.9088,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.043038 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.044194 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0187],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.044854 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.045478 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.046096 - k: tensor([0.0578], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0595]
0:01:16.619513 - bracket_assembly_nut_noaug_coarse--206204
0:01:16.619747 - {'grad_norm': 1.0483744144439697, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05660724639892578, 'time_backward': 0.07764554023742676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270331.1064172, 'n_iterations': 186, 'n_datas': 1488, 'train_loss_TCO-iter=1': 0.059464626014232635, 'train_loss_TCO': 0.059464626014232635, 'train_[loss_total': 0.059464626014232635, 'train_loss_total': 0.059464626014232635, 'train_grad_norm': 1.0483744144439697, 'epoch': 185}
0:01:16.619874 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:16.627251 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.152464 - iteration 0
0:01:17.373801 - vxvyvz tensor([[ 0.0513, -0.0767,  0.0655]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.374940 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.375936 - dR tensor([[[-0.8116,  0.5568,  0.1768],
         [-0.5744, -0.7055, -0.4150],
         [-0.1063, -0.4384,  0.8925]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.376843 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.380029 - k: tensor([[[-0.8116,  0.5568,  0.1768, -0.0100],
         [-0.5744, -0.7055, -0.4150,  0.0062],
         [-0.1063, -0.4384,  0.8925,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.381082 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.382560 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0196],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.383216 - k: tensor([0.0014], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.383865 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.384515 - k: tensor([0.0574], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0591]
0:01:16.952492 - bracket_assembly_nut_noaug_coarse--206204
0:01:16.952731 - {'grad_norm': 1.0322179794311523, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056243896484375, 'time_backward': 0.07732176780700684, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270331.4445472, 'n_iterations': 187, 'n_datas': 1496, 'train_loss_TCO-iter=1': 0.05914158374071121, 'train_loss_TCO': 0.05914158374071121, 'train_[loss_total': 0.05914158374071121, 'train_loss_total': 0.05914158374071121, 'train_grad_norm': 1.0322179794311523, 'epoch': 186}
0:01:16.952923 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:16.960557 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.485717 - iteration 0
0:01:17.707103 - vxvyvz tensor([[ 0.0412, -0.0785,  0.0439]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:17.708227 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.709237 - dR tensor([[[-0.8102,  0.5734,  0.1213],
         [-0.5680, -0.7172, -0.4037],
         [-0.1445, -0.3960,  0.9068]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:17.710070 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:17.713320 - k: tensor([[[-0.8102,  0.5734,  0.1213, -0.0100],
         [-0.5680, -0.7172, -0.4037,  0.0062],
         [-0.1445, -0.3960,  0.9068,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.714736 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.715754 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0132],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:17.716386 - k: tensor([0.0015], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.717034 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:17.717644 - k: tensor([0.0596], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0614]
0:01:17.280704 - bracket_assembly_nut_noaug_coarse--206204
0:01:17.280938 - {'grad_norm': 1.0399625301361084, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056138038635253906, 'time_backward': 0.0775148868560791, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270331.777863, 'n_iterations': 188, 'n_datas': 1504, 'train_loss_TCO-iter=1': 0.061408497393131256, 'train_loss_TCO': 0.061408497393131256, 'train_[loss_total': 0.061408497393131256, 'train_loss_total': 0.061408497393131256, 'train_grad_norm': 1.0399625301361084, 'epoch': 187}
0:01:17.281060 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:17.288497 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:17.813721 - iteration 0
0:01:18.034887 - vxvyvz tensor([[ 0.0411, -0.0751,  0.1631]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:18.035999 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:18.037014 - dR tensor([[[-0.7952,  0.5640,  0.2226],
         [-0.6045, -0.7088, -0.3637],
         [-0.0474, -0.4237,  0.9045]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:18.037846 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
         [ 0.0000,  1.0000,  0.0000,  0.0103],], device='cuda:0',,, loss=0.0762]
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:18.807649 - iteration 0
0:01:19.029988 - vxvyvz tensor([[ 0.0477, -0.0798,  0.0635]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:19.031076 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.032090 - dR tensor([[[-0.8126,  0.5614,  0.1567],
         [-0.5761, -0.7327, -0.3622],
         [-0.0885, -0.3846,  0.9188]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:19.032974 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:19.036192 - k: tensor([[[-0.8126,  0.5614,  0.1567, -0.0100],
         [-0.5761, -0.7327, -0.3622,  0.0062],
         [-0.0885, -0.3846,  0.9188,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.037673 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.038647 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0191],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.039266 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.039910 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.040560 - k: tensor([0.0576], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0592]
0:01:18.607486 - bracket_assembly_nut_noaug_coarse--206204
0:01:18.607722 - {'grad_norm': 1.108219027519226, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057151079177856445, 'time_backward': 0.0773162841796875, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270333.1005733, 'n_iterations': 192, 'n_datas': 1536, 'train_loss_TCO-iter=1': 0.05921870470046997, 'train_loss_TCO': 0.05921870470046997, 'train_[loss_total': 0.05921870470046997, 'train_loss_total': 0.05921870470046997, 'train_grad_norm': 1.108219027519226, 'epoch': 191}
0:01:18.607849 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:18.615287 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.140492 - iteration 0
0:01:19.361961 - vxvyvz tensor([[ 0.0535, -0.0822,  0.0432]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:19.363003 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:19.364021 - dR tensor([[[-0.8324,  0.5295,  0.1634],
         [-0.5487, -0.7463, -0.3768],
         [-0.0776, -0.4033,  0.9118]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:19.364905 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:19.368124 - k: tensor([[[-0.8324,  0.5295,  0.1634, -0.0100],
         [-0.5487, -0.7463, -0.3768,  0.0062],
         [-0.0776, -0.4033,  0.9118,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.369162 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.370565 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0130],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:19.371266 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.371914 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:19.372610 - k: tensor([0.0597], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0612]
       grad_fn=<CopySlices>) 0.0000,  0.0103],], device='cuda:0',,, loss=0.0762]
0:01:20.365310 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.366313 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0695],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.366935 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.367554 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.368194 - k: tensor([0.0408], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.042]
0:01:19.936557 - bracket_assembly_nut_noaug_coarse--206204
0:01:19.936810 - {'grad_norm': 1.092208743095398, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05617237091064453, 'time_backward': 0.07784438133239746, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270334.4286869, 'n_iterations': 196, 'n_datas': 1568, 'train_loss_TCO-iter=1': 0.042009588330984116, 'train_loss_TCO': 0.042009588330984116, 'train_[loss_total': 0.042009588330984116, 'train_loss_total': 0.042009588330984116, 'train_grad_norm': 1.092208743095398, 'epoch': 195}
0:01:19.937002 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:19.944475 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:20.469619 - iteration 0
0:01:20.691896 - vxvyvz tensor([[ 0.0459, -0.0836,  0.1304]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:20.692951 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:20.693903 - dR tensor([[[-0.7906,  0.5816,  0.1916],
         [-0.6106, -0.7245, -0.3197],
         [-0.0472, -0.3698,  0.9279]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:20.694738 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:20.697986 - k: tensor([[[-0.7906,  0.5816,  0.1916, -0.0100],
         [-0.6106, -0.7245, -0.3197,  0.0062],
         [-0.0472, -0.3698,  0.9279,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.699527 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.700551 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0391],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:20.701208 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.701851 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:20.702461 - k: tensor([0.0509], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0524]
0:01:20.374332 - bracket_assembly_nut_noaug_coarse--206204
0:01:20.374588 - {'grad_norm': 1.0870672464370728, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05699038505554199, 'time_backward': 0.07820820808410645, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270334.7632983, 'n_iterations': 197, 'n_datas': 1576, 'train_loss_TCO-iter=1': 0.05240960419178009, 'train_loss_TCO': 0.05240960419178009, 'train_[loss_total': 0.05240960419178009, 'train_loss_total': 0.05240960419178009, 'train_grad_norm': 1.0870672464370728, 'epoch': 196}
0:01:20.374722 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:20.382267 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:20.907486 - iteration 0
0:01:21.129043 - vxvyvz tensor([[ 0.0415, -0.0812,  0.2378]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:21.130048 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.131004 - dR tensor([[[-0.7960,  0.5474,  0.2584],
         [-0.6041, -0.7450, -0.2828],
         [ 0.0377, -0.3812,  0.9237]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:21.131927 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:21.135162 - k: tensor([[[-0.7960,  0.5474,  0.2584, -0.0100],
         [-0.6041, -0.7450, -0.2828,  0.0062],
         [ 0.0377, -0.3812,  0.9237,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.136665 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.137665 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0713],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.138361 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.138990 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.139650 - k: tensor([0.0402], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0413]
0:01:20.707870 - bracket_assembly_nut_noaug_coarse--206204
0:01:20.708110 - {'grad_norm': 1.0575412511825562, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05645632743835449, 'time_backward': 0.0778801441192627, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270335.2002878, 'n_iterations': 198, 'n_datas': 1584, 'train_loss_TCO-iter=1': 0.04134105145931244, 'train_loss_TCO': 0.04134105145931244, 'train_[loss_total': 0.04134105145931244, 'train_loss_total': 0.04134105145931244, 'train_grad_norm': 1.0575412511825562, 'epoch': 197}
0:01:20.708264 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:20.715656 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.240793 - iteration 0
0:01:21.462188 - vxvyvz tensor([[ 0.0510, -0.0833,  0.0448]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:21.463262 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:21.464275 - dR tensor([[[-0.8208,  0.5320,  0.2081],
         [-0.5680, -0.7217, -0.3956],
         [-0.0603, -0.4429,  0.8945]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:21.465152 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:21.468345 - k: tensor([[[-0.8208,  0.5320,  0.2081, -0.0100],
         [-0.5680, -0.7217, -0.3956,  0.0062],
         [-0.0603, -0.4429,  0.8945,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.469968 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.471029 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0134],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:21.471679 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.472299 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:21.472945 - k: tensor([0.0595], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.061]
         [-0.5688, -0.7927, -0.2192,  0.0062],], device='cuda:0',,, loss=0.0762]
         [ 0.2313, -0.4099,  0.8823,  0.0015],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.274007 - k: tensor([0.0030], device='cuda:0')
0:01:22.274611 - k: tensor([0.0003], device='cuda:0')
0:01:22.275213 - k: tensor([0.0635], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.46it/s]
0:01:21.762754 - bracket_assembly_nut_noaug_coarse--206204
0:01:21.762981 - {'grad_norm': 1.0658550262451172, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05611681938171387, 'time_backward': 0.07794857025146484, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270336.256786, 'n_iterations': 201, 'n_datas': 1608, 'train_loss_TCO-iter=1': 0.05547663941979408, 'train_loss_TCO': 0.05547663941979408, 'train_[loss_total': 0.05547663941979408, 'train_loss_total': 0.05547663941979408, 'train_grad_norm': 1.0658550262451172, 'val_loss_TCO-iter=1': 0.0667801946401596, 'val_loss_TCO': 0.0667801946401596, 'val_[loss_total': 0.0667801946401596, 'val_loss_total': 0.0667801946401596, 'epoch': 200}
0:01:21.763103 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:21.770635 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.292553 - iteration 0
0:01:22.513829 - vxvyvz tensor([[ 0.0584, -0.0851,  0.0423]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:22.514843 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.515838 - dR tensor([[[-0.8151,  0.5503,  0.1814],
         [-0.5770, -0.7428, -0.3395],
         [-0.0521, -0.3813,  0.9230]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:22.516724 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:22.519984 - k: tensor([[[-0.8151,  0.5503,  0.1814, -0.0100],
         [-0.5770, -0.7428, -0.3395,  0.0062],
         [-0.0521, -0.3813,  0.9230,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.520939 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.521832 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0127],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.522468 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.523092 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.523724 - k: tensor([0.0598], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.47it/s, loss=0.0612]
0:01:22.088735 - bracket_assembly_nut_noaug_coarse--206204
0:01:22.088930 - {'grad_norm': 1.0151126384735107, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05264139175415039, 'time_backward': 0.07739710807800293, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270336.5844145, 'n_iterations': 202, 'n_datas': 1616, 'train_loss_TCO-iter=1': 0.061215806752443314, 'train_loss_TCO': 0.061215806752443314, 'train_[loss_total': 0.061215806752443314, 'train_loss_total': 0.061215806752443314, 'train_grad_norm': 1.0151126384735107, 'epoch': 201}
0:01:22.089037 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.096489 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.621649 - iteration 0
0:01:22.842805 - vxvyvz tensor([[ 0.0575, -0.0905,  0.0904]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:22.843868 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.844884 - dR tensor([[[-0.8171,  0.5426,  0.1948],
         [-0.5741, -0.7349, -0.3610],
         [-0.0527, -0.4068,  0.9120]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:22.845717 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:22.849009 - k: tensor([[[-0.8171,  0.5426,  0.1948, -0.0100],
         [-0.5741, -0.7349, -0.3610,  0.0062],
         [-0.0527, -0.4068,  0.9120,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.849913 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.850813 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0271],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:22.851994 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.852703 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:22.853329 - k: tensor([0.0550], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0564]
0:01:22.414054 - bracket_assembly_nut_noaug_coarse--206204
0:01:22.414268 - {'grad_norm': 1.0817110538482666, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05586719512939453, 'time_backward': 0.07738065719604492, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270336.913338, 'n_iterations': 203, 'n_datas': 1624, 'train_loss_TCO-iter=1': 0.05639832094311714, 'train_loss_TCO': 0.05639832094311714, 'train_[loss_total': 0.05639832094311714, 'train_loss_total': 0.05639832094311714, 'train_grad_norm': 1.0817110538482666, 'epoch': 202}
0:01:22.414373 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.421688 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:22.946821 - iteration 0
0:01:23.168020 - vxvyvz tensor([[ 0.0592, -0.0870,  0.0832]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:23.169072 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.170085 - dR tensor([[[-0.8033,  0.5619,  0.1973],
         [-0.5933, -0.7259, -0.3481],
         [-0.0524, -0.3967,  0.9165]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:23.170941 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:23.174150 - k: tensor([[[-0.8033,  0.5619,  0.1973, -0.0100],
         [-0.5933, -0.7259, -0.3481,  0.0062],
         [-0.0524, -0.3967,  0.9165,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.175053 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.176649 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0250],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.177288 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.177899 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.178504 - k: tensor([0.0557], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0572]
0:01:22.738361 - bracket_assembly_nut_noaug_coarse--206204
0:01:22.738583 - {'grad_norm': 1.099414348602295, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05582618713378906, 'time_backward': 0.07776951789855957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270337.2389314, 'n_iterations': 204, 'n_datas': 1632, 'train_loss_TCO-iter=1': 0.05715050548315048, 'train_loss_TCO': 0.05715050548315048, 'train_[loss_total': 0.05715050548315048, 'train_loss_total': 0.05715050548315048, 'train_grad_norm': 1.099414348602295, 'epoch': 203}
0:01:22.738769 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:22.748065 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.275442 - iteration 0
0:01:23.506800 - vxvyvz tensor([[ 0.0540, -0.0919,  0.0501]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:23.508191 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:23.509482 - dR tensor([[[-0.8307,  0.5280,  0.1764],
         [-0.5524, -0.7422, -0.3795],
         [-0.0695, -0.4127,  0.9082]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:23.510519 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:23.514982 - k: tensor([[[-0.8307,  0.5280,  0.1764, -0.0100],
         [-0.5524, -0.7422, -0.3795,  0.0062],
         [-0.0695, -0.4127,  0.9082,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.516165 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.517350 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0150],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:23.518115 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.519058 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:23.519842 - k: tensor([0.0590], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, loss=0.0605]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',,, loss=0.0762]
0:01:24.504758 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.505673 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0168],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.506803 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.507549 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.508189 - k: tensor([0.0584], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0598]
0:01:24.070499 - bracket_assembly_nut_noaug_coarse--206204
0:01:24.070714 - {'grad_norm': 1.0702136754989624, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05609631538391113, 'time_backward': 0.07801938056945801, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270338.5688887, 'n_iterations': 208, 'n_datas': 1664, 'train_loss_TCO-iter=1': 0.05983763560652733, 'train_loss_TCO': 0.05983763560652733, 'train_[loss_total': 0.05983763560652733, 'train_loss_total': 0.05983763560652733, 'train_grad_norm': 1.0702136754989624, 'epoch': 207}
0:01:24.070898 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.078285 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.603495 - iteration 0
0:01:24.824915 - vxvyvz tensor([[ 0.0620, -0.0937,  0.0441]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:24.825912 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.826910 - dR tensor([[[-0.8324,  0.5239,  0.1806],
         [-0.5529, -0.7633, -0.3343],
         [-0.0373, -0.3781,  0.9250]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:24.827794 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:24.831016 - k: tensor([[[-0.8324,  0.5239,  0.1806, -0.0100],
         [-0.5529, -0.7633, -0.3343,  0.0062],
         [-0.0373, -0.3781,  0.9250,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.831961 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.833503 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0132],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:24.834125 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.834745 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:24.835352 - k: tensor([0.0596], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.061]
0:01:24.399644 - bracket_assembly_nut_noaug_coarse--206204
0:01:24.399840 - {'grad_norm': 0.962637186050415, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056099653244018555, 'time_backward': 0.07805585861206055, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270338.8961618, 'n_iterations': 209, 'n_datas': 1672, 'train_loss_TCO-iter=1': 0.06097591668367386, 'train_loss_TCO': 0.06097591668367386, 'train_[loss_total': 0.06097591668367386, 'train_loss_total': 0.06097591668367386, 'train_grad_norm': 0.962637186050415, 'epoch': 208}
0:01:24.399953 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.407346 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:24.932508 - iteration 0
0:01:25.153807 - vxvyvz tensor([[ 0.0615, -0.0974,  0.0454]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:25.154859 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.155884 - dR tensor([[[-0.8325,  0.5343,  0.1466],
         [-0.5522, -0.7786, -0.2979],
         [-0.0451, -0.3290,  0.9433]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:25.156760 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:25.159971 - k: tensor([[[-0.8325,  0.5343,  0.1466, -0.0100],
         [-0.5522, -0.7786, -0.2979,  0.0062],
         [-0.0451, -0.3290,  0.9433,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.160926 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.162285 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0136],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.162982 - k: tensor([0.0011], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.163632 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.164251 - k: tensor([0.0594], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0609]
0:01:24.762549 - bracket_assembly_nut_noaug_coarse--206204
0:01:24.762781 - {'grad_norm': 1.0098434686660767, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055907249450683594, 'time_backward': 0.07753729820251465, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270339.2245386, 'n_iterations': 210, 'n_datas': 1680, 'train_loss_TCO-iter=1': 0.0608929879963398, 'train_loss_TCO': 0.0608929879963398, 'train_[loss_total': 0.0608929879963398, 'train_loss_total': 0.0608929879963398, 'train_grad_norm': 1.0098434686660767, 'epoch': 209}
0:01:24.762902 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:24.770607 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.295908 - iteration 0
0:01:25.516940 - vxvyvz tensor([[ 0.0543, -0.0884,  0.2106]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:25.517991 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:25.518973 - dR tensor([[[-0.7948,  0.5412,  0.2747],
         [-0.6057, -0.7355, -0.3035],
         [ 0.0378, -0.4077,  0.9124]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:25.519844 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:25.523052 - k: tensor([[[-0.7948,  0.5412,  0.2747, -0.0100],
         [-0.6057, -0.7355, -0.3035,  0.0062],
         [ 0.0378, -0.4077,  0.9124,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.524001 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.525529 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0632],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:25.526151 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.526758 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:25.527403 - k: tensor([0.0429], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0441]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',,, loss=0.0762]
0:01:26.544159 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.545616 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0173],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.546322 - k: tensor([0.0012], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.546933 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.547550 - k: tensor([0.0582], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0598]
0:01:26.117392 - bracket_assembly_nut_noaug_coarse--206204
0:01:26.117599 - {'grad_norm': 1.0336650609970093, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05579662322998047, 'time_backward': 0.0773012638092041, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270340.607577, 'n_iterations': 214, 'n_datas': 1712, 'train_loss_TCO-iter=1': 0.0598025806248188, 'train_loss_TCO': 0.0598025806248188, 'train_[loss_total': 0.0598025806248188, 'train_loss_total': 0.0598025806248188, 'train_grad_norm': 1.0336650609970093, 'epoch': 213}
0:01:26.117720 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.125098 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.650276 - iteration 0
0:01:26.874368 - vxvyvz tensor([[ 0.0510, -0.0922,  0.2727]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:26.875393 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.876404 - dR tensor([[[-0.7973,  0.5152,  0.3143],
         [-0.5940, -0.7622, -0.2574],
         [ 0.1069, -0.3919,  0.9138]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:26.877289 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:26.880544 - k: tensor([[[-0.7973,  0.5152,  0.3143, -0.0100],
         [-0.5940, -0.7622, -0.2574,  0.0062],
         [ 0.1069, -0.3919,  0.9138,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.881463 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.882980 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0818],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:26.883684 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.884309 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:26.884947 - k: tensor([0.0367], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.08it/s, loss=0.0376]
0:01:26.452849 - bracket_assembly_nut_noaug_coarse--206204
0:01:26.453075 - {'grad_norm': 1.092108964920044, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05893373489379883, 'time_backward': 0.07863879203796387, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270340.9462805, 'n_iterations': 215, 'n_datas': 1720, 'train_loss_TCO-iter=1': 0.03758647292852402, 'train_loss_TCO': 0.03758647292852402, 'train_[loss_total': 0.03758647292852402, 'train_loss_total': 0.03758647292852402, 'train_grad_norm': 1.092108964920044, 'epoch': 214}
0:01:26.453187 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.460547 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:26.985727 - iteration 0
0:01:27.207270 - vxvyvz tensor([[ 0.0515, -0.0928,  0.2754]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:27.208312 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.209317 - dR tensor([[[-0.7972,  0.5132,  0.3178],
         [-0.5934, -0.7631, -0.2560],
         [ 0.1112, -0.3927,  0.9129]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:27.210184 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:27.213480 - k: tensor([[[-0.7972,  0.5132,  0.3178, -0.0100],
         [-0.5934, -0.7631, -0.2560,  0.0062],
         [ 0.1112, -0.3927,  0.9129,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.214390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.215281 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0826],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.216467 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.217189 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.217798 - k: tensor([0.0364], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0373]
0:01:26.790798 - bracket_assembly_nut_noaug_coarse--206204
0:01:26.791020 - {'grad_norm': 1.0706616640090942, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05629110336303711, 'time_backward': 0.07773590087890625, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270341.2782083, 'n_iterations': 216, 'n_datas': 1728, 'train_loss_TCO-iter=1': 0.03728155046701431, 'train_loss_TCO': 0.03728155046701431, 'train_[loss_total': 0.03728155046701431, 'train_loss_total': 0.03728155046701431, 'train_grad_norm': 1.0706616640090942, 'epoch': 215}
0:01:26.791196 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:26.800343 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.327670 - iteration 0
0:01:27.558841 - vxvyvz tensor([[ 0.0692, -0.0969,  0.1076]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:27.560232 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:27.561522 - dR tensor([[[-0.8077,  0.5393,  0.2381],
         [-0.5896, -0.7396, -0.3247],
         [ 0.0010, -0.4026,  0.9154]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:27.562569 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:27.566989 - k: tensor([[[-8.0772e-01,  5.3935e-01,  2.3809e-01, -1.0004e-02],
         [-5.8956e-01, -7.3958e-01, -3.2471e-01,  6.1788e-03],
         [ 9.5353e-04, -4.0264e-01,  9.1536e-01,  1.9197e-01],
         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]],
       device='cuda:0', grad_fn=<CopySlices>)
0:01:27.568185 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.569376 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0323],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:27.570137 - k: tensor([0.0009], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.571044 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:27.571839 - k: tensor([0.0532], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, loss=0.0545]
       grad_fn=<CopySlices>)-0.2192,  0.0062],], device='cuda:0',,, loss=0.0762]
0:01:28.552023 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.553054 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0453],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.553696 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.554307 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.554911 - k: tensor([0.0489], device='cuda:0', grad_fn=<MinBackward0>)
100%|██████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.05]
0:01:28.116436 - bracket_assembly_nut_noaug_coarse--206204
0:01:28.116646 - {'grad_norm': 1.2673124074935913, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056069135665893555, 'time_backward': 0.07735133171081543, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270342.614882, 'n_iterations': 220, 'n_datas': 1760, 'train_loss_TCO-iter=1': 0.05000157654285431, 'train_loss_TCO': 0.05000157654285431, 'train_[loss_total': 0.05000157654285431, 'train_loss_total': 0.05000157654285431, 'train_grad_norm': 1.2673124074935913, 'epoch': 219}
0:01:28.116762 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:28.125702 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:28.652895 - iteration 0
0:01:28.884094 - vxvyvz tensor([[ 0.0720, -0.1040,  0.0534]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:28.885446 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:28.886696 - dR tensor([[[-0.8324,  0.5126,  0.2108],
         [-0.5542, -0.7635, -0.3317],
         [-0.0091, -0.3929,  0.9195]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:28.887825 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:28.892254 - k: tensor([[[-0.8324,  0.5126,  0.2108, -0.0100],
         [-0.5542, -0.7635, -0.3317,  0.0062],
         [-0.0091, -0.3929,  0.9195,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.893445 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.894582 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0160],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:28.895340 - k: tensor([0.0010], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.896137 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:28.897185 - k: tensor([0.0587], device='cuda:0', grad_fn=<MinBackward0>)
100%|██████████████████████████████████| 1/1 [00:00<00:00,  6.50it/s, loss=0.06]
0:01:28.473460 - bracket_assembly_nut_noaug_coarse--206204
0:01:28.473698 - {'grad_norm': 1.1121113300323486, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07116007804870605, 'time_backward': 0.07803058624267578, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270342.9579136, 'n_iterations': 221, 'n_datas': 1768, 'train_loss_TCO-iter=1': 0.0599510632455349, 'train_loss_TCO': 0.0599510632455349, 'train_[loss_total': 0.0599510632455349, 'train_loss_total': 0.0599510632455349, 'train_grad_norm': 1.1121113300323486, 'epoch': 220}
0:01:28.473813 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:28.481304 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.006562 - iteration 0
0:01:29.228628 - vxvyvz tensor([[ 0.0750, -0.1007,  0.1105]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.229645 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.230608 - dR tensor([[[-0.8328,  0.5113,  0.2123],
         [-0.5536, -0.7705, -0.3159],
         [ 0.0021, -0.3807,  0.9247]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:29.231436 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:29.234681 - k: tensor([[[-0.8328,  0.5113,  0.2123, -0.0100],
         [-0.5536, -0.7705, -0.3159,  0.0062],
         [ 0.0021, -0.3807,  0.9247,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.235604 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.237132 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0332],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.237756 - k: tensor([0.0009], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.238366 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.238973 - k: tensor([0.0529], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0542]
0:01:28.797459 - bracket_assembly_nut_noaug_coarse--206204
0:01:28.797705 - {'grad_norm': 1.1127219200134277, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05679154396057129, 'time_backward': 0.0777585506439209, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270343.299557, 'n_iterations': 222, 'n_datas': 1776, 'train_loss_TCO-iter=1': 0.054180603474378586, 'train_loss_TCO': 0.054180603474378586, 'train_[loss_total': 0.054180603474378586, 'train_loss_total': 0.054180603474378586, 'train_grad_norm': 1.1127219200134277, 'epoch': 221}
0:01:28.797824 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:28.805434 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.330738 - iteration 0
0:01:29.554845 - vxvyvz tensor([[ 0.0802, -0.1053,  0.0649]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.555904 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.556925 - dR tensor([[[-0.8344,  0.5102,  0.2088],
         [-0.5505, -0.7523, -0.3620],
         [-0.0276, -0.4169,  0.9085]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:29.557755 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:29.560990 - k: tensor([[[-0.8344,  0.5102,  0.2088, -0.0100],
         [-0.5505, -0.7523, -0.3620,  0.0062],
         [-0.0276, -0.4169,  0.9085,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.561892 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.563354 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0195],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:29.564065 - k: tensor([0.0010], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.564718 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:29.565336 - k: tensor([0.0575], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.13it/s, loss=0.0589]
0:01:29.127634 - bracket_assembly_nut_noaug_coarse--206204
0:01:29.127834 - {'grad_norm': 1.0961155891418457, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05900835990905762, 'time_backward': 0.07746315002441406, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270343.6254575, 'n_iterations': 223, 'n_datas': 1784, 'train_loss_TCO-iter=1': 0.05887614190578461, 'train_loss_TCO': 0.05887614190578461, 'train_[loss_total': 0.05887614190578461, 'train_loss_total': 0.05887614190578461, 'train_grad_norm': 1.0961155891418457, 'epoch': 222}
0:01:29.127960 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:29.135557 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:29.660784 - iteration 0
0:01:29.882098 - vxvyvz tensor([[ 0.0729, -0.1064,  0.1247]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:29.883085 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0539]
0:01:30.157615 - bracket_assembly_nut_noaug_coarse--206204
0:01:30.157841 - {'grad_norm': 1.1016697883605957, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05603384971618652, 'time_backward': 0.0773458480834961, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270344.6213675, 'n_iterations': 226, 'n_datas': 1808, 'train_loss_TCO-iter=1': 0.053858742117881775, 'train_loss_TCO': 0.053858742117881775, 'train_[loss_total': 0.053858742117881775, 'train_loss_total': 0.053858742117881775, 'train_grad_norm': 1.1016697883605957, 'epoch': 225}
0:01:30.157962 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.165421 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:30.690640 - iteration 0
0:01:30.911847 - vxvyvz tensor([[ 0.0767, -0.1091,  0.0604]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:30.912895 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:30.913907 - dR tensor([[[-0.8258,  0.5180,  0.2228],
         [-0.5639, -0.7634, -0.3151],
         [ 0.0069, -0.3858,  0.9225]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:30.914740 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:30.917964 - k: tensor([[[-0.8258,  0.5180,  0.2228, -0.0100],
         [-0.5639, -0.7634, -0.3151,  0.0062],
         [ 0.0069, -0.3858,  0.9225,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:30.918872 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:30.920390 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0181],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:30.921050 - k: tensor([0.0009], device='cuda:0', grad_fn=<MinBackward0>)
0:01:30.921658 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:30.922266 - k: tensor([0.0579], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0592]
0:01:30.498307 - bracket_assembly_nut_noaug_coarse--206204
0:01:30.498523 - {'grad_norm': 1.0474625825881958, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055902957916259766, 'time_backward': 0.07735586166381836, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270344.9823015, 'n_iterations': 227, 'n_datas': 1816, 'train_loss_TCO-iter=1': 0.0591651126742363, 'train_loss_TCO': 0.0591651126742363, 'train_[loss_total': 0.0591651126742363, 'train_loss_total': 0.0591651126742363, 'train_grad_norm': 1.0474625825881958, 'epoch': 226}
0:01:30.498638 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.506143 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.031392 - iteration 0
0:01:31.252958 - vxvyvz tensor([[ 0.0749, -0.1050,  0.0629]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.253944 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.254891 - dR tensor([[[-0.8337,  0.5090,  0.2142],
         [-0.5522, -0.7706, -0.3182],
         [ 0.0031, -0.3836,  0.9235]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.255756 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.259019 - k: tensor([[[-0.8337,  0.5090,  0.2142, -0.0100],
         [-0.5522, -0.7706, -0.3182,  0.0062],
         [ 0.0031, -0.3836,  0.9235,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.260580 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.261527 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0189],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.262164 - k: tensor([0.0009], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.262774 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.263382 - k: tensor([0.0577], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0589]
0:01:30.839427 - bracket_assembly_nut_noaug_coarse--206204
0:01:30.839628 - {'grad_norm': 0.9724670648574829, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05632805824279785, 'time_backward': 0.07847404479980469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270345.3246124, 'n_iterations': 228, 'n_datas': 1824, 'train_loss_TCO-iter=1': 0.05893493816256523, 'train_loss_TCO': 0.05893493816256523, 'train_[loss_total': 0.05893493816256523, 'train_loss_total': 0.05893493816256523, 'train_grad_norm': 0.9724670648574829, 'epoch': 227}
0:01:30.839745 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:30.848680 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.376013 - iteration 0
0:01:31.607168 - vxvyvz tensor([[ 0.0608, -0.1009,  0.3030]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.608547 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.609795 - dR tensor([[[-0.7919,  0.4957,  0.3566],
         [-0.5880, -0.7766, -0.2262],
         [ 0.1648, -0.3888,  0.9065]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.610874 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.615307 - k: tensor([[[-0.7919,  0.4957,  0.3566, -0.0100],
         [-0.5880, -0.7766, -0.2262,  0.0062],
         [ 0.1648, -0.3888,  0.9065,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.616528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.617684 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0909],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.618446 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.619270 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.620207 - k: tensor([0.0337], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, loss=0.0343]
0:01:31.186519 - bracket_assembly_nut_noaug_coarse--206204
0:01:31.186740 - {'grad_norm': 0.9809775948524475, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07116818428039551, 'time_backward': 0.07810688018798828, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270345.6810215, 'n_iterations': 229, 'n_datas': 1832, 'train_loss_TCO-iter=1': 0.03433017432689667, 'train_loss_TCO': 0.03433017432689667, 'train_[loss_total': 0.03433017432689667, 'train_loss_total': 0.03433017432689667, 'train_grad_norm': 0.9809775948524475, 'epoch': 228}
0:01:31.186857 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:31.194266 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.719487 - iteration 0
0:01:31.940936 - vxvyvz tensor([[ 0.0899, -0.1048,  0.0679]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:31.941914 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:31.942888 - dR tensor([[[-0.8233,  0.5128,  0.2434],
         [-0.5670, -0.7643, -0.3072],
         [ 0.0285, -0.3909,  0.9200]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:31.943754 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:31.946961 - k: tensor([[[-0.8233,  0.5128,  0.2434, -0.0100],
         [-0.5670, -0.7643, -0.3072,  0.0062],
         [ 0.0285, -0.3909,  0.9200,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.948203 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.949474 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0204],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:31.950091 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.950701 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:31.951306 - k: tensor([0.0572], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0583]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:32.969567 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:32.970723 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0206],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:32.971481 - k: tensor([0.0009], device='cuda:0', grad_fn=<MinBackward0>)
0:01:32.972321 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:32.973320 - k: tensor([0.0571], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.49it/s, loss=0.0584]
0:01:32.544719 - bracket_assembly_nut_noaug_coarse--206204
0:01:32.544936 - {'grad_norm': 0.9882475137710571, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07105779647827148, 'time_backward': 0.07816410064697266, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270347.0341108, 'n_iterations': 233, 'n_datas': 1864, 'train_loss_TCO-iter=1': 0.058371786028146744, 'train_loss_TCO': 0.058371786028146744, 'train_[loss_total': 0.058371786028146744, 'train_loss_total': 0.058371786028146744, 'train_grad_norm': 0.9882475137710571, 'epoch': 232}
0:01:32.545072 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:32.552618 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.077805 - iteration 0
0:01:33.299316 - vxvyvz tensor([[ 0.0815, -0.1129,  0.0695]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.300368 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.301389 - dR tensor([[[-0.8337,  0.4964,  0.2420],
         [-0.5517, -0.7686, -0.3238],
         [ 0.0252, -0.4035,  0.9146]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.302215 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.305471 - k: tensor([[[-0.8337,  0.4964,  0.2420, -0.0100],
         [-0.5517, -0.7686, -0.3238,  0.0062],
         [ 0.0252, -0.4035,  0.9146,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.306371 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.307841 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0209],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.308500 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.309124 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.309729 - k: tensor([0.0570], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0582]
0:01:32.879478 - bracket_assembly_nut_noaug_coarse--206204
0:01:32.879678 - {'grad_norm': 1.0223290920257568, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05621194839477539, 'time_backward': 0.07736921310424805, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270347.369851, 'n_iterations': 234, 'n_datas': 1872, 'train_loss_TCO-iter=1': 0.0581946037709713, 'train_loss_TCO': 0.0581946037709713, 'train_[loss_total': 0.0581946037709713, 'train_loss_total': 0.0581946037709713, 'train_grad_norm': 1.0223290920257568, 'epoch': 233}
0:01:32.879799 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:32.887239 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.412440 - iteration 0
0:01:33.633793 - vxvyvz tensor([[ 0.0847, -0.1123,  0.0660]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.634805 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.635815 - dR tensor([[[-0.8344,  0.4934,  0.2457],
         [-0.5496, -0.7785, -0.3030],
         [ 0.0417, -0.3879,  0.9208]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.636706 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.639955 - k: tensor([[[-0.8344,  0.4934,  0.2457, -0.0100],
         [-0.5496, -0.7785, -0.3030,  0.0062],
         [ 0.0417, -0.3879,  0.9208,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.640910 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.642319 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0198],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.643035 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.643684 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.644305 - k: tensor([0.0574], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0585]
0:01:33.214618 - bracket_assembly_nut_noaug_coarse--206204
0:01:33.214816 - {'grad_norm': 0.9933536052703857, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05612373352050781, 'time_backward': 0.07755327224731445, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270347.704619, 'n_iterations': 235, 'n_datas': 1880, 'train_loss_TCO-iter=1': 0.05848868563771248, 'train_loss_TCO': 0.05848868563771248, 'train_[loss_total': 0.05848868563771248, 'train_loss_total': 0.05848868563771248, 'train_grad_norm': 0.9933536052703857, 'epoch': 234}
0:01:33.214986 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:33.222374 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.747586 - iteration 0
0:01:33.968877 - vxvyvz tensor([[ 0.0871, -0.1172,  0.0734]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:33.969871 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:33.970843 - dR tensor([[[-0.8307,  0.4983,  0.2483],
         [-0.5561, -0.7648, -0.3253],
         [ 0.0278, -0.4083,  0.9124]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:33.971718 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:33.974932 - k: tensor([[[-0.8307,  0.4983,  0.2483, -0.0100],
         [-0.5561, -0.7648, -0.3253,  0.0062],
         [ 0.0278, -0.4083,  0.9124,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.976397 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.977415 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0220],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:33.978058 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.978669 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:33.979276 - k: tensor([0.0566], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0578]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:34.960723 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:34.961853 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0960],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:34.962759 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:34.963471 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:34.964130 - k: tensor([0.0320], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0325]
0:01:34.518668 - bracket_assembly_nut_noaug_coarse--206204
0:01:34.518883 - {'grad_norm': 0.9680274128913879, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.059107065200805664, 'time_backward': 0.07775497436523438, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270349.0246632, 'n_iterations': 239, 'n_datas': 1912, 'train_loss_TCO-iter=1': 0.03251656889915466, 'train_loss_TCO': 0.03251656889915466, 'train_[loss_total': 0.03251656889915466, 'train_loss_total': 0.03251656889915466, 'train_grad_norm': 0.9680274128913879, 'epoch': 238}
0:01:34.518999 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:34.526471 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.051676 - iteration 0
0:01:35.272979 - vxvyvz tensor([[ 0.0927, -0.1173,  0.0813]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.273959 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.274919 - dR tensor([[[-0.8168,  0.5076,  0.2741],
         [-0.5723, -0.7729, -0.2741],
         [ 0.0727, -0.3807,  0.9218]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.275805 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.279012 - k: tensor([[[-0.8168,  0.5076,  0.2741, -0.0100],
         [-0.5723, -0.7729, -0.2741,  0.0062],
         [ 0.0727, -0.3807,  0.9218,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.279960 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.280904 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0244],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.281993 - k: tensor([0.0006], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.282692 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.283322 - k: tensor([0.0559], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0568]
0:01:34.881798 - bracket_assembly_nut_noaug_coarse--206204
0:01:34.882006 - {'grad_norm': 1.0397992134094238, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05587601661682129, 'time_backward': 0.07741403579711914, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270349.343424, 'n_iterations': 240, 'n_datas': 1920, 'train_loss_TCO-iter=1': 0.05681595578789711, 'train_loss_TCO': 0.05681595578789711, 'train_[loss_total': 0.05681595578789711, 'train_loss_total': 0.05681595578789711, 'train_grad_norm': 1.0397992134094238, 'epoch': 239}
0:01:34.882143 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:34.891320 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.418829 - iteration 0
0:01:35.649743 - vxvyvz tensor([[ 0.0900, -0.1145,  0.0796]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.651074 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.652371 - dR tensor([[[-0.8316,  0.4985,  0.2447],
         [-0.5550, -0.7621, -0.3334],
         [ 0.0202, -0.4131,  0.9105]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.653487 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.657902 - k: tensor([[[-0.8316,  0.4985,  0.2447, -0.0100],
         [-0.5550, -0.7621, -0.3334,  0.0062],
         [ 0.0202, -0.4131,  0.9105,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.659050 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.660246 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0239],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.661047 - k: tensor([0.0008], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.661934 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.662769 - k: tensor([0.0560], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, loss=0.0572]
0:01:35.228025 - bracket_assembly_nut_noaug_coarse--206204
0:01:35.228251 - {'grad_norm': 0.9930429458618164, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07103228569030762, 'time_backward': 0.07773375511169434, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270349.7248201, 'n_iterations': 241, 'n_datas': 1928, 'train_loss_TCO-iter=1': 0.057219114154577255, 'train_loss_TCO': 0.057219114154577255, 'train_[loss_total': 0.057219114154577255, 'train_loss_total': 0.057219114154577255, 'train_grad_norm': 0.9930429458618164, 'epoch': 240}
0:01:35.228378 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:35.235747 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.760876 - iteration 0
0:01:35.982029 - vxvyvz tensor([[ 0.0907, -0.1206,  0.0782]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:35.983044 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:35.984053 - dR tensor([[[-0.8270,  0.4997,  0.2577],
         [-0.5603, -0.7704, -0.3043],
         [ 0.0465, -0.3960,  0.9171]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:35.984936 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:35.988137 - k: tensor([[[-0.8270,  0.4997,  0.2577, -0.0100],
         [-0.5603, -0.7704, -0.3043,  0.0062],
         [ 0.0465, -0.3960,  0.9171,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.989092 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.990686 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0235],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:35.991309 - k: tensor([0.0007], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.991955 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:35.992603 - k: tensor([0.0562], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0572]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:37.002586 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.003764 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0235],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.004571 - k: tensor([0.0007], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.005337 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.006314 - k: tensor([0.0561], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.51it/s, loss=0.0572]
0:01:36.573516 - bracket_assembly_nut_noaug_coarse--206204
0:01:36.573729 - {'grad_norm': 1.029921531677246, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07106232643127441, 'time_backward': 0.07776784896850586, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270351.0668097, 'n_iterations': 245, 'n_datas': 1960, 'train_loss_TCO-iter=1': 0.05719364807009697, 'train_loss_TCO': 0.05719364807009697, 'train_[loss_total': 0.05719364807009697, 'train_loss_total': 0.05719364807009697, 'train_grad_norm': 1.029921531677246, 'epoch': 244}
0:01:36.573844 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:36.581182 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.106385 - iteration 0
0:01:37.327969 - vxvyvz tensor([[ 0.0889, -0.1254,  0.0767]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:37.329014 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.329976 - dR tensor([[[-0.8232,  0.5067,  0.2562],
         [-0.5655, -0.7723, -0.2894],
         [ 0.0512, -0.3831,  0.9223]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:37.330803 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:37.334075 - k: tensor([[[-0.8232,  0.5067,  0.2562, -0.0100],
         [-0.5655, -0.7723, -0.2894,  0.0062],
         [ 0.0512, -0.3831,  0.9223,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.335474 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.336557 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0230],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.337194 - k: tensor([0.0007], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.337803 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.338428 - k: tensor([0.0563], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0574]
0:01:36.913081 - bracket_assembly_nut_noaug_coarse--206204
0:01:36.913285 - {'grad_norm': 1.0252326726913452, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05631422996520996, 'time_backward': 0.07840752601623535, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270351.3995059, 'n_iterations': 246, 'n_datas': 1968, 'train_loss_TCO-iter=1': 0.0573648065328598, 'train_loss_TCO': 0.0573648065328598, 'train_[loss_total': 0.0573648065328598, 'train_loss_total': 0.0573648065328598, 'train_grad_norm': 1.0252326726913452, 'epoch': 245}
0:01:36.913403 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:36.920753 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.445920 - iteration 0
0:01:37.670051 - vxvyvz tensor([[ 0.0907, -0.1246,  0.0768]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:37.671068 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.672071 - dR tensor([[[-0.8317,  0.4895,  0.2618],
         [-0.5527, -0.7749, -0.3069],
         [ 0.0526, -0.3999,  0.9150]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:37.672965 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:37.676176 - k: tensor([[[-0.8317,  0.4895,  0.2618, -0.0100],
         [-0.5527, -0.7749, -0.3069,  0.0062],
         [ 0.0526, -0.3999,  0.9150,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.677145 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.678691 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0231],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:37.679311 - k: tensor([0.0007], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.679957 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:37.680601 - k: tensor([0.0563], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0574]
0:01:37.244899 - bracket_assembly_nut_noaug_coarse--206204
0:01:37.245115 - {'grad_norm': 1.0981080532073975, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05890512466430664, 'time_backward': 0.07818794250488281, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270351.7414236, 'n_iterations': 247, 'n_datas': 1976, 'train_loss_TCO-iter=1': 0.05735743045806885, 'train_loss_TCO': 0.05735743045806885, 'train_[loss_total': 0.05735743045806885, 'train_loss_total': 0.05735743045806885, 'train_grad_norm': 1.0981080532073975, 'epoch': 246}
0:01:37.245227 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:37.252623 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:37.777822 - iteration 0
0:01:37.999231 - vxvyvz tensor([[ 0.0952, -0.1247,  0.1171]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:38.000307 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:38.001314 - dR tensor([[[-0.8280,  0.4604,  0.3202],
         [-0.5518, -0.7706, -0.3189],
         [ 0.0999, -0.4407,  0.8921]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:38.002151 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:38.005405 - k: tensor([[[-0.8280,  0.4604,  0.3202, -0.0100],
         [-0.5518, -0.7706, -0.3189,  0.0062],
         [ 0.0999, -0.4407,  0.8921,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:38.006314 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:38.007209 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0351],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:38.008337 - k: tensor([0.0006], device='cuda:0', grad_fn=<MinBackward0>)
0:01:38.009056 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:38.009664 - k: tensor([0.0523], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0532]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:39.018816 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.020265 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0361],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.020993 - k: tensor([0.0006], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.021630 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.022233 - k: tensor([0.0519], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0529]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:38.403953 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:38.931301 - iteration 0
0:01:39.157103 - vxvyvz tensor([[ 0.0498, -0.0234,  0.0042]], device='cuda:0')
0:01:39.158317 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.159488 - dR tensor([[[-0.8030,  0.0643,  0.5925],
         [-0.5293, -0.5340, -0.6593],
         [ 0.2740, -0.8430,  0.4628]]], device='cuda:0')
0:01:39.160572 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.164328 - k: tensor([[[-0.8030,  0.0643,  0.5925, -0.0100],
         [-0.5293, -0.5340, -0.6593,  0.0062],
         [ 0.2740, -0.8430,  0.4628,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.165453 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.166524 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0013],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.167252 - k: tensor([0.0025], device='cuda:0')
0:01:39.168016 - k: tensor([0.0003], device='cuda:0')
0:01:39.168789 - k: tensor([0.0636], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 15.33it/s]
0:01:38.661705 - bracket_assembly_nut_noaug_coarse--206204
0:01:38.661912 - {'grad_norm': 1.1302886009216309, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056914567947387695, 'time_backward': 0.07811951637268066, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270353.1506217, 'n_iterations': 251, 'n_datas': 2008, 'train_loss_TCO-iter=1': 0.05286577716469765, 'train_loss_TCO': 0.05286577716469765, 'train_[loss_total': 0.05286577716469765, 'train_loss_total': 0.05286577716469765, 'train_grad_norm': 1.1302886009216309, 'val_loss_TCO-iter=1': 0.06641145050525665, 'val_loss_TCO': 0.06641145050525665, 'val_[loss_total': 0.06641145050525665, 'val_loss_total': 0.06641145050525665, 'epoch': 250}
0:01:38.662045 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:38.669504 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.191425 - iteration 0
0:01:39.416347 - vxvyvz tensor([[ 0.0981, -0.1294,  0.0786]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:39.417382 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.418347 - dR tensor([[[-0.8214,  0.4946,  0.2840],
         [-0.5653, -0.7720, -0.2907],
         [ 0.0755, -0.3993,  0.9137]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:39.419177 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.422426 - k: tensor([[[-0.8214,  0.4946,  0.2840, -0.0100],
         [-0.5653, -0.7720, -0.2907,  0.0062],
         [ 0.0755, -0.3993,  0.9137,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.423338 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.424273 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0236],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.424929 - k: tensor([0.0006], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.425541 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.426146 - k: tensor([0.0561], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0571]
0:01:38.993269 - bracket_assembly_nut_noaug_coarse--206204
0:01:38.993486 - {'grad_norm': 0.9886276125907898, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05574202537536621, 'time_backward': 0.07763409614562988, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270353.48672, 'n_iterations': 252, 'n_datas': 2016, 'train_loss_TCO-iter=1': 0.057085536420345306, 'train_loss_TCO': 0.057085536420345306, 'train_[loss_total': 0.057085536420345306, 'train_loss_total': 0.057085536420345306, 'train_grad_norm': 0.9886276125907898, 'epoch': 251}
0:01:38.993603 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:39.002617 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.529968 - iteration 0
0:01:39.761433 - vxvyvz tensor([[ 0.0857, -0.1192,  0.2645]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:39.762807 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.764071 - dR tensor([[[-0.7828,  0.4906,  0.3829],
         [-0.5941, -0.7721, -0.2255],
         [ 0.1850, -0.4040,  0.8959]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:39.765164 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:39.769675 - k: tensor([[[-0.7828,  0.4906,  0.3829, -0.0100],
         [-0.5941, -0.7721, -0.2255,  0.0062],
         [ 0.1850, -0.4040,  0.8959,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.770818 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.771990 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0793],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:39.772805 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.773691 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:39.774493 - k: tensor([0.0375], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.44it/s, loss=0.0381]
0:01:39.326333 - bracket_assembly_nut_noaug_coarse--206204
0:01:39.326526 - {'grad_norm': 1.157208800315857, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07142400741577148, 'time_backward': 0.07924723625183105, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270353.836311, 'n_iterations': 253, 'n_datas': 2024, 'train_loss_TCO-iter=1': 0.03812466561794281, 'train_loss_TCO': 0.03812466561794281, 'train_[loss_total': 0.03812466561794281, 'train_loss_total': 0.03812466561794281, 'train_grad_norm': 1.157208800315857, 'epoch': 252}
0:01:39.326697 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:39.334050 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:39.859238 - iteration 0
0:01:40.080692 - vxvyvz tensor([[ 0.0789, -0.1187,  0.3599]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:40.081729 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:40.082682 - dR tensor([[[-0.7842,  0.4571,  0.4195],
         [-0.5700, -0.7979, -0.1961],
         [ 0.2451, -0.3929,  0.8863]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:40.083534 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:40.086812 - k: tensor([[[-0.7842,  0.4571,  0.4195, -0.0100],
         [-0.5700, -0.7979, -0.1961,  0.0062],
         [ 0.2451, -0.3929,  0.8863,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:40.088272 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:40.089290 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1080],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:40.089936 - k: tensor([9.1890e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:40.090544 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:40.091148 - k: tensor([0.0280], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0284]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:41.069229 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.070399 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1105],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.071169 - k: tensor([6.7946e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.071960 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.072757 - k: tensor([0.0272], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  6.32it/s, loss=0.0276]
0:01:40.626082 - bracket_assembly_nut_noaug_coarse--206204
0:01:40.626301 - {'grad_norm': 0.888937771320343, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.07401084899902344, 'time_backward': 0.07946395874023438, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270355.1353142, 'n_iterations': 257, 'n_datas': 2056, 'train_loss_TCO-iter=1': 0.027568137273192406, 'train_loss_TCO': 0.027568137273192406, 'train_[loss_total': 0.027568137273192406, 'train_loss_total': 0.027568137273192406, 'train_grad_norm': 0.888937771320343, 'epoch': 256}
0:01:40.626415 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:40.633906 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.159190 - iteration 0
0:01:41.380636 - vxvyvz tensor([[ 0.0952, -0.1300,  0.1347]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:41.381662 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.382648 - dR tensor([[[-0.8282,  0.4656,  0.3120],
         [-0.5489, -0.7862, -0.2838],
         [ 0.1132, -0.4063,  0.9067]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:41.383481 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:41.386738 - k: tensor([[[-0.8282,  0.4656,  0.3120, -0.0100],
         [-0.5489, -0.7862, -0.2838,  0.0062],
         [ 0.1132, -0.4063,  0.9067,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.388183 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.389181 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0404],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.389800 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.390404 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.391006 - k: tensor([0.0505], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0513]
0:01:40.944453 - bracket_assembly_nut_noaug_coarse--206204
0:01:40.944670 - {'grad_norm': 1.0172903537750244, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05616903305053711, 'time_backward': 0.07773065567016602, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270355.4513261, 'n_iterations': 258, 'n_datas': 2064, 'train_loss_TCO-iter=1': 0.05134964734315872, 'train_loss_TCO': 0.05134964734315872, 'train_[loss_total': 0.05134964734315872, 'train_loss_total': 0.05134964734315872, 'train_grad_norm': 1.0172903537750244, 'epoch': 257}
0:01:40.944783 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:40.952337 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.477542 - iteration 0
0:01:41.698861 - vxvyvz tensor([[ 0.1098, -0.1350,  0.1150]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:41.699908 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.700919 - dR tensor([[[-0.8293,  0.4702,  0.3019],
         [-0.5510, -0.7784, -0.3010],
         [ 0.0935, -0.4160,  0.9046]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:41.701770 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:41.705026 - k: tensor([[[-0.8293,  0.4702,  0.3019, -0.0100],
         [-0.5510, -0.7784, -0.3010,  0.0062],
         [ 0.0935, -0.4160,  0.9046,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.705933 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.707345 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0345],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:41.708035 - k: tensor([0.0006], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.708707 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:41.709330 - k: tensor([0.0525], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0534]
0:01:41.267501 - bracket_assembly_nut_noaug_coarse--206204
0:01:41.267706 - {'grad_norm': 1.076900839805603, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05601811408996582, 'time_backward': 0.07835030555725098, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270355.7702875, 'n_iterations': 259, 'n_datas': 2072, 'train_loss_TCO-iter=1': 0.05338907986879349, 'train_loss_TCO': 0.05338907986879349, 'train_[loss_total': 0.05338907986879349, 'train_loss_total': 0.05338907986879349, 'train_grad_norm': 1.076900839805603, 'epoch': 258}
0:01:41.267821 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:41.275327 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:41.800527 - iteration 0
0:01:42.025077 - vxvyvz tensor([[ 0.1006, -0.1293,  0.1385]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:42.026073 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:42.027031 - dR tensor([[[-0.8006,  0.4951,  0.3376],
         [-0.5860, -0.7647, -0.2680],
         [ 0.1255, -0.4124,  0.9023]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:42.027908 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:42.031092 - k: tensor([[[-0.8006,  0.4951,  0.3376, -0.0100],
         [-0.5860, -0.7647, -0.2680,  0.0062],
         [ 0.1255, -0.4124,  0.9023,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:42.032040 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:42.033511 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0416],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:42.034224 - k: tensor([0.0004], device='cuda:0', grad_fn=<MinBackward0>)
0:01:42.034832 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:42.035439 - k: tensor([0.0501], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.09it/s, loss=0.0509]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:43.000150 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.001685 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0560],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.002301 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.002903 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.003515 - k: tensor([0.0453], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.046]
0:01:42.552548 - bracket_assembly_nut_noaug_coarse--206204
0:01:42.552770 - {'grad_norm': 1.178941011428833, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0559086799621582, 'time_backward': 0.07766962051391602, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270357.0638084, 'n_iterations': 263, 'n_datas': 2104, 'train_loss_TCO-iter=1': 0.045950133353471756, 'train_loss_TCO': 0.045950133353471756, 'train_[loss_total': 0.045950133353471756, 'train_loss_total': 0.045950133353471756, 'train_grad_norm': 1.178941011428833, 'epoch': 262}
0:01:42.552897 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:42.560338 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.085699 - iteration 0
0:01:43.306893 - vxvyvz tensor([[ 0.1096, -0.1369,  0.1077]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:43.307965 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.308988 - dR tensor([[[-0.8313,  0.4403,  0.3393],
         [-0.5427, -0.7748, -0.3242],
         [ 0.1202, -0.4537,  0.8830]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:43.309825 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:43.313043 - k: tensor([[[-0.8313,  0.4403,  0.3393, -0.0100],
         [-0.5427, -0.7748, -0.3242,  0.0062],
         [ 0.1202, -0.4537,  0.8830,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.313948 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.314890 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0323],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.315989 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.316736 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.317356 - k: tensor([0.0532], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0541]
0:01:42.872448 - bracket_assembly_nut_noaug_coarse--206204
0:01:42.872668 - {'grad_norm': 1.0443774461746216, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05610084533691406, 'time_backward': 0.07718849182128906, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270357.3771863, 'n_iterations': 264, 'n_datas': 2112, 'train_loss_TCO-iter=1': 0.05406973883509636, 'train_loss_TCO': 0.05406973883509636, 'train_[loss_total': 0.05406973883509636, 'train_loss_total': 0.05406973883509636, 'train_grad_norm': 1.0443774461746216, 'epoch': 263}
0:01:42.872796 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:42.880197 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.405399 - iteration 0
0:01:43.629561 - vxvyvz tensor([[ 0.1066, -0.1346,  0.0930]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:43.630582 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.631580 - dR tensor([[[-0.8275,  0.4664,  0.3125],
         [-0.5507, -0.7828, -0.2897],
         [ 0.1095, -0.4118,  0.9047]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:43.632456 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:43.635641 - k: tensor([[[-0.8275,  0.4664,  0.3125, -0.0100],
         [-0.5507, -0.7828, -0.2897,  0.0062],
         [ 0.1095, -0.4118,  0.9047,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.636579 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.637985 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0279],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.638704 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.639310 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.639952 - k: tensor([0.0547], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0555]
0:01:43.193635 - bracket_assembly_nut_noaug_coarse--206204
0:01:43.193853 - {'grad_norm': 0.9534060955047607, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0587916374206543, 'time_backward': 0.07744216918945312, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270357.7000306, 'n_iterations': 265, 'n_datas': 2120, 'train_loss_TCO-iter=1': 0.055525314062833786, 'train_loss_TCO': 0.055525314062833786, 'train_[loss_total': 0.055525314062833786, 'train_loss_total': 0.055525314062833786, 'train_grad_norm': 0.9534060955047607, 'epoch': 264}
0:01:43.193982 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:43.201403 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.726619 - iteration 0
0:01:43.947769 - vxvyvz tensor([[ 0.1124, -0.1346,  0.0867]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:43.948810 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:43.949762 - dR tensor([[[-0.8355,  0.4529,  0.3111],
         [-0.5368, -0.7935, -0.2866],
         [ 0.1171, -0.4064,  0.9062]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:43.950590 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:43.953848 - k: tensor([[[-0.8355,  0.4529,  0.3111, -0.0100],
         [-0.5368, -0.7935, -0.2866,  0.0062],
         [ 0.1171, -0.4064,  0.9062,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.954744 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.955671 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0260],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:43.956812 - k: tensor([0.0005], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.957527 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:43.958132 - k: tensor([0.0553], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0562]
0:01:43.520075 - bracket_assembly_nut_noaug_coarse--206204
0:01:43.520334 - {'grad_norm': 1.0772912502288818, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05580472946166992, 'time_backward': 0.07885241508483887, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270358.019884, 'n_iterations': 266, 'n_datas': 2128, 'train_loss_TCO-iter=1': 0.0561521016061306, 'train_loss_TCO': 0.0561521016061306, 'train_[loss_total': 0.0561521016061306, 'train_loss_total': 0.0561521016061306, 'train_grad_norm': 1.0772912502288818, 'epoch': 265}
0:01:43.520479 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:43.527889 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:44.053124 - iteration 0
0:01:44.274299 - vxvyvz tensor([[ 0.1144, -0.1386,  0.1048]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:44.275329 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:44.276324 - dR tensor([[[-0.8100,  0.4751,  0.3438],
         [-0.5709, -0.7731, -0.2765],
         [ 0.1344, -0.4202,  0.8974]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:44.277196 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:44.280361 - k: tensor([[[-0.8100,  0.4751,  0.3438, -0.0100],
         [-0.5709, -0.7731, -0.2765,  0.0062],
         [ 0.1344, -0.4202,  0.8974,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:44.281303 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:44.282709 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0314],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:44.283392 - k: tensor([0.0004], device='cuda:0', grad_fn=<MinBackward0>)
0:01:44.284026 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:44.284658 - k: tensor([0.0535], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0542]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:45.258349 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.259683 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0297],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.260316 - k: tensor([0.0004], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.260968 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.261572 - k: tensor([0.0541], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0549]
0:01:44.818497 - bracket_assembly_nut_noaug_coarse--206204
0:01:44.818713 - {'grad_norm': 1.006408929824829, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05643200874328613, 'time_backward': 0.07872676849365234, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270359.3230305, 'n_iterations': 270, 'n_datas': 2160, 'train_loss_TCO-iter=1': 0.05487939715385437, 'train_loss_TCO': 0.05487939715385437, 'train_[loss_total': 0.05487939715385437, 'train_loss_total': 0.05487939715385437, 'train_grad_norm': 1.006408929824829, 'epoch': 269}
0:01:44.818838 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:44.826307 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:45.351488 - iteration 0
0:01:45.572647 - vxvyvz tensor([[ 0.0985, -0.1318,  0.3008]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:45.573652 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:45.574600 - dR tensor([[[-0.7744,  0.4836,  0.4080],
         [-0.5959, -0.7741, -0.2135],
         [ 0.2126, -0.4085,  0.8877]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:45.575420 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:45.578670 - k: tensor([[[-0.7744,  0.4836,  0.4080, -0.0100],
         [-0.5959, -0.7741, -0.2135,  0.0062],
         [ 0.2126, -0.4085,  0.8877,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.579909 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.581170 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0902],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.581787 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.582389 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.582990 - k: tensor([0.0339], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0344]
0:01:45.143982 - bracket_assembly_nut_noaug_coarse--206204
0:01:45.144257 - {'grad_norm': 1.150627613067627, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05571866035461426, 'time_backward': 0.07848215103149414, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270359.6457214, 'n_iterations': 271, 'n_datas': 2168, 'train_loss_TCO-iter=1': 0.03442270681262016, 'train_loss_TCO': 0.03442270681262016, 'train_[loss_total': 0.03442270681262016, 'train_loss_total': 0.03442270681262016, 'train_grad_norm': 1.150627613067627, 'epoch': 270}
0:01:45.144419 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:45.151950 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:45.677186 - iteration 0
0:01:45.898820 - vxvyvz tensor([[ 0.1023, -0.1397,  0.1692]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:45.899857 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:45.900871 - dR tensor([[[-0.8129,  0.4682,  0.3464],
         [-0.5590, -0.7941, -0.2386],
         [ 0.1634, -0.3876,  0.9072]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:45.901699 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:45.904940 - k: tensor([[[-0.8129,  0.4682,  0.3464, -0.0100],
         [-0.5590, -0.7941, -0.2386,  0.0062],
         [ 0.1634, -0.3876,  0.9072,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.905837 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.907290 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0508],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:45.907948 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.908592 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:45.909248 - k: tensor([0.0471], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0477]
0:01:45.470697 - bracket_assembly_nut_noaug_coarse--206204
0:01:45.470910 - {'grad_norm': 1.0449227094650269, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05631399154663086, 'time_backward': 0.07839846611022949, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270359.9702382, 'n_iterations': 272, 'n_datas': 2176, 'train_loss_TCO-iter=1': 0.047691188752651215, 'train_loss_TCO': 0.047691188752651215, 'train_[loss_total': 0.047691188752651215, 'train_loss_total': 0.047691188752651215, 'train_grad_norm': 1.0449227094650269, 'epoch': 271}
0:01:45.471058 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:45.478458 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:46.003701 - iteration 0
0:01:46.228444 - vxvyvz tensor([[ 0.0911, -0.1341,  0.4079]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:46.229448 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:46.230394 - dR tensor([[[-0.7748,  0.4616,  0.4320],
         [-0.5788, -0.7928, -0.1909],
         [ 0.2544, -0.3980,  0.8814]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:46.231221 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:46.234443 - k: tensor([[[-0.7748,  0.4616,  0.4320, -0.0100],
         [-0.5788, -0.7928, -0.1909,  0.0062],
         [ 0.2544, -0.3980,  0.8814,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:46.235375 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:46.236866 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1224],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:46.237586 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:01:46.238195 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:46.238798 - k: tensor([0.0232], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.10it/s, loss=0.0237]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:47.199674 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.201156 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0536],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.201838 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.202442 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.203041 - k: tensor([0.0461], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, loss=0.0467]
0:01:46.760807 - bracket_assembly_nut_noaug_coarse--206204
0:01:46.761031 - {'grad_norm': 1.038941740989685, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05884957313537598, 'time_backward': 0.07762598991394043, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270361.263296, 'n_iterations': 276, 'n_datas': 2208, 'train_loss_TCO-iter=1': 0.04668673127889633, 'train_loss_TCO': 0.04668673127889633, 'train_[loss_total': 0.04668673127889633, 'train_loss_total': 0.04668673127889633, 'train_grad_norm': 1.038941740989685, 'epoch': 275}
0:01:46.761144 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:46.768620 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:47.293763 - iteration 0
0:01:47.515117 - vxvyvz tensor([[ 0.0941, -0.1374,  0.4177]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:47.516170 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:47.517166 - dR tensor([[[-0.7740,  0.4438,  0.4517],
         [-0.5775, -0.7872, -0.2161],
         [ 0.2597, -0.4282,  0.8656]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:47.517990 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:47.521193 - k: tensor([[[-0.7740,  0.4438,  0.4517, -0.0100],
         [-0.5775, -0.7872, -0.2161,  0.0062],
         [ 0.2597, -0.4282,  0.8656,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.522601 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.523670 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1253],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.524300 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.524942 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.525545 - k: tensor([0.0222], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0227]
0:01:47.087588 - bracket_assembly_nut_noaug_coarse--206204
0:01:47.087783 - {'grad_norm': 0.9430663585662842, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05594491958618164, 'time_backward': 0.07796955108642578, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270361.5860755, 'n_iterations': 277, 'n_datas': 2216, 'train_loss_TCO-iter=1': 0.022701110690832138, 'train_loss_TCO': 0.022701110690832138, 'train_[loss_total': 0.022701110690832138, 'train_loss_total': 0.022701110690832138, 'train_grad_norm': 0.9430663585662842, 'epoch': 276}
0:01:47.087912 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:47.095308 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:47.620488 - iteration 0
0:01:47.841600 - vxvyvz tensor([[ 0.1149, -0.1494,  0.2177]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:47.842636 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:47.843639 - dR tensor([[[-0.7953,  0.4718,  0.3808],
         [-0.5679, -0.7995, -0.1956],
         [ 0.2122, -0.3718,  0.9037]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:47.844507 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:47.847680 - k: tensor([[[-0.7953,  0.4718,  0.3808, -0.0100],
         [-0.5679, -0.7995, -0.1956,  0.0062],
         [ 0.2122, -0.3718,  0.9037,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.848618 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.849989 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0653],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:47.850760 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.851369 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:47.852007 - k: tensor([0.0422], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0427]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:48.814725 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:48.816165 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0429],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:48.816902 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:48.817512 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:48.818113 - k: tensor([0.0497], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.11it/s, loss=0.0504]
0:01:48.378416 - bracket_assembly_nut_noaug_coarse--206204
0:01:48.378657 - {'grad_norm': 1.055607557296753, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05887174606323242, 'time_backward': 0.07808566093444824, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270362.8788435, 'n_iterations': 281, 'n_datas': 2248, 'train_loss_TCO-iter=1': 0.05037990212440491, 'train_loss_TCO': 0.05037990212440491, 'train_[loss_total': 0.05037990212440491, 'train_loss_total': 0.05037990212440491, 'train_grad_norm': 1.055607557296753, 'epoch': 280}
0:01:48.378778 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:48.386451 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:48.911767 - iteration 0
0:01:49.133050 - vxvyvz tensor([[ 0.1207, -0.1462,  0.1388]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:49.134076 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:49.135044 - dR tensor([[[-0.8172,  0.4601,  0.3472],
         [-0.5509, -0.8005, -0.2360],
         [ 0.1693, -0.3841,  0.9076]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:49.135910 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:49.139084 - k: tensor([[[-0.8172,  0.4601,  0.3472, -0.0100],
         [-0.5509, -0.8005, -0.2360,  0.0062],
         [ 0.1693, -0.3841,  0.9076,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.140510 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.141604 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0416],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.142243 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.142849 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.143451 - k: tensor([0.0501], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0507]
0:01:48.736512 - bracket_assembly_nut_noaug_coarse--206204
0:01:48.736731 - {'grad_norm': 1.0753669738769531, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05610394477844238, 'time_backward': 0.07717037200927734, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270363.203341, 'n_iterations': 282, 'n_datas': 2256, 'train_loss_TCO-iter=1': 0.05072971433401108, 'train_loss_TCO': 0.05072971433401108, 'train_[loss_total': 0.05072971433401108, 'train_loss_total': 0.05072971433401108, 'train_grad_norm': 1.0753669738769531, 'epoch': 281}
0:01:48.736867 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:48.744219 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:49.269441 - iteration 0
0:01:49.490311 - vxvyvz tensor([[ 0.1267, -0.1532,  0.1159]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:49.491324 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:49.492333 - dR tensor([[[-0.8189,  0.4583,  0.3455],
         [-0.5483, -0.8025, -0.2352],
         [ 0.1695, -0.3821,  0.9085]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:49.493202 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:49.496455 - k: tensor([[[-0.8189,  0.4583,  0.3455, -0.0100],
         [-0.5483, -0.8025, -0.2352,  0.0062],
         [ 0.1695, -0.3821,  0.9085,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.497371 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.498785 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0348],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.499479 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.500126 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.500776 - k: tensor([0.0524], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.053]
0:01:49.158385 - bracket_assembly_nut_noaug_coarse--206204
0:01:49.158626 - {'grad_norm': 1.0485703945159912, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055541276931762695, 'time_backward': 0.07832026481628418, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270363.5618103, 'n_iterations': 283, 'n_datas': 2264, 'train_loss_TCO-iter=1': 0.05303265526890755, 'train_loss_TCO': 0.05303265526890755, 'train_[loss_total': 0.05303265526890755, 'train_loss_total': 0.05303265526890755, 'train_grad_norm': 1.0485703945159912, 'epoch': 282}
0:01:49.158750 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:49.166432 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:49.691658 - iteration 0
0:01:49.913262 - vxvyvz tensor([[ 0.0998, -0.1430,  0.4310]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:49.914261 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:49.915219 - dR tensor([[[-0.7729,  0.4382,  0.4589],
         [-0.5745, -0.7903, -0.2129],
         [ 0.2694, -0.4282,  0.8626]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:49.916106 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:49.919369 - k: tensor([[[-0.7729,  0.4382,  0.4589, -0.0100],
         [-0.5745, -0.7903, -0.2129,  0.0062],
         [ 0.2694, -0.4282,  0.8626,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.920919 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.921851 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1293],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:49.922464 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.923065 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:49.923708 - k: tensor([0.0209], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0214]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:01:50.922694 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:50.924192 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0500],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:50.924920 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:50.925527 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:50.926126 - k: tensor([0.0473], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0479]
0:01:50.497634 - bracket_assembly_nut_noaug_coarse--206204
0:01:50.497845 - {'grad_norm': 1.1295204162597656, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0559842586517334, 'time_backward': 0.0781087875366211, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270364.986892, 'n_iterations': 287, 'n_datas': 2296, 'train_loss_TCO-iter=1': 0.047902777791023254, 'train_loss_TCO': 0.047902777791023254, 'train_[loss_total': 0.047902777791023254, 'train_loss_total': 0.047902777791023254, 'train_grad_norm': 1.1295204162597656, 'epoch': 286}
0:01:50.497959 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:50.505467 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.030746 - iteration 0
0:01:51.252095 - vxvyvz tensor([[ 0.1189, -0.1507,  0.1625]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:51.253135 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.254146 - dR tensor([[[-0.8064,  0.4619,  0.3693],
         [-0.5613, -0.7943, -0.2323],
         [ 0.1860, -0.3946,  0.8998]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:51.254973 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:51.258169 - k: tensor([[[-0.8064,  0.4619,  0.3693, -0.0100],
         [-0.5613, -0.7943, -0.2323,  0.0062],
         [ 0.1860, -0.3946,  0.8998,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.259071 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.260607 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0488],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.261274 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.261879 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.262476 - k: tensor([0.0477], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0483]
0:01:50.834592 - bracket_assembly_nut_noaug_coarse--206204
0:01:50.834803 - {'grad_norm': 1.0400052070617676, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056101083755493164, 'time_backward': 0.07748556137084961, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270365.322611, 'n_iterations': 288, 'n_datas': 2304, 'train_loss_TCO-iter=1': 0.04826616868376732, 'train_loss_TCO': 0.04826616868376732, 'train_[loss_total': 0.04826616868376732, 'train_loss_total': 0.04826616868376732, 'train_grad_norm': 1.0400052070617676, 'epoch': 287}
0:01:50.834977 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:50.842359 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.367582 - iteration 0
0:01:51.591687 - vxvyvz tensor([[ 0.1221, -0.1572,  0.2483]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:51.592710 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.593678 - dR tensor([[[-0.7863,  0.4490,  0.4243],
         [-0.5696, -0.7929, -0.2164],
         [ 0.2393, -0.4119,  0.8793]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:51.594502 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:51.597731 - k: tensor([[[-0.7863,  0.4490,  0.4243, -0.0100],
         [-0.5696, -0.7929, -0.2164,  0.0062],
         [ 0.2393, -0.4119,  0.8793,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.598633 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.600047 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0745],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.600817 - k: tensor([3.3088e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.601424 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.602031 - k: tensor([0.0392], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0395]
0:01:51.171724 - bracket_assembly_nut_noaug_coarse--206204
0:01:51.171934 - {'grad_norm': 1.1092381477355957, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05864858627319336, 'time_backward': 0.07717132568359375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270365.6618779, 'n_iterations': 289, 'n_datas': 2312, 'train_loss_TCO-iter=1': 0.03953187167644501, 'train_loss_TCO': 0.03953187167644501, 'train_[loss_total': 0.03953187167644501, 'train_loss_total': 0.03953187167644501, 'train_grad_norm': 1.1092381477355957, 'epoch': 288}
0:01:51.172049 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:51.179440 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.704614 - iteration 0
0:01:51.925760 - vxvyvz tensor([[ 0.1039, -0.1477,  0.4411]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:51.926794 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:51.927786 - dR tensor([[[-0.7737,  0.4426,  0.4533],
         [-0.5715, -0.7965, -0.1976],
         [ 0.2736, -0.4119,  0.8692]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:51.928650 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:51.931825 - k: tensor([[[-0.7737,  0.4426,  0.4533, -0.0100],
         [-0.5715, -0.7965, -0.1976,  0.0062],
         [ 0.2736, -0.4119,  0.8692,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.932777 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.934159 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1323],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:51.934868 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.935476 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:51.936116 - k: tensor([0.0199], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0204]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:52.947472 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:52.948446 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0407],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:52.949076 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:52.949680 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:52.950306 - k: tensor([0.0504], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.051]
0:01:52.536776 - bracket_assembly_nut_noaug_coarse--206204
0:01:52.536975 - {'grad_norm': 1.0787800550460815, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0560755729675293, 'time_backward': 0.07705211639404297, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270367.0100296, 'n_iterations': 293, 'n_datas': 2344, 'train_loss_TCO-iter=1': 0.05103958025574684, 'train_loss_TCO': 0.05103958025574684, 'train_[loss_total': 0.05103958025574684, 'train_loss_total': 0.05103958025574684, 'train_grad_norm': 1.0787800550460815, 'epoch': 292}
0:01:52.537148 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:52.544578 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.069763 - iteration 0
0:01:53.291169 - vxvyvz tensor([[ 0.1128, -0.1497,  0.3165]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:53.292256 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.293257 - dR tensor([[[-0.7832,  0.4480,  0.4311],
         [-0.5733, -0.7888, -0.2218],
         [ 0.2406, -0.4209,  0.8746]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:53.294092 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:53.297314 - k: tensor([[[-0.7832,  0.4480,  0.4311, -0.0100],
         [-0.5733, -0.7888, -0.2218,  0.0062],
         [ 0.2406, -0.4209,  0.8746,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.298209 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.299750 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0949],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.300385 - k: tensor([6.3984e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.301029 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.301628 - k: tensor([0.0323], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0327]
0:01:52.866950 - bracket_assembly_nut_noaug_coarse--206204
0:01:52.867158 - {'grad_norm': 1.2790669202804565, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056096553802490234, 'time_backward': 0.07708239555358887, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270367.361336, 'n_iterations': 294, 'n_datas': 2352, 'train_loss_TCO-iter=1': 0.032741475850343704, 'train_loss_TCO': 0.032741475850343704, 'train_[loss_total': 0.032741475850343704, 'train_loss_total': 0.032741475850343704, 'train_grad_norm': 1.2790669202804565, 'epoch': 293}
0:01:52.867285 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:52.874635 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.399863 - iteration 0
0:01:53.621182 - vxvyvz tensor([[ 0.1337, -0.1663,  0.1153]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:53.622192 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.623150 - dR tensor([[[-0.8128,  0.4694,  0.3451],
         [-0.5574, -0.7988, -0.2264],
         [ 0.1694, -0.3763,  0.9109]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:53.624019 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:53.627183 - k: tensor([[[-0.8128,  0.4694,  0.3451, -0.0100],
         [-0.5574, -0.7988, -0.2264,  0.0062],
         [ 0.1694, -0.3763,  0.9109,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.628126 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.629705 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0346],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.630321 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.630923 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.631553 - k: tensor([0.0525], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0531]
0:01:53.193890 - bracket_assembly_nut_noaug_coarse--206204
0:01:53.194105 - {'grad_norm': 0.9646438956260681, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05587053298950195, 'time_backward': 0.07666683197021484, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270367.6908324, 'n_iterations': 295, 'n_datas': 2360, 'train_loss_TCO-iter=1': 0.05306880176067352, 'train_loss_TCO': 0.05306880176067352, 'train_[loss_total': 0.05306880176067352, 'train_loss_total': 0.05306880176067352, 'train_grad_norm': 0.9646438956260681, 'epoch': 294}
0:01:53.194283 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:53.201632 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.726870 - iteration 0
0:01:53.948086 - vxvyvz tensor([[ 0.1336, -0.1581,  0.1430]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:53.949119 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:53.950115 - dR tensor([[[-0.8054,  0.4394,  0.3978],
         [-0.5642, -0.7738, -0.2878],
         [ 0.1813, -0.4563,  0.8712]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:53.950968 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:53.954210 - k: tensor([[[-0.8054,  0.4394,  0.3978, -0.0100],
         [-0.5642, -0.7738, -0.2878,  0.0062],
         [ 0.1813, -0.4563,  0.8712,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.955104 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.956579 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0429],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:53.957301 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.957905 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:53.958505 - k: tensor([0.0497], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0503]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:54.945173 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:54.946637 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0447],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:54.947351 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:54.947995 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:54.948633 - k: tensor([0.0491], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0496]
0:01:54.514903 - bracket_assembly_nut_noaug_coarse--206204
0:01:54.515119 - {'grad_norm': 1.0779626369476318, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05600571632385254, 'time_backward': 0.07892012596130371, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270369.0102565, 'n_iterations': 299, 'n_datas': 2392, 'train_loss_TCO-iter=1': 0.0496474988758564, 'train_loss_TCO': 0.0496474988758564, 'train_[loss_total': 0.0496474988758564, 'train_loss_total': 0.0496474988758564, 'train_grad_norm': 1.0779626369476318, 'epoch': 298}
0:01:54.515233 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:54.522575 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.047823 - iteration 0
0:01:55.268956 - vxvyvz tensor([[ 0.1351, -0.1712,  0.1545]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:55.269983 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.270973 - dR tensor([[[-0.8021,  0.4497,  0.3931],
         [-0.5697, -0.7736, -0.2774],
         [ 0.1793, -0.4464,  0.8767]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:55.271846 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:55.275075 - k: tensor([[[-0.8021,  0.4497,  0.3931, -0.0100],
         [-0.5697, -0.7736, -0.2774,  0.0062],
         [ 0.1793, -0.4464,  0.8767,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.276014 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.277453 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0464],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.278133 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.278738 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.279342 - k: tensor([0.0485], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0491]
0:01:54.844308 - bracket_assembly_nut_noaug_coarse--206204
0:01:54.844521 - {'grad_norm': 1.0514718294143677, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05579733848571777, 'time_backward': 0.07754898071289062, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270369.3396425, 'n_iterations': 300, 'n_datas': 2400, 'train_loss_TCO-iter=1': 0.049126602709293365, 'train_loss_TCO': 0.049126602709293365, 'train_[loss_total': 0.049126602709293365, 'train_loss_total': 0.049126602709293365, 'train_grad_norm': 1.0514718294143677, 'epoch': 299}
0:01:54.844635 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:54.851996 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.377280 - iteration 0
0:01:55.598496 - vxvyvz tensor([[ 0.1223, -0.1601,  0.2177]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:55.599535 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.600557 - dR tensor([[[-0.7943,  0.4598,  0.3969],
         [-0.5677, -0.7945, -0.2156],
         [ 0.2162, -0.3966,  0.8922]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:55.601398 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:55.604630 - k: tensor([[[-0.7943,  0.4598,  0.3969, -0.0100],
         [-0.5677, -0.7945, -0.2156,  0.0062],
         [ 0.2162, -0.3966,  0.8922,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.605546 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.607068 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0653],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.607718 - k: tensor([7.8213e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.608337 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.608979 - k: tensor([0.0422], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0426]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:54.989086 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.514137 - iteration 0
0:01:55.729007 - vxvyvz tensor([[ 0.0556, -0.0424,  0.0063]], device='cuda:0')
0:01:55.729960 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.730879 - dR tensor([[[-0.8520,  0.0692,  0.5190],
         [-0.4357, -0.6434, -0.6294],
         [ 0.2904, -0.7624,  0.5783]]], device='cuda:0')
0:01:55.731737 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:55.734784 - k: tensor([[[-0.8520,  0.0692,  0.5190, -0.0100],
         [-0.4357, -0.6434, -0.6294,  0.0062],
         [ 0.2904, -0.7624,  0.5783,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.735712 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.736645 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0019],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.737267 - k: tensor([0.0022], device='cuda:0')
0:01:55.737869 - k: tensor([0.0003], device='cuda:0')
0:01:55.738465 - k: tensor([0.0634], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.55it/s]
0:01:55.225416 - bracket_assembly_nut_noaug_coarse--206204
0:01:55.225642 - {'grad_norm': 1.0801944732666016, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05597376823425293, 'time_backward': 0.07757329940795898, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270369.721449, 'n_iterations': 301, 'n_datas': 2408, 'train_loss_TCO-iter=1': 0.042636603116989136, 'train_loss_TCO': 0.042636603116989136, 'train_[loss_total': 0.042636603116989136, 'train_loss_total': 0.042636603116989136, 'train_grad_norm': 1.0801944732666016, 'val_loss_TCO-iter=1': 0.06590112298727036, 'val_loss_TCO': 0.06590112298727036, 'val_[loss_total': 0.06590112298727036, 'val_loss_total': 0.06590112298727036, 'epoch': 300}
0:01:55.225760 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:55.233315 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.755228 - iteration 0
0:01:55.976466 - vxvyvz tensor([[ 0.1113, -0.1551,  0.4595]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:55.977469 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:55.978424 - dR tensor([[[-0.7752,  0.4560,  0.4371],
         [-0.5727, -0.7993, -0.1819],
         [ 0.2665, -0.3914,  0.8808]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:55.979252 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:55.982511 - k: tensor([[[-0.7752,  0.4560,  0.4371, -0.0100],
         [-0.5727, -0.7993, -0.1819,  0.0062],
         [ 0.2665, -0.3914,  0.8808,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.983409 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.984351 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1379],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:55.985004 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.985631 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:55.986235 - k: tensor([0.0180], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.48it/s, loss=0.0185]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:56.975847 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:56.976898 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1397],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:56.977513 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:56.978117 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:56.978722 - k: tensor([0.0174], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0179]
0:01:56.539947 - bracket_assembly_nut_noaug_coarse--206204
0:01:56.540166 - {'grad_norm': 0.9835699796676636, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055726051330566406, 'time_backward': 0.07764911651611328, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270371.0390477, 'n_iterations': 305, 'n_datas': 2440, 'train_loss_TCO-iter=1': 0.017903819680213928, 'train_loss_TCO': 0.017903819680213928, 'train_[loss_total': 0.017903819680213928, 'train_loss_total': 0.017903819680213928, 'train_grad_norm': 0.9835699796676636, 'epoch': 304}
0:01:56.540318 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:56.547664 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.072825 - iteration 0
0:01:57.294021 - vxvyvz tensor([[ 0.1319, -0.1637,  0.2629]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:57.295039 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.296035 - dR tensor([[[-0.7875,  0.4457,  0.4258],
         [-0.5650, -0.7979, -0.2098],
         [ 0.2462, -0.4058,  0.8802]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:57.296916 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:57.300094 - k: tensor([[[-0.7875,  0.4457,  0.4258, -0.0100],
         [-0.5650, -0.7979, -0.2098,  0.0062],
         [ 0.2462, -0.4058,  0.8802,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.301037 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.302460 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0789],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.303157 - k: tensor([6.3372e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.303798 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.304411 - k: tensor([0.0377], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0381]
0:01:56.872504 - bracket_assembly_nut_noaug_coarse--206204
0:01:56.872763 - {'grad_norm': 1.2084203958511353, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05577683448791504, 'time_backward': 0.07740092277526855, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270371.3646605, 'n_iterations': 306, 'n_datas': 2448, 'train_loss_TCO-iter=1': 0.0380995087325573, 'train_loss_TCO': 0.0380995087325573, 'train_[loss_total': 0.0380995087325573, 'train_loss_total': 0.0380995087325573, 'train_grad_norm': 1.2084203958511353, 'epoch': 305}
0:01:56.872880 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:56.880535 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.405805 - iteration 0
0:01:57.626957 - vxvyvz tensor([[ 0.1355, -0.1719,  0.1912]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:57.628023 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.629031 - dR tensor([[[-0.8113,  0.4293,  0.3969],
         [-0.5439, -0.8032, -0.2430],
         [ 0.2144, -0.4131,  0.8851]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:57.629862 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:57.633097 - k: tensor([[[-0.8113,  0.4293,  0.3969, -0.0100],
         [-0.5439, -0.8032, -0.2430,  0.0062],
         [ 0.2144, -0.4131,  0.8851,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.634000 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.635428 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0574],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.636143 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.636796 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.637423 - k: tensor([0.0449], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0454]
0:01:57.200865 - bracket_assembly_nut_noaug_coarse--206204
0:01:57.201085 - {'grad_norm': 1.3466870784759521, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05596637725830078, 'time_backward': 0.07808876037597656, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270371.6982005, 'n_iterations': 307, 'n_datas': 2456, 'train_loss_TCO-iter=1': 0.045357294380664825, 'train_loss_TCO': 0.045357294380664825, 'train_[loss_total': 0.045357294380664825, 'train_loss_total': 0.045357294380664825, 'train_grad_norm': 1.3466870784759521, 'epoch': 306}
0:01:57.201201 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:57.208600 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.733796 - iteration 0
0:01:57.955149 - vxvyvz tensor([[ 0.1387, -0.1626,  0.1679]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:57.956223 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:57.957219 - dR tensor([[[-0.7877,  0.4663,  0.4025],
         [-0.5837, -0.7739, -0.2457],
         [ 0.1969, -0.4285,  0.8818]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:57.958050 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:57.961338 - k: tensor([[[-0.7877,  0.4663,  0.4025, -0.0100],
         [-0.5837, -0.7739, -0.2457,  0.0062],
         [ 0.1969, -0.4285,  0.8818,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.962806 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.963849 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0504],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:57.964513 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.965133 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:57.965739 - k: tensor([0.0472], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0477]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:01:58.983920 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:58.984897 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0594],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:58.985554 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:01:58.986180 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:58.986802 - k: tensor([0.0442], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0447]
0:01:58.555825 - bracket_assembly_nut_noaug_coarse--206204
0:01:58.556052 - {'grad_norm': 1.0584317445755005, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05740237236022949, 'time_backward': 0.07836747169494629, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270373.0480173, 'n_iterations': 311, 'n_datas': 2488, 'train_loss_TCO-iter=1': 0.04467625543475151, 'train_loss_TCO': 0.04467625543475151, 'train_[loss_total': 0.04467625543475151, 'train_loss_total': 0.04467625543475151, 'train_grad_norm': 1.0584317445755005, 'epoch': 310}
0:01:58.556185 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:58.563753 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.088980 - iteration 0
0:01:59.310969 - vxvyvz tensor([[ 0.1170, -0.1606,  0.4805]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:59.312023 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.313043 - dR tensor([[[-0.7713,  0.4496,  0.4506],
         [-0.5800, -0.7880, -0.2064],
         [ 0.2623, -0.4206,  0.8685]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:59.313951 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:59.317810 - k: tensor([[[-0.7713,  0.4496,  0.4506, -0.0100],
         [-0.5800, -0.7880, -0.2064,  0.0062],
         [ 0.2623, -0.4206,  0.8685,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.318778 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.319736 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1441],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.320381 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:01:59.321042 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:59.321677 - k: tensor([0.0159], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0164]
0:01:58.894490 - bracket_assembly_nut_noaug_coarse--206204
0:01:58.894703 - {'grad_norm': 0.9897905588150024, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0570371150970459, 'time_backward': 0.0767056941986084, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270373.3811285, 'n_iterations': 312, 'n_datas': 2496, 'train_loss_TCO-iter=1': 0.01642761006951332, 'train_loss_TCO': 0.01642761006951332, 'train_[loss_total': 0.01642761006951332, 'train_loss_total': 0.01642761006951332, 'train_grad_norm': 0.9897905588150024, 'epoch': 311}
0:01:58.894829 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:58.902386 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.427704 - iteration 0
0:01:59.649590 - vxvyvz tensor([[ 0.1176, -0.1611,  0.4831]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:59.650591 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.651592 - dR tensor([[[-0.7714,  0.4526,  0.4473],
         [-0.5800, -0.7893, -0.2016],
         [ 0.2618, -0.4149,  0.8714]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:59.652484 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:01:59.656239 - k: tensor([[[-0.7714,  0.4526,  0.4473, -0.0100],
         [-0.5800, -0.7893, -0.2016,  0.0062],
         [ 0.2618, -0.4149,  0.8714,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.657326 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.658260 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1449],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:01:59.658900 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:01:59.659551 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:01:59.660181 - k: tensor([0.0157], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.21it/s, loss=0.0162]
0:01:59.238266 - bracket_assembly_nut_noaug_coarse--206204
0:01:59.238474 - {'grad_norm': 0.9751157164573669, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05692005157470703, 'time_backward': 0.07807445526123047, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270373.720977, 'n_iterations': 313, 'n_datas': 2504, 'train_loss_TCO-iter=1': 0.016156617552042007, 'train_loss_TCO': 0.016156617552042007, 'train_[loss_total': 0.016156617552042007, 'train_loss_total': 0.016156617552042007, 'train_grad_norm': 0.9751157164573669, 'epoch': 312}
0:01:59.238593 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:01:59.246269 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.771610 - iteration 0
0:01:59.993740 - vxvyvz tensor([[ 0.1469, -0.1727,  0.1458]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:01:59.994749 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:01:59.995754 - dR tensor([[[-0.8003,  0.4614,  0.3830],
         [-0.5744, -0.7733, -0.2684],
         [ 0.1723, -0.4348,  0.8839]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:01:59.996663 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:00.000506 - k: tensor([[[-0.8003,  0.4614,  0.3830, -0.0100],
         [-0.5744, -0.7733, -0.2684,  0.0062],
         [ 0.1723, -0.4348,  0.8839,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:00.001499 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:00.002418 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0437],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:00.003050 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:00.003708 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:00.004341 - k: tensor([0.0494], device='cuda:0', grad_fn=<MinBackward0>)
100%|██████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.05]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:01.050128 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.051046 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0535],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.051714 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.052351 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.053014 - k: tensor([0.0461], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.0467]
0:02:00.625482 - bracket_assembly_nut_noaug_coarse--206204
0:02:00.625697 - {'grad_norm': 1.0773789882659912, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057298898696899414, 'time_backward': 0.07698774337768555, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270375.1126387, 'n_iterations': 317, 'n_datas': 2536, 'train_loss_TCO-iter=1': 0.046654392033815384, 'train_loss_TCO': 0.046654392033815384, 'train_[loss_total': 0.046654392033815384, 'train_loss_total': 0.046654392033815384, 'train_grad_norm': 1.0773789882659912, 'epoch': 316}
0:02:00.625844 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:00.633507 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:01.158802 - iteration 0
0:02:01.381013 - vxvyvz tensor([[ 0.1416, -0.1770,  0.2350]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:01.382042 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:01.383023 - dR tensor([[[-0.7834,  0.4658,  0.4115],
         [-0.5765, -0.7919, -0.2012],
         [ 0.2321, -0.3949,  0.8889]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:01.383914 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:01.387719 - k: tensor([[[-0.7834,  0.4658,  0.4115, -0.0100],
         [-0.5765, -0.7919, -0.2012,  0.0062],
         [ 0.2321, -0.3949,  0.8889,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.388780 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.389703 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0705],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.390353 - k: tensor([9.0445e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.391012 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.391673 - k: tensor([0.0405], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.22it/s, loss=0.0409]
0:02:00.959964 - bracket_assembly_nut_noaug_coarse--206204
0:02:00.960181 - {'grad_norm': 1.0797829627990723, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057363033294677734, 'time_backward': 0.07723689079284668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270375.4517078, 'n_iterations': 318, 'n_datas': 2544, 'train_loss_TCO-iter=1': 0.040911316871643066, 'train_loss_TCO': 0.040911316871643066, 'train_[loss_total': 0.040911316871643066, 'train_loss_total': 0.040911316871643066, 'train_grad_norm': 1.0797829627990723, 'epoch': 317}
0:02:00.960325 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:00.967904 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:01.493203 - iteration 0
0:02:01.715383 - vxvyvz tensor([[ 0.1405, -0.1722,  0.2985]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:01.716458 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:01.717445 - dR tensor([[[-0.7824,  0.4730,  0.4051],
         [-0.5721, -0.8030, -0.1673],
         [ 0.2461, -0.3627,  0.8988]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:01.718316 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:01.722111 - k: tensor([[[-0.7824,  0.4730,  0.4051, -0.0100],
         [-0.5721, -0.8030, -0.1673,  0.0062],
         [ 0.2461, -0.3627,  0.8988,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.723100 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.724056 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0895],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:01.724737 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.725361 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:01.725991 - k: tensor([0.0341], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0347]
0:02:01.299660 - bracket_assembly_nut_noaug_coarse--206204
0:02:01.299875 - {'grad_norm': 1.2031147480010986, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057138919830322266, 'time_backward': 0.07727503776550293, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270375.7860136, 'n_iterations': 319, 'n_datas': 2552, 'train_loss_TCO-iter=1': 0.034701209515333176, 'train_loss_TCO': 0.034701209515333176, 'train_[loss_total': 0.034701209515333176, 'train_loss_total': 0.034701209515333176, 'train_grad_norm': 1.2031147480010986, 'epoch': 318}
0:02:01.299990 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:01.307590 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:01.832849 - iteration 0
0:02:02.054817 - vxvyvz tensor([[ 0.1433, -0.1817,  0.2178]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:02.055868 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:02.056896 - dR tensor([[[-0.8039,  0.4499,  0.3889],
         [-0.5480, -0.8145, -0.1905],
         [ 0.2311, -0.3662,  0.9014]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:02.057746 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:02.061524 - k: tensor([[[-0.8039,  0.4499,  0.3889, -0.0100],
         [-0.5480, -0.8145, -0.1905,  0.0062],
         [ 0.2311, -0.3662,  0.9014,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:02.062553 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:02.063468 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0653],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:02.064142 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:02.064814 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:02.065460 - k: tensor([0.0422], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0427]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:03.068582 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.069518 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0502],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.070146 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.070769 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.071389 - k: tensor([0.0473], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0478]
0:02:02.647959 - bracket_assembly_nut_noaug_coarse--206204
0:02:02.648170 - {'grad_norm': 1.0344574451446533, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057158708572387695, 'time_backward': 0.07841300964355469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270377.1326299, 'n_iterations': 323, 'n_datas': 2584, 'train_loss_TCO-iter=1': 0.04781249910593033, 'train_loss_TCO': 0.04781249910593033, 'train_[loss_total': 0.04781249910593033, 'train_loss_total': 0.04781249910593033, 'train_grad_norm': 1.0344574451446533, 'epoch': 322}
0:02:02.648397 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:02.656035 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:03.181335 - iteration 0
0:02:03.403287 - vxvyvz tensor([[ 0.1473, -0.1849,  0.1447]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:03.404340 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:03.405357 - dR tensor([[[-0.7896,  0.4554,  0.4114],
         [-0.5748, -0.7837, -0.2356],
         [ 0.2151, -0.4225,  0.8805]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:03.406199 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:03.410016 - k: tensor([[[-0.7896,  0.4554,  0.4114, -0.0100],
         [-0.5748, -0.7837, -0.2356,  0.0062],
         [ 0.2151, -0.4225,  0.8805,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.411025 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.411998 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0434],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.412678 - k: tensor([7.9999e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.413312 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.413929 - k: tensor([0.0495], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.0499]
0:02:02.988872 - bracket_assembly_nut_noaug_coarse--206204
0:02:02.989093 - {'grad_norm': 1.047298550605774, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056966304779052734, 'time_backward': 0.07816815376281738, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270377.474784, 'n_iterations': 324, 'n_datas': 2592, 'train_loss_TCO-iter=1': 0.049930065870285034, 'train_loss_TCO': 0.049930065870285034, 'train_[loss_total': 0.049930065870285034, 'train_loss_total': 0.049930065870285034, 'train_grad_norm': 1.047298550605774, 'epoch': 323}
0:02:02.989224 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:02.996778 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:03.522106 - iteration 0
0:02:03.744037 - vxvyvz tensor([[ 0.1535, -0.1833,  0.1462]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:03.745096 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:03.746064 - dR tensor([[[-0.7966,  0.4369,  0.4179],
         [-0.5661, -0.7816, -0.2621],
         [ 0.2121, -0.4453,  0.8699]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:03.746941 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:03.750745 - k: tensor([[[-0.7966,  0.4369,  0.4179, -0.0100],
         [-0.5661, -0.7816, -0.2621,  0.0062],
         [ 0.2121, -0.4453,  0.8699,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.751786 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.752746 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0439],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:03.753399 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.754018 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:03.754671 - k: tensor([0.0494], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0499]
0:02:03.320849 - bracket_assembly_nut_noaug_coarse--206204
0:02:03.321118 - {'grad_norm': 1.0510642528533936, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057033538818359375, 'time_backward': 0.07757329940795898, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270377.814995, 'n_iterations': 325, 'n_datas': 2600, 'train_loss_TCO-iter=1': 0.04987472668290138, 'train_loss_TCO': 0.04987472668290138, 'train_[loss_total': 0.04987472668290138, 'train_loss_total': 0.04987472668290138, 'train_grad_norm': 1.0510642528533936, 'epoch': 324}
0:02:03.321238 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:03.328943 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:03.854301 - iteration 0
0:02:04.076541 - vxvyvz tensor([[ 0.1553, -0.1846,  0.1971]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:04.077560 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:04.078529 - dR tensor([[[-0.7924,  0.4381,  0.4246],
         [-0.5730, -0.7732, -0.2718],
         [ 0.2092, -0.4586,  0.8637]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:04.079380 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:04.083322 - k: tensor([[[-0.7924,  0.4381,  0.4246, -0.0100],
         [-0.5730, -0.7732, -0.2718,  0.0062],
         [ 0.2092, -0.4586,  0.8637,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:04.084290 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:04.085253 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0591],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:04.085882 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:04.086504 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:04.087122 - k: tensor([0.0443], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.18it/s, loss=0.0448]
0:02:03.657650 - bracket_assembly_nut_noaug_coarse--206204
0:02:03.657865 - {'grad_norm': 1.1826015710830688, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05739450454711914, 'time_backward': 0.07807445526123047, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270378.1479838, 'n_iterations': 326, 'n_datas': 2608, 'train_loss_TCO-iter=1': 0.04482763260602951, 'train_loss_TCO': 0.04482763260602951, 'train_[loss_total': 0.04482763260602951, 'train_loss_total': 0.04482763260602951, 'train_grad_norm': 1.1826015710830688, 'epoch': 325}
0:02:03.657979 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:03.665572 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:04.190865 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0467],], device='cuda:0',s, loss=0.0539]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.108186 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.108854 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.109490 - k: tensor([0.0484], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.15it/s, loss=0.0489]
0:02:04.680314 - bracket_assembly_nut_noaug_coarse--206204
0:02:04.680536 - {'grad_norm': 1.110548496246338, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057923078536987305, 'time_backward': 0.07802033424377441, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270379.1702797, 'n_iterations': 329, 'n_datas': 2632, 'train_loss_TCO-iter=1': 0.048908621072769165, 'train_loss_TCO': 0.048908621072769165, 'train_[loss_total': 0.048908621072769165, 'train_loss_total': 0.048908621072769165, 'train_grad_norm': 1.110548496246338, 'epoch': 328}
0:02:04.680656 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:04.688409 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:05.213676 - iteration 0
0:02:05.436065 - vxvyvz tensor([[ 0.1544, -0.1929,  0.2000]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:05.437110 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:05.438070 - dR tensor([[[-0.7918,  0.4536,  0.4089],
         [-0.5804, -0.7674, -0.2725],
         [ 0.1902, -0.4531,  0.8709]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:05.438895 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:05.442661 - k: tensor([[[-0.7918,  0.4536,  0.4089, -0.0100],
         [-0.5804, -0.7674, -0.2725,  0.0062],
         [ 0.1902, -0.4531,  0.8709,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.443686 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.444637 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0600],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.445273 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.445880 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.446483 - k: tensor([0.0440], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, loss=0.0445]
0:02:05.012357 - bracket_assembly_nut_noaug_coarse--206204
0:02:05.012566 - {'grad_norm': 1.1922770738601685, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057129859924316406, 'time_backward': 0.0790102481842041, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270379.5081549, 'n_iterations': 330, 'n_datas': 2640, 'train_loss_TCO-iter=1': 0.04454069212079048, 'train_loss_TCO': 0.04454069212079048, 'train_[loss_total': 0.04454069212079048, 'train_loss_total': 0.04454069212079048, 'train_grad_norm': 1.1922770738601685, 'epoch': 329}
0:02:05.012681 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:05.020222 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:05.545500 - iteration 0
0:02:05.767666 - vxvyvz tensor([[ 0.1566, -0.1913,  0.1475]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:05.768718 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:05.769723 - dR tensor([[[-0.8098,  0.4212,  0.4084],
         [-0.5461, -0.7955, -0.2626],
         [ 0.2143, -0.4357,  0.8742]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:05.770596 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:05.773923 - k: tensor([[[-0.8098,  0.4212,  0.4084, -0.0100],
         [-0.5461, -0.7955, -0.2626,  0.0062],
         [ 0.2143, -0.4357,  0.8742,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.775480 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.776469 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0443],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:05.777126 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.777748 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:05.778400 - k: tensor([0.0492], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.14it/s, loss=0.0498]
0:02:05.344360 - bracket_assembly_nut_noaug_coarse--206204
0:02:05.344565 - {'grad_norm': 1.0055549144744873, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057305335998535156, 'time_backward': 0.07893776893615723, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270379.8416834, 'n_iterations': 331, 'n_datas': 2648, 'train_loss_TCO-iter=1': 0.04977184906601906, 'train_loss_TCO': 0.04977184906601906, 'train_[loss_total': 0.04977184906601906, 'train_loss_total': 0.04977184906601906, 'train_grad_norm': 1.0055549144744873, 'epoch': 330}
0:02:05.344714 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:05.352243 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:05.877512 - iteration 0
0:02:06.099581 - vxvyvz tensor([[ 0.1562, -0.1885,  0.1549]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:06.100643 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:06.101610 - dR tensor([[[-0.7930,  0.4189,  0.4423],
         [-0.5665, -0.7742, -0.2823],
         [ 0.2242, -0.4745,  0.8512]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:06.102461 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:06.106313 - k: tensor([[[-0.7930,  0.4189,  0.4423, -0.0100],
         [-0.5665, -0.7742, -0.2823,  0.0062],
         [ 0.2242, -0.4745,  0.8512,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.107300 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.108263 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0465],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.108940 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:06.109566 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:06.110188 - k: tensor([0.0485], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.0491]
0:02:05.676946 - bracket_assembly_nut_noaug_coarse--206204
0:02:05.677162 - {'grad_norm': 1.0466870069503784, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.057073354721069336, 'time_backward': 0.07828044891357422, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270380.1711066, 'n_iterations': 332, 'n_datas': 2656, 'train_loss_TCO-iter=1': 0.049125127494335175, 'train_loss_TCO': 0.049125127494335175, 'train_[loss_total': 0.049125127494335175, 'train_loss_total': 0.049125127494335175, 'train_grad_norm': 1.0466870069503784, 'epoch': 331}
0:02:05.677298 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:05.684880 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:06.210191 - iteration 0
0:02:06.432230 - vxvyvz tensor([[ 0.1556, -0.1900,  0.1437]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:06.433285 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:06.434253 - dR tensor([[[-0.8010,  0.4471,  0.3981],
         [-0.5632, -0.7883, -0.2479],
         [ 0.2030, -0.4228,  0.8832]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:06.435097 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:06.438962 - k: tensor([[[-0.8010,  0.4471,  0.3981, -0.0100],
         [-0.5632, -0.7883, -0.2479,  0.0062],
         [ 0.2030, -0.4228,  0.8832,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.440027 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.440986 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0431],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:06.441631 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:06.442253 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:06.442871 - k: tensor([0.0496], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0501]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:02:07.422493 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:07.423486 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1519],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:07.424132 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:07.424779 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:07.425379 - k: tensor([0.0134], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0139]
0:02:06.988032 - bracket_assembly_nut_noaug_coarse--206204
0:02:06.988251 - {'grad_norm': 1.33644437789917, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05624890327453613, 'time_backward': 0.07793116569519043, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270381.4859257, 'n_iterations': 336, 'n_datas': 2688, 'train_loss_TCO-iter=1': 0.013942699879407883, 'train_loss_TCO': 0.013942699879407883, 'train_[loss_total': 0.013942699879407883, 'train_loss_total': 0.013942699879407883, 'train_grad_norm': 1.33644437789917, 'epoch': 335}
0:02:06.988375 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:06.995855 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:07.521084 - iteration 0
0:02:07.742172 - vxvyvz tensor([[ 0.1631, -0.1924,  0.1650]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:07.743186 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:07.744198 - dR tensor([[[-0.8097,  0.4411,  0.3871],
         [-0.5497, -0.8010, -0.2372],
         [ 0.2054, -0.4048,  0.8910]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:07.745070 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:07.748311 - k: tensor([[[-0.8097,  0.4411,  0.3871, -0.0100],
         [-0.5497, -0.8010, -0.2372,  0.0062],
         [ 0.2054, -0.4048,  0.8910,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:07.749251 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:07.750646 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0495],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:07.751361 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:07.752015 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:07.752657 - k: tensor([0.0475], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.048]
0:02:07.316087 - bracket_assembly_nut_noaug_coarse--206204
0:02:07.316310 - {'grad_norm': 1.1098273992538452, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05588555335998535, 'time_backward': 0.07735896110534668, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270381.8126683, 'n_iterations': 337, 'n_datas': 2696, 'train_loss_TCO-iter=1': 0.04797826707363129, 'train_loss_TCO': 0.04797826707363129, 'train_[loss_total': 0.04797826707363129, 'train_loss_total': 0.04797826707363129, 'train_grad_norm': 1.1098273992538452, 'epoch': 336}
0:02:07.316430 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:07.323884 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:07.849110 - iteration 0
0:02:08.070677 - vxvyvz tensor([[ 0.1638, -0.1927,  0.1581]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:08.071764 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:08.072769 - dR tensor([[[-0.7941,  0.4458,  0.4131],
         [-0.5708, -0.7805, -0.2549],
         [ 0.2088, -0.4383,  0.8743]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:08.073636 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:08.076888 - k: tensor([[[-0.7941,  0.4458,  0.4131, -0.0100],
         [-0.5708, -0.7805, -0.2549,  0.0062],
         [ 0.2088, -0.4383,  0.8743,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.077790 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.078695 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0474],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.079306 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:08.079946 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:08.080586 - k: tensor([0.0482], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.17it/s, loss=0.0486]
0:02:07.648736 - bracket_assembly_nut_noaug_coarse--206204
0:02:07.648952 - {'grad_norm': 1.0761833190917969, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055710554122924805, 'time_backward': 0.07996940612792969, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270382.143415, 'n_iterations': 338, 'n_datas': 2704, 'train_loss_TCO-iter=1': 0.04864969104528427, 'train_loss_TCO': 0.04864969104528427, 'train_[loss_total': 0.04864969104528427, 'train_loss_total': 0.04864969104528427, 'train_grad_norm': 1.0761833190917969, 'epoch': 337}
0:02:07.649064 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:07.656518 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:08.181751 - iteration 0
0:02:08.402884 - vxvyvz tensor([[ 0.1669, -0.1952,  0.1572]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:08.403929 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:08.404934 - dR tensor([[[-0.8058,  0.4601,  0.3727],
         [-0.5567, -0.8031, -0.2122],
         [ 0.2017, -0.3785,  0.9034]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:08.405759 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:08.408986 - k: tensor([[[-0.8058,  0.4601,  0.3727, -0.0100],
         [-0.5567, -0.8031, -0.2122,  0.0062],
         [ 0.2017, -0.3785,  0.9034,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.409886 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.411370 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0472],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:08.412028 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:08.412671 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:08.413307 - k: tensor([0.0483], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0488]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:09.396794 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:09.398060 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1561],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:09.398680 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:09.399284 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:09.399925 - k: tensor([0.0120], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0126]
0:02:08.961429 - bracket_assembly_nut_noaug_coarse--206204
0:02:08.961631 - {'grad_norm': 1.0874125957489014, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05695080757141113, 'time_backward': 0.07765698432922363, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270383.4602664, 'n_iterations': 342, 'n_datas': 2736, 'train_loss_TCO-iter=1': 0.012558110989630222, 'train_loss_TCO': 0.012558110989630222, 'train_[loss_total': 0.012558110989630222, 'train_loss_total': 0.012558110989630222, 'train_grad_norm': 1.0874125957489014, 'epoch': 341}
0:02:08.961746 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:08.969189 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:09.494468 - iteration 0
0:02:09.715599 - vxvyvz tensor([[ 0.1550, -0.1905,  0.3672]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:09.716642 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:09.717618 - dR tensor([[[-0.7667,  0.4579,  0.4501],
         [-0.5807, -0.7936, -0.1819],
         [ 0.2739, -0.4008,  0.8743]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:09.718446 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:09.721674 - k: tensor([[[-0.7667,  0.4579,  0.4501, -0.0100],
         [-0.5807, -0.7936, -0.1819,  0.0062],
         [ 0.2739, -0.4008,  0.8743,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:09.722950 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:09.724169 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1101],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:09.724824 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:09.725443 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:09.726045 - k: tensor([0.0273], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0278]
0:02:09.288281 - bracket_assembly_nut_noaug_coarse--206204
0:02:09.288483 - {'grad_norm': 1.1592134237289429, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055933475494384766, 'time_backward': 0.07738137245178223, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270383.7860184, 'n_iterations': 343, 'n_datas': 2744, 'train_loss_TCO-iter=1': 0.027808649465441704, 'train_loss_TCO': 0.027808649465441704, 'train_[loss_total': 0.027808649465441704, 'train_loss_total': 0.027808649465441704, 'train_grad_norm': 1.1592134237289429, 'epoch': 342}
0:02:09.288592 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:09.295998 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:09.821264 - iteration 0
0:02:10.042644 - vxvyvz tensor([[ 0.1716, -0.1969,  0.1552]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:10.043696 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:10.044700 - dR tensor([[[-0.7871,  0.4708,  0.3984],
         [-0.5769, -0.7905, -0.2056],
         [ 0.2182, -0.3917,  0.8939]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:10.045553 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:10.048766 - k: tensor([[[-0.7871,  0.4708,  0.3984, -0.0100],
         [-0.5769, -0.7905, -0.2056,  0.0062],
         [ 0.2182, -0.3917,  0.8939,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.049704 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.051121 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0466],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.051895 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:10.052541 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:10.053159 - k: tensor([0.0485], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0489]
0:02:09.617761 - bracket_assembly_nut_noaug_coarse--206204
0:02:09.617972 - {'grad_norm': 1.1056221723556519, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056185007095336914, 'time_backward': 0.07740283012390137, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270384.1131973, 'n_iterations': 344, 'n_datas': 2752, 'train_loss_TCO-iter=1': 0.04891861230134964, 'train_loss_TCO': 0.04891861230134964, 'train_[loss_total': 0.04891861230134964, 'train_loss_total': 0.04891861230134964, 'train_grad_norm': 1.1056221723556519, 'epoch': 343}
0:02:09.618091 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:09.625458 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:10.150723 - iteration 0
0:02:10.371897 - vxvyvz tensor([[ 0.1597, -0.1973,  0.2264]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:10.372927 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:10.373898 - dR tensor([[[-0.7776,  0.4763,  0.4104],
         [-0.5865, -0.7847, -0.2006],
         [ 0.2265, -0.3967,  0.8896]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:10.374758 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:10.378007 - k: tensor([[[-0.7776,  0.4763,  0.4104, -0.0100],
         [-0.5865, -0.7847, -0.2006,  0.0062],
         [ 0.2265, -0.3967,  0.8896,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.379401 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.380465 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0679],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:10.381100 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:10.381705 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:10.382306 - k: tensor([0.0413], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.26it/s, loss=0.0418]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:11.375038 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:11.376045 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0703],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:11.376687 - k: tensor([6.9346e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:11.377288 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:11.377893 - k: tensor([0.0406], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.24it/s, loss=0.041]
0:02:10.942573 - bracket_assembly_nut_noaug_coarse--206204
0:02:10.942786 - {'grad_norm': 1.0532420873641968, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05595254898071289, 'time_backward': 0.0784296989440918, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270385.438852, 'n_iterations': 348, 'n_datas': 2784, 'train_loss_TCO-iter=1': 0.04096183925867081, 'train_loss_TCO': 0.04096183925867081, 'train_[loss_total': 0.04096183925867081, 'train_loss_total': 0.04096183925867081, 'train_grad_norm': 1.0532420873641968, 'epoch': 347}
0:02:10.942901 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:10.950247 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:11.475418 - iteration 0
0:02:11.696802 - vxvyvz tensor([[ 0.1721, -0.2041,  0.1603]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:11.697826 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:11.698812 - dR tensor([[[-0.8018,  0.4511,  0.3920],
         [-0.5597, -0.7967, -0.2280],
         [ 0.2095, -0.4022,  0.8913]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:11.699675 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:11.702929 - k: tensor([[[-0.8018,  0.4511,  0.3920, -0.0100],
         [-0.5597, -0.7967, -0.2280,  0.0062],
         [ 0.2095, -0.4022,  0.8913,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:11.703863 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:11.705353 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0481],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:11.705966 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:11.706570 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:11.707171 - k: tensor([0.0480], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s, loss=0.0484]
0:02:11.272461 - bracket_assembly_nut_noaug_coarse--206204
0:02:11.272667 - {'grad_norm': 0.9801806211471558, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05593276023864746, 'time_backward': 0.07788705825805664, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270385.7677145, 'n_iterations': 349, 'n_datas': 2792, 'train_loss_TCO-iter=1': 0.04840093478560448, 'train_loss_TCO': 0.04840093478560448, 'train_[loss_total': 0.04840093478560448, 'train_loss_total': 0.04840093478560448, 'train_grad_norm': 0.9801806211471558, 'epoch': 348}
0:02:11.272778 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:11.280042 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:11.805197 - iteration 0
0:02:12.026031 - vxvyvz tensor([[ 0.1619, -0.2019,  0.2950]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:12.027034 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.028024 - dR tensor([[[-0.7788,  0.4573,  0.4294],
         [-0.5708, -0.8005, -0.1827],
         [ 0.2602, -0.3873,  0.8845]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:12.028899 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:12.032110 - k: tensor([[[-0.7788,  0.4573,  0.4294, -0.0100],
         [-0.5708, -0.8005, -0.1827,  0.0062],
         [ 0.2602, -0.3873,  0.8845,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.033061 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.034489 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0885],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.035183 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:12.035833 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:12.036470 - k: tensor([0.0345], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.035]
0:02:11.597623 - bracket_assembly_nut_noaug_coarse--206204
0:02:11.597842 - {'grad_norm': 1.2791749238967896, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055388689041137695, 'time_backward': 0.07809853553771973, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270386.0971847, 'n_iterations': 350, 'n_datas': 2800, 'train_loss_TCO-iter=1': 0.0349748432636261, 'train_loss_TCO': 0.0349748432636261, 'train_[loss_total': 0.0349748432636261, 'train_loss_total': 0.0349748432636261, 'train_grad_norm': 1.2791749238967896, 'epoch': 349}
0:02:11.597953 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:11.605262 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.130457 - iteration 0
0:02:12.351661 - vxvyvz tensor([[ 0.1762, -0.2108,  0.1653]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:12.352704 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.353660 - dR tensor([[[-0.8021,  0.4353,  0.4089],
         [-0.5484, -0.8079, -0.2157],
         [ 0.2365, -0.3972,  0.8867]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:12.354491 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:12.357733 - k: tensor([[[-0.8021,  0.4353,  0.4089, -0.0100],
         [-0.5484, -0.8079, -0.2157,  0.0062],
         [ 0.2365, -0.3972,  0.8867,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.359150 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.360180 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0496],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:12.360842 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:12.361448 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:12.362047 - k: tensor([0.0475], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0479]
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:11.742095 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.267132 - iteration 0
0:02:12.482568 - vxvyvz tensor([[ 0.0568, -0.0662,  0.0156]], device='cuda:0')
0:02:12.483600 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.484564 - dR tensor([[[-0.9011,  0.0230,  0.4330],
         [-0.3068, -0.7395, -0.5992],
         [ 0.3064, -0.6727,  0.6735]]], device='cuda:0')
0:02:12.485399 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:12.488454 - k: tensor([[[-0.9011,  0.0230,  0.4330, -0.0100],
         [-0.3068, -0.7395, -0.5992,  0.0062],
         [ 0.3064, -0.6727,  0.6735,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.489366 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.490253 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0047],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:12.490862 - k: tensor([0.0022], device='cuda:0')
0:02:12.491471 - k: tensor([0.0003], device='cuda:0')
0:02:12.492100 - k: tensor([0.0624], device='cuda:0')
100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 20.33it/s]
       grad_fn=<CopySlices>) 0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:13.387763 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:13.388706 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0488],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:13.389317 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:13.389920 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:13.390522 - k: tensor([0.0477], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0483]
0:02:12.960463 - bracket_assembly_nut_noaug_coarse--206204
0:02:12.960680 - {'grad_norm': 1.0626771450042725, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05545330047607422, 'time_backward': 0.07893252372741699, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270387.4523087, 'n_iterations': 354, 'n_datas': 2832, 'train_loss_TCO-iter=1': 0.048272304236888885, 'train_loss_TCO': 0.048272304236888885, 'train_[loss_total': 0.048272304236888885, 'train_loss_total': 0.048272304236888885, 'train_grad_norm': 1.0626771450042725, 'epoch': 353}
0:02:12.960793 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:12.968183 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:13.493366 - iteration 0
0:02:13.714538 - vxvyvz tensor([[ 0.1459, -0.1893,  0.5376]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:13.715555 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:13.716572 - dR tensor([[[-0.7677,  0.4344,  0.4711],
         [-0.5796, -0.7842, -0.2213],
         [ 0.2733, -0.4430,  0.8538]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:13.717415 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:13.720628 - k: tensor([[[-0.7677,  0.4344,  0.4711, -0.0100],
         [-0.5796, -0.7842, -0.2213,  0.0062],
         [ 0.2733, -0.4430,  0.8538,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:13.721537 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:13.722992 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1613],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:13.723642 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:13.724260 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:13.724904 - k: tensor([0.0102], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0108]
0:02:13.288677 - bracket_assembly_nut_noaug_coarse--206204
0:02:13.288886 - {'grad_norm': 1.0833038091659546, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05570077896118164, 'time_backward': 0.07727885246276855, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270387.7848465, 'n_iterations': 355, 'n_datas': 2840, 'train_loss_TCO-iter=1': 0.01078889425843954, 'train_loss_TCO': 0.01078889425843954, 'train_[loss_total': 0.01078889425843954, 'train_loss_total': 0.01078889425843954, 'train_grad_norm': 1.0833038091659546, 'epoch': 354}
0:02:13.289000 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:13.296461 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:13.821674 - iteration 0
0:02:14.043475 - vxvyvz tensor([[ 0.1545, -0.1892,  0.4356]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:14.044549 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:14.045514 - dR tensor([[[-0.7599,  0.4532,  0.4660],
         [-0.5879, -0.7851, -0.1951],
         [ 0.2775, -0.4222,  0.8630]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:14.046341 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:14.049598 - k: tensor([[[-0.7599,  0.4532,  0.4660, -0.0100],
         [-0.5879, -0.7851, -0.1951,  0.0062],
         [ 0.2775, -0.4222,  0.8630,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:14.051058 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:14.052083 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1307],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:14.052740 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:14.053361 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:14.053962 - k: tensor([0.0204], device='cuda:0', grad_fn=<MinBackward0>)
100%|█████████████████████████████████| 1/1 [00:00<00:00,  7.20it/s, loss=0.021]
0:02:13.624991 - bracket_assembly_nut_noaug_coarse--206204
0:02:13.625201 - {'grad_norm': 1.1177692413330078, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.056542158126831055, 'time_backward': 0.0787210464477539, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270388.1153316, 'n_iterations': 356, 'n_datas': 2848, 'train_loss_TCO-iter=1': 0.02098897285759449, 'train_loss_TCO': 0.02098897285759449, 'train_[loss_total': 0.02098897285759449, 'train_loss_total': 0.02098897285759449, 'train_grad_norm': 1.1177692413330078, 'epoch': 355}
0:02:13.625321 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:13.632674 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:14.157868 - iteration 0
0:02:14.378911 - vxvyvz tensor([[ 0.1469, -0.1908,  0.5422]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:14.379966 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:14.380979 - dR tensor([[[-0.7697,  0.4395,  0.4630],
         [-0.5776, -0.7883, -0.2119],
         [ 0.2719, -0.4306,  0.8606]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:14.381808 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:14.385044 - k: tensor([[[-0.7697,  0.4395,  0.4630, -0.0100],
         [-0.5776, -0.7883, -0.2119,  0.0062],
         [ 0.2719, -0.4306,  0.8606,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:14.386444 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:14.387557 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1627],
       grad_fn=<StackBackward0>)000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:15.372468 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:15.375714 - k: tensor([[[-0.8049,  0.4286,  0.4104, -0.0100],
         [-0.5466, -0.8048, -0.2315,  0.0062],
         [ 0.2311, -0.4107,  0.8820,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.377198 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.378186 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0516],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.378802 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:15.379408 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:15.380052 - k: tensor([0.0468], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0472]
0:02:14.944951 - bracket_assembly_nut_noaug_coarse--206204
0:02:14.945175 - {'grad_norm': 1.0282440185546875, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05597543716430664, 'time_backward': 0.07718825340270996, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270389.4399624, 'n_iterations': 360, 'n_datas': 2880, 'train_loss_TCO-iter=1': 0.047234609723091125, 'train_loss_TCO': 0.047234609723091125, 'train_[loss_total': 0.047234609723091125, 'train_loss_total': 0.047234609723091125, 'train_grad_norm': 1.0282440185546875, 'epoch': 359}
0:02:14.945288 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:14.952728 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:15.477912 - iteration 0
0:02:15.699134 - vxvyvz tensor([[ 0.1775, -0.2030,  0.2063]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:15.700204 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:15.701208 - dR tensor([[[-0.8071,  0.4454,  0.3874],
         [-0.5567, -0.7927, -0.2483],
         [ 0.1965, -0.4161,  0.8878]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:15.702063 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:15.705290 - k: tensor([[[-0.8071,  0.4454,  0.3874, -0.0100],
         [-0.5567, -0.7927, -0.2483,  0.0062],
         [ 0.1965, -0.4161,  0.8878,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.706190 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.707739 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0619],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:15.708365 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:15.709012 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:15.709614 - k: tensor([0.0434], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0439]
0:02:15.301046 - bracket_assembly_nut_noaug_coarse--206204
0:02:15.301274 - {'grad_norm': 1.0133802890777588, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05591535568237305, 'time_backward': 0.07741951942443848, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270389.7710834, 'n_iterations': 361, 'n_datas': 2888, 'train_loss_TCO-iter=1': 0.043856993317604065, 'train_loss_TCO': 0.043856993317604065, 'train_[loss_total': 0.043856993317604065, 'train_loss_total': 0.043856993317604065, 'train_grad_norm': 1.0133802890777588, 'epoch': 360}
0:02:15.301392 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:15.308754 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:15.833935 - iteration 0
0:02:16.055070 - vxvyvz tensor([[ 0.1792, -0.2152,  0.2102]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:16.056113 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:16.057109 - dR tensor([[[-0.8039,  0.4388,  0.4015],
         [-0.5442, -0.8150, -0.1991],
         [ 0.2398, -0.3786,  0.8940]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:16.057958 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:16.061187 - k: tensor([[[-0.8039,  0.4388,  0.4015, -0.0100],
         [-0.5442, -0.8150, -0.1991,  0.0062],
         [ 0.2398, -0.3786,  0.8940,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:16.062566 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:16.063586 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0631],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:16.064227 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:16.064875 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:16.065478 - k: tensor([0.0430], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0435]
       grad_fn=<CopySlices>)d0>)000,  1.0000]]], device='cuda:0',s, loss=0.0539]
0:02:17.075237 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.076283 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0563],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.076943 - k: tensor([8.4529e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.077547 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.078150 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0456]
0:02:16.633827 - bracket_assembly_nut_noaug_coarse--206204
0:02:16.634042 - {'grad_norm': 1.0967466831207275, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055709123611450195, 'time_backward': 0.07733845710754395, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270391.138082, 'n_iterations': 365, 'n_datas': 2920, 'train_loss_TCO-iter=1': 0.0456332191824913, 'train_loss_TCO': 0.0456332191824913, 'train_[loss_total': 0.0456332191824913, 'train_loss_total': 0.0456332191824913, 'train_grad_norm': 1.0967466831207275, 'epoch': 364}
0:02:16.634161 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:16.641379 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:17.166567 - iteration 0
0:02:17.387722 - vxvyvz tensor([[ 0.1765, -0.2040,  0.2728]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:17.388754 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:17.389733 - dR tensor([[[-0.7688,  0.4618,  0.4423],
         [-0.5856, -0.7864, -0.1968],
         [ 0.2569, -0.4103,  0.8750]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:17.390561 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:17.393794 - k: tensor([[[-0.7688,  0.4618,  0.4423, -0.0100],
         [-0.5856, -0.7864, -0.1968,  0.0062],
         [ 0.2569, -0.4103,  0.8750,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.394689 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.396477 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0818],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.397115 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.397723 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.398329 - k: tensor([0.0367], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.0372]
0:02:16.953604 - bracket_assembly_nut_noaug_coarse--206204
0:02:16.953813 - {'grad_norm': 1.14650297164917, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05595707893371582, 'time_backward': 0.07731437683105469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270391.4582274, 'n_iterations': 366, 'n_datas': 2928, 'train_loss_TCO-iter=1': 0.03718515485525131, 'train_loss_TCO': 0.03718515485525131, 'train_[loss_total': 0.03718515485525131, 'train_loss_total': 0.03718515485525131, 'train_grad_norm': 1.14650297164917, 'epoch': 365}
0:02:16.953938 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:16.961180 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:17.486403 - iteration 0
0:02:17.707421 - vxvyvz tensor([[ 0.1884, -0.2169,  0.1768]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:17.708473 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:17.709434 - dR tensor([[[-0.7983,  0.4582,  0.3908],
         [-0.5649, -0.7946, -0.2223],
         [ 0.2087, -0.3983,  0.8932]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:17.710259 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:17.713485 - k: tensor([[[-0.7983,  0.4582,  0.3908, -0.0100],
         [-0.5649, -0.7946, -0.2223,  0.0062],
         [ 0.2087, -0.3983,  0.8932,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.714905 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.715909 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0530],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:17.716561 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.717183 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:17.717785 - k: tensor([0.0463], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0467]
0:02:17.275808 - bracket_assembly_nut_noaug_coarse--206204
0:02:17.276029 - {'grad_norm': 1.0902092456817627, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055608272552490234, 'time_backward': 0.07718372344970703, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270391.7775548, 'n_iterations': 367, 'n_datas': 2936, 'train_loss_TCO-iter=1': 0.04674621298909187, 'train_loss_TCO': 0.04674621298909187, 'train_[loss_total': 0.04674621298909187, 'train_loss_total': 0.04674621298909187, 'train_grad_norm': 1.0902092456817627, 'epoch': 366}
0:02:17.276150 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:17.283506 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:17.808681 - iteration 0
0:02:18.030077 - vxvyvz tensor([[ 0.1830, -0.2143,  0.1798]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:18.031080 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:18.032077 - dR tensor([[[-0.7973,  0.4560,  0.3955],
         [-0.5620, -0.7999, -0.2107],
         [ 0.2202, -0.3902,  0.8940]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:18.032958 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:18.036150 - k: tensor([[[-0.7973,  0.4560,  0.3955, -0.0100],
         [-0.5620, -0.7999, -0.2107,  0.0062],
         [ 0.2202, -0.3902,  0.8940,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:18.037091 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:18.038512 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0539],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:18.039230 - k: tensor([9.8353e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:18.039880 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:18.040520 - k: tensor([0.0460], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0464]
0:02:17.597421 - bracket_assembly_nut_noaug_coarse--206204
0:02:17.597635 - {'grad_norm': 1.0480551719665527, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055988311767578125, 'time_backward': 0.0771632194519043, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270392.1003828, 'n_iterations': 368, 'n_datas': 2944, 'train_loss_TCO-iter=1': 0.04644022509455681, 'train_loss_TCO': 0.04644022509455681, 'train_[loss_total': 0.04644022509455681, 'train_loss_total': 0.04644022509455681, 'train_grad_norm': 1.0480551719665527, 'epoch': 367}
0:02:17.597749 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:17.604961 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:18.130136 - iteration 0
         [ 0.2313, -0.4099,  0.8823,  0.0563],], device='cuda:0',s, loss=0.0539]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:18.999360 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.000011 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.000658 - k: tensor([0.0452], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.35it/s, loss=0.0457]
0:02:18.561301 - bracket_assembly_nut_noaug_coarse--206204
0:02:18.561518 - {'grad_norm': 1.005816102027893, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05549979209899902, 'time_backward': 0.07685589790344238, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270393.0602088, 'n_iterations': 371, 'n_datas': 2968, 'train_loss_TCO-iter=1': 0.045673247426748276, 'train_loss_TCO': 0.045673247426748276, 'train_[loss_total': 0.045673247426748276, 'train_loss_total': 0.045673247426748276, 'train_grad_norm': 1.005816102027893, 'epoch': 370}
0:02:18.561631 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:18.568867 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.094031 - iteration 0
0:02:19.315210 - vxvyvz tensor([[ 0.1638, -0.2011,  0.4745]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:19.316279 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.317278 - dR tensor([[[-0.7623,  0.4890,  0.4241],
         [-0.5949, -0.7874, -0.1613],
         [ 0.2550, -0.3753,  0.8911]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:19.318105 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:19.321327 - k: tensor([[[-0.7623,  0.4890,  0.4241, -0.0100],
         [-0.5949, -0.7874, -0.1613,  0.0062],
         [ 0.2550, -0.3753,  0.8911,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.322738 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.323768 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1423],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.324399 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.325042 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.325645 - k: tensor([0.0165], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0171]
0:02:18.880299 - bracket_assembly_nut_noaug_coarse--206204
0:02:18.880500 - {'grad_norm': 1.111037254333496, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055770158767700195, 'time_backward': 0.07741355895996094, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270393.3858047, 'n_iterations': 372, 'n_datas': 2976, 'train_loss_TCO-iter=1': 0.01713653653860092, 'train_loss_TCO': 0.01713653653860092, 'train_[loss_total': 0.01713653653860092, 'train_loss_total': 0.01713653653860092, 'train_grad_norm': 1.111037254333496, 'epoch': 371}
0:02:18.880614 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:18.887852 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.412935 - iteration 0
0:02:19.634269 - vxvyvz tensor([[ 0.1865, -0.2116,  0.2418]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:19.635282 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.636286 - dR tensor([[[-0.7749,  0.4729,  0.4195],
         [-0.5864, -0.7856, -0.1975],
         [ 0.2362, -0.3990,  0.8860]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:19.637153 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:19.640310 - k: tensor([[[-0.7749,  0.4729,  0.4195, -0.0100],
         [-0.5864, -0.7856, -0.1975,  0.0062],
         [ 0.2362, -0.3990,  0.8860,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.641245 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.642771 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0725],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.643386 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.644027 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.644671 - k: tensor([0.0398], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0403]
0:02:19.199665 - bracket_assembly_nut_noaug_coarse--206204
0:02:19.199881 - {'grad_norm': 1.19661283493042, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05579853057861328, 'time_backward': 0.07688713073730469, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270393.7042792, 'n_iterations': 373, 'n_datas': 2984, 'train_loss_TCO-iter=1': 0.04026329889893532, 'train_loss_TCO': 0.04026329889893532, 'train_[loss_total': 0.04026329889893532, 'train_loss_total': 0.04026329889893532, 'train_grad_norm': 1.19661283493042, 'epoch': 372}
0:02:19.199994 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:19.207231 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.732430 - iteration 0
0:02:19.953505 - vxvyvz tensor([[ 0.1824, -0.2179,  0.2536]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:19.954528 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:19.955490 - dR tensor([[[-0.7831,  0.4478,  0.4315],
         [-0.5589, -0.8111, -0.1725],
         [ 0.2727, -0.3763,  0.8855]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:19.956352 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:19.959589 - k: tensor([[[-0.7831,  0.4478,  0.4315, -0.0100],
         [-0.5589, -0.8111, -0.1725,  0.0062],
         [ 0.2727, -0.3763,  0.8855,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.960528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.962045 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0761],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:19.962671 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.963277 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:19.963917 - k: tensor([0.0386], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0392]
0:02:19.514447 - bracket_assembly_nut_noaug_coarse--206204
0:02:19.514662 - {'grad_norm': 1.0668909549713135, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05562734603881836, 'time_backward': 0.07721924781799316, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270394.0237606, 'n_iterations': 374, 'n_datas': 2992, 'train_loss_TCO-iter=1': 0.039162471890449524, 'train_loss_TCO': 0.039162471890449524, 'train_[loss_total': 0.039162471890449524, 'train_loss_total': 0.039162471890449524, 'train_grad_norm': 1.0668909549713135, 'epoch': 373}
0:02:19.514774 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:19.522179 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:20.047436 - iteration 0
0:02:20.268532 - vxvyvz tensor([[ 0.1716, -0.2062,  0.3782]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:20.269526 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:20.270478 - dR tensor([[[-0.7534,  0.4913,  0.4370],
         [-0.6060, -0.7768, -0.1713],
         [ 0.2553, -0.3939,  0.8830]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:20.271304 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:20.274566 - k: tensor([[[-0.7534,  0.4913,  0.4370, -0.0100],
         [-0.6060, -0.7768, -0.1713,  0.0062],
         [ 0.2553, -0.3939,  0.8830,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:20.276024 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:20.277070 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1135],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:20.277685 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:20.278289 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:20.278890 - k: tensor([0.0262], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.30it/s, loss=0.0268]
       grad_fn=<CopySlices>) 0.8823,  0.0563],], device='cuda:0',s, loss=0.0539]
0:02:21.371650 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:21.373171 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1710],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:21.373802 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:21.374407 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:21.375007 - k: tensor([0.0070], device='cuda:0', grad_fn=<MinBackward0>)
100%|███████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.00747]
0:02:20.926936 - bracket_assembly_nut_noaug_coarse--206204
0:02:20.927144 - {'grad_norm': 1.1070506572723389, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055483102798461914, 'time_backward': 0.07720637321472168, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270395.4348822, 'n_iterations': 378, 'n_datas': 3024, 'train_loss_TCO-iter=1': 0.00746791809797287, 'train_loss_TCO': 0.00746791809797287, 'train_[loss_total': 0.00746791809797287, 'train_loss_total': 0.00746791809797287, 'train_grad_norm': 1.1070506572723389, 'epoch': 377}
0:02:20.927266 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:20.934534 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:21.459714 - iteration 0
0:02:21.680584 - vxvyvz tensor([[ 0.1978, -0.2249,  0.2475]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:21.681575 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:21.682531 - dR tensor([[[-0.7767,  0.4328,  0.4576],
         [-0.5743, -0.7849, -0.2325],
         [ 0.2585, -0.4434,  0.8582]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:21.683358 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:21.686602 - k: tensor([[[-0.7767,  0.4328,  0.4576, -0.0100],
         [-0.5743, -0.7849, -0.2325,  0.0062],
         [ 0.2585, -0.4434,  0.8582,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:21.687514 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:21.689079 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0742],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:21.689750 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:21.690355 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:21.690957 - k: tensor([0.0392], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0398]
0:02:21.246928 - bracket_assembly_nut_noaug_coarse--206204
0:02:21.247147 - {'grad_norm': 1.0906354188919067, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05542397499084473, 'time_backward': 0.0774691104888916, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270395.7511544, 'n_iterations': 379, 'n_datas': 3032, 'train_loss_TCO-iter=1': 0.039752814918756485, 'train_loss_TCO': 0.039752814918756485, 'train_[loss_total': 0.039752814918756485, 'train_loss_total': 0.039752814918756485, 'train_grad_norm': 1.0906354188919067, 'epoch': 378}
0:02:21.247275 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:21.254681 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:21.779919 - iteration 0
0:02:22.001026 - vxvyvz tensor([[ 0.1604, -0.2062,  0.5738]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:22.002013 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:22.002970 - dR tensor([[[-0.7782,  0.4548,  0.4331],
         [-0.5765, -0.7909, -0.2052],
         [ 0.2493, -0.4093,  0.8777]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:22.003833 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:22.007058 - k: tensor([[[-0.7782,  0.4548,  0.4331, -0.0100],
         [-0.5765, -0.7909, -0.2052,  0.0062],
         [ 0.2493, -0.4093,  0.8777,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.008528 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.009550 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1721],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.010175 - k: tensor([8.7874e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:22.010780 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:22.011387 - k: tensor([0.0066], device='cuda:0', grad_fn=<MinBackward0>)
100%|███████████████████████████████| 1/1 [00:00<00:00,  7.31it/s, loss=0.00703]
0:02:21.563787 - bracket_assembly_nut_noaug_coarse--206204
0:02:21.563998 - {'grad_norm': 1.033743977546692, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05573844909667969, 'time_backward': 0.07734036445617676, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270396.0714233, 'n_iterations': 380, 'n_datas': 3040, 'train_loss_TCO-iter=1': 0.007031579967588186, 'train_loss_TCO': 0.007031579967588186, 'train_[loss_total': 0.007031579967588186, 'train_loss_total': 0.007031579967588186, 'train_grad_norm': 1.033743977546692, 'epoch': 379}
0:02:21.564111 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:21.571491 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:22.096647 - iteration 0
0:02:22.317597 - vxvyvz tensor([[ 0.1751, -0.2166,  0.3175]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:22.318627 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:22.319624 - dR tensor([[[-0.7874,  0.4356,  0.4362],
         [-0.5673, -0.7889, -0.2362],
         [ 0.2413, -0.4334,  0.8683]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:22.320492 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:22.323667 - k: tensor([[[-0.7874,  0.4356,  0.4362, -0.0100],
         [-0.5673, -0.7889, -0.2362,  0.0062],
         [ 0.2413, -0.4334,  0.8683,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.324616 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.326149 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0952],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:22.326770 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:22.327378 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:22.328033 - k: tensor([0.0322], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0327]
       grad_fn=<CopySlices>) 0.8823,  0.0563],], device='cuda:0',s, loss=0.0539]
0:02:23.293196 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.294582 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0639],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.295265 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.295909 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.296546 - k: tensor([0.0427], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0432]
0:02:22.846669 - bracket_assembly_nut_noaug_coarse--206204
0:02:22.846885 - {'grad_norm': 1.0559606552124023, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05570673942565918, 'time_backward': 0.07698822021484375, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270397.3562317, 'n_iterations': 384, 'n_datas': 3072, 'train_loss_TCO-iter=1': 0.04322633519768715, 'train_loss_TCO': 0.04322633519768715, 'train_[loss_total': 0.04322633519768715, 'train_loss_total': 0.04322633519768715, 'train_grad_norm': 1.0559606552124023, 'epoch': 383}
0:02:22.847002 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:22.854434 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:23.379703 - iteration 0
0:02:23.600652 - vxvyvz tensor([[ 0.1942, -0.2316,  0.1994]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:23.601666 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:23.602651 - dR tensor([[[-0.7896,  0.4460,  0.4214],
         [-0.5658, -0.7950, -0.2188],
         [ 0.2374, -0.4112,  0.8801]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:23.603490 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:23.606705 - k: tensor([[[-0.7896,  0.4460,  0.4214, -0.0100],
         [-0.5658, -0.7950, -0.2188,  0.0062],
         [ 0.2374, -0.4112,  0.8801,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.607635 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.609199 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0598],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.609822 - k: tensor([3.1746e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.610427 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.611027 - k: tensor([0.0441], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.33it/s, loss=0.0444]
0:02:23.169802 - bracket_assembly_nut_noaug_coarse--206204
0:02:23.170018 - {'grad_norm': 1.0782660245895386, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055576324462890625, 'time_backward': 0.07711291313171387, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270397.670828, 'n_iterations': 385, 'n_datas': 3080, 'train_loss_TCO-iter=1': 0.04441728815436363, 'train_loss_TCO': 0.04441728815436363, 'train_[loss_total': 0.04441728815436363, 'train_loss_total': 0.04441728815436363, 'train_grad_norm': 1.0782660245895386, 'epoch': 384}
0:02:23.170130 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:23.177384 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:23.702565 - iteration 0
0:02:23.923737 - vxvyvz tensor([[ 0.1890, -0.2262,  0.3084]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:23.924793 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:23.925751 - dR tensor([[[-0.7767,  0.4434,  0.4473],
         [-0.5785, -0.7831, -0.2283],
         [ 0.2490, -0.4361,  0.8648]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:23.926575 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:23.929800 - k: tensor([[[-0.7767,  0.4434,  0.4473, -0.0100],
         [-0.5785, -0.7831, -0.2283,  0.0062],
         [ 0.2490, -0.4361,  0.8648,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.931179 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.932240 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0925],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:23.932897 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.933501 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:23.934099 - k: tensor([0.0332], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0336]
0:02:23.489169 - bracket_assembly_nut_noaug_coarse--206204
0:02:23.489393 - {'grad_norm': 1.0945661067962646, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05572843551635742, 'time_backward': 0.07729554176330566, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270397.994088, 'n_iterations': 386, 'n_datas': 3088, 'train_loss_TCO-iter=1': 0.03362597897648811, 'train_loss_TCO': 0.03362597897648811, 'train_[loss_total': 0.03362597897648811, 'train_loss_total': 0.03362597897648811, 'train_grad_norm': 1.0945661067962646, 'epoch': 385}
0:02:23.489508 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:23.496874 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:24.022051 - iteration 0
0:02:24.243210 - vxvyvz tensor([[ 0.1923, -0.2348,  0.2068]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:24.244283 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:24.245291 - dR tensor([[[-0.8178,  0.4372,  0.3744],
         [-0.5471, -0.7924, -0.2699],
         [ 0.1787, -0.4255,  0.8871]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:24.246122 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:24.249341 - k: tensor([[[-0.8178,  0.4372,  0.3744, -0.0100],
         [-0.5471, -0.7924, -0.2699,  0.0062],
         [ 0.1787, -0.4255,  0.8871,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:24.250241 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:24.251734 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0620],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:24.252368 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:24.253014 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:24.253618 - k: tensor([0.0433], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.34it/s, loss=0.0439]
       grad_fn=<CopySlices>) 0.8823,  0.0563],], device='cuda:0',s, loss=0.0539]
0:02:25.214667 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.216174 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0623],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.216839 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.217447 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.218052 - k: tensor([0.0432], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0438]
0:02:24.776407 - bracket_assembly_nut_noaug_coarse--206204
0:02:24.776623 - {'grad_norm': 1.0484929084777832, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05559563636779785, 'time_backward': 0.07738757133483887, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270399.2780826, 'n_iterations': 390, 'n_datas': 3120, 'train_loss_TCO-iter=1': 0.04383225366473198, 'train_loss_TCO': 0.04383225366473198, 'train_[loss_total': 0.04383225366473198, 'train_loss_total': 0.04383225366473198, 'train_grad_norm': 1.0484929084777832, 'epoch': 389}
0:02:24.776736 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:24.784107 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:25.309275 - iteration 0
0:02:25.530657 - vxvyvz tensor([[ 0.2041, -0.2387,  0.2476]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:25.531730 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:25.532738 - dR tensor([[[-0.7890,  0.4629,  0.4040],
         [-0.5725, -0.7926, -0.2100],
         [ 0.2230, -0.3970,  0.8903]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:25.533565 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:25.536788 - k: tensor([[[-0.7890,  0.4629,  0.4040, -0.0100],
         [-0.5725, -0.7926, -0.2100,  0.0062],
         [ 0.2230, -0.3970,  0.8903,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.537705 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.539345 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0743],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.540079 - k: tensor([7.3078e-05], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.540737 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.541340 - k: tensor([0.0392], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.28it/s, loss=0.0396]
0:02:25.098624 - bracket_assembly_nut_noaug_coarse--206204
0:02:25.098838 - {'grad_norm': 1.0338667631149292, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05619382858276367, 'time_backward': 0.07752537727355957, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270399.6029298, 'n_iterations': 391, 'n_datas': 3128, 'train_loss_TCO-iter=1': 0.03963136300444603, 'train_loss_TCO': 0.03963136300444603, 'train_[loss_total': 0.03963136300444603, 'train_loss_total': 0.03963136300444603, 'train_grad_norm': 1.0338667631149292, 'epoch': 390}
0:02:25.098945 - {}
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:25.106666 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:25.631856 - iteration 0
0:02:25.853225 - vxvyvz tensor([[ 0.1954, -0.2252,  0.2897]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:25.854261 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:25.855228 - dR tensor([[[-0.7794,  0.4775,  0.4056],
         [-0.5834, -0.7892, -0.1919],
         [ 0.2285, -0.3862,  0.8937]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:25.856099 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:25.859295 - k: tensor([[[-0.7794,  0.4775,  0.4056, -0.0100],
         [-0.5834, -0.7892, -0.1919,  0.0062],
         [ 0.2285, -0.3862,  0.8937,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.860242 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.861768 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0869],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:25.862388 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.862995 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:25.863631 - k: tensor([0.0350], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0355]
0:02:25.425617 - bracket_assembly_nut_noaug_coarse--206204
0:02:25.425846 - {'grad_norm': 1.1024454832077026, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05590963363647461, 'time_backward': 0.07747936248779297, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270399.9237804, 'n_iterations': 392, 'n_datas': 3136, 'train_loss_TCO-iter=1': 0.03550055995583534, 'train_loss_TCO': 0.03550055995583534, 'train_[loss_total': 0.03550055995583534, 'train_loss_total': 0.03550055995583534, 'train_grad_norm': 1.1024454832077026, 'epoch': 391}
0:02:25.425969 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:25.433360 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:25.958602 - iteration 0
0:02:26.180446 - vxvyvz tensor([[ 0.2046, -0.2381,  0.2056]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:26.181440 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:26.182382 - dR tensor([[[-0.7970,  0.4524,  0.4001],
         [-0.5682, -0.7863, -0.2428],
         [ 0.2047, -0.4209,  0.8837]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:26.183211 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:26.186427 - k: tensor([[[-0.7970,  0.4524,  0.4001, -0.0100],
         [-0.5682, -0.7863, -0.2428,  0.0062],
         [ 0.2047, -0.4209,  0.8837,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.187901 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.188875 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0617],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.189491 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:26.190097 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:26.190701 - k: tensor([0.0434], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.25it/s, loss=0.0439]
0:02:25.755512 - bracket_assembly_nut_noaug_coarse--206204
0:02:25.755713 - {'grad_norm': 1.0394707918167114, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05640244483947754, 'time_backward': 0.07783961296081543, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270400.2512057, 'n_iterations': 393, 'n_datas': 3144, 'train_loss_TCO-iter=1': 0.043881598860025406, 'train_loss_TCO': 0.043881598860025406, 'train_[loss_total': 0.043881598860025406, 'train_loss_total': 0.043881598860025406, 'train_grad_norm': 1.0394707918167114, 'epoch': 392}
0:02:25.755831 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:25.763207 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:26.288407 - iteration 0
0:02:26.509450 - vxvyvz tensor([[ 0.2060, -0.2369,  0.2093]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:26.510474 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:26.511425 - dR tensor([[[-0.8136,  0.4437,  0.3758],
         [-0.5459, -0.8054, -0.2309],
         [ 0.2002, -0.3930,  0.8975]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:26.512303 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:26.515488 - k: tensor([[[-0.8136,  0.4437,  0.3758, -0.0100],
         [-0.5459, -0.8054, -0.2309,  0.0062],
         [ 0.2002, -0.3930,  0.8975,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.516739 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.518041 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0628],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:26.518661 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:26.519272 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:26.519915 - k: tensor([0.0431], device='cuda:0', grad_fn=<MinBackward0>)
  0%|                                        | 0/1 [00:00<?, ?it/s, loss=0.0436]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
       grad_fn=<CopySlices>)
0:02:27.501184 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:27.502642 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0677],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:27.503268 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:27.503914 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:27.504553 - k: tensor([0.0414], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.32it/s, loss=0.0419]
0:02:27.063486 - bracket_assembly_nut_noaug_coarse--206204
0:02:27.063687 - {'grad_norm': 1.061252474784851, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.055487632751464844, 'time_backward': 0.07737898826599121, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270401.564562, 'n_iterations': 397, 'n_datas': 3176, 'train_loss_TCO-iter=1': 0.04188467934727669, 'train_loss_TCO': 0.04188467934727669, 'train_[loss_total': 0.04188467934727669, 'train_loss_total': 0.04188467934727669, 'train_grad_norm': 1.061252474784851, 'epoch': 396}
0:02:27.063803 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:27.071434 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:27.596584 - iteration 0
0:02:27.817525 - vxvyvz tensor([[ 0.2115, -0.2377,  0.2112]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:27.818534 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:27.819539 - dR tensor([[[-0.8053,  0.4455,  0.3912],
         [-0.5574, -0.7937, -0.2437],
         [ 0.2019, -0.4143,  0.8875]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:27.820393 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:27.823601 - k: tensor([[[-0.8053,  0.4455,  0.3912, -0.0100],
         [-0.5574, -0.7937, -0.2437,  0.0062],
         [ 0.2019, -0.4143,  0.8875,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:27.824550 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:27.825985 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0634],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:27.826687 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:27.827298 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:27.827940 - k: tensor([0.0429], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.29it/s, loss=0.0433]
0:02:27.386575 - bracket_assembly_nut_noaug_coarse--206204
0:02:27.386794 - {'grad_norm': 1.0475963354110718, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.0554966926574707, 'time_backward': 0.07790231704711914, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270401.888604, 'n_iterations': 398, 'n_datas': 3184, 'train_loss_TCO-iter=1': 0.04333871975541115, 'train_loss_TCO': 0.04333871975541115, 'train_[loss_total': 0.04333871975541115, 'train_loss_total': 0.04333871975541115, 'train_grad_norm': 1.0475963354110718, 'epoch': 397}
0:02:27.386928 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:27.394384 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:27.919606 - iteration 0
0:02:28.141163 - vxvyvz tensor([[ 0.2033, -0.2305,  0.2961]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:28.142202 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:28.143152 - dR tensor([[[-0.7851,  0.4718,  0.4012],
         [-0.5776, -0.7916, -0.1994],
         [ 0.2235, -0.3883,  0.8940]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:28.144022 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:28.147228 - k: tensor([[[-0.7851,  0.4718,  0.4012, -0.0100],
         [-0.5776, -0.7916, -0.1994,  0.0062],
         [ 0.2235, -0.3883,  0.8940,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.148749 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.149798 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.0888],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.150434 - k: tensor([0.0001], device='cuda:0', grad_fn=<MinBackward0>)
0:02:28.151040 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:28.151675 - k: tensor([0.0344], device='cuda:0', grad_fn=<MinBackward0>)
100%|████████████████████████████████| 1/1 [00:00<00:00,  7.23it/s, loss=0.0348]
0:02:27.709161 - bracket_assembly_nut_noaug_coarse--206204
0:02:27.709377 - {'grad_norm': 1.1599385738372803, 'grad_norm_std': inf, 'learning_rate': 2.5250000000000004e-06, 'time_forward': 0.05634188652038574, 'time_backward': 0.07831001281738281, 'time_data': nan, 'gpu_memory': 2299.4736328125, 'time': 1683270402.212619, 'n_iterations': 399, 'n_datas': 3192, 'train_loss_TCO-iter=1': 0.03483670577406883, 'train_loss_TCO': 0.03483670577406883, 'train_[loss_total': 0.03483670577406883, 'train_loss_total': 0.03483670577406883, 'train_grad_norm': 1.1599385738372803, 'epoch': 398}
0:02:27.709487 - None
  0%|                                                     | 0/1 [00:00<?, ?it/s]0:02:27.716902 - TCO_init tensor([[[ 1.0000,  0.0000,  0.0000, -0.0166],
         [ 0.0000,  1.0000,  0.0000,  0.0103],
         [ 0.0000,  0.0000,  1.0000,  0.3000],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:28.242117 - iteration 0
0:02:28.463326 - vxvyvz tensor([[ 0.1748, -0.2204,  0.6047]], device='cuda:0',
       grad_fn=<SliceBackward0>)
0:02:28.464381 - TCO_gt tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0')
0:02:28.465372 - dR tensor([[[-0.7791,  0.4408,  0.4458],
         [-0.5791, -0.7784, -0.2424],
         [ 0.2402, -0.4470,  0.8617]]], device='cuda:0',
       grad_fn=<StackBackward0>)
0:02:28.466198 - fxfy tensor([[1811.1807, 1811.1808]], device='cuda:0')
0:02:28.469474 - k: tensor([[[-0.7791,  0.4408,  0.4458, -0.0100],
         [-0.5791, -0.7784, -0.2424,  0.0062],
         [ 0.2402, -0.4470,  0.8617,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.470429 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0106],
         [-0.5688, -0.7927, -0.2192,  0.0066],
         [ 0.2313, -0.4099,  0.8823,  0.1920],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.471939 - k: tensor([[[-0.7893,  0.4511,  0.4165, -0.0100],
         [-0.5688, -0.7927, -0.2192,  0.0062],
         [ 0.2313, -0.4099,  0.8823,  0.1814],
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',
       grad_fn=<CopySlices>)
0:02:28.472606 - k: tensor([0.0002], device='cuda:0', grad_fn=<MinBackward0>)
0:02:28.473227 - k: tensor([0.0003], device='cuda:0', grad_fn=<MinBackward0>)
0:02:28.473832 - k: tensor([0.0035], device='cuda:0', grad_fn=<MinBackward0>)
100%|███████████████████████████████| 1/1 [00:00<00:00,  7.19it/s, loss=0.00402]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]
         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',s, loss=0.0539]